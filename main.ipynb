{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NeRF: Collision handling in Instant Neural Graphics Primitives\n",
    "#### Federico Montagna (fedemonti00@gmail.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda avilable: True\n",
      "Available device 0: NVIDIA GeForce RTX 2070\n",
      "Available device 1: NVIDIA GeForce RTX 2070\n",
      "Current device 0: NVIDIA GeForce RTX 2070\n",
      "Random seed: 45005\n"
     ]
    }
   ],
   "source": [
    "from typing import Tuple, List\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib\n",
    "from matplotlib.ticker import MultipleLocator, AutoMinorLocator, FixedLocator\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from scipy.stats import norm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import collections, functools, operator\n",
    "from collections import Counter\n",
    "import itertools\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import io, transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.autograd.profiler as profiler\n",
    "from torch.optim.lr_scheduler import StepLR, CosineAnnealingLR, CosineAnnealingWarmRestarts\n",
    "\n",
    "# from torchinfo import summary\n",
    "\n",
    "from einops import rearrange, reduce, repeat\n",
    "\n",
    "import traceback\n",
    "import inspect\n",
    "from pprint import pprint\n",
    "\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pdb\n",
    "\n",
    "try:\n",
    "    from zoneinfo import ZoneInfo\n",
    "except ImportError:\n",
    "    from backports.zoneinfo import ZoneInfo\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# from params import *\n",
    "\n",
    "print(\"Cuda avilable:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"Available device {i}:\", torch.cuda.get_device_name(i))\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Current device {torch.cuda.current_device()}:\", torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "\n",
    "torch.set_default_device(device)\n",
    "\n",
    "random_seed = 45005 # np.random.randint(0, (2**16 - 1)) # 4129\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "torch.random.manual_seed(random_seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(random_seed)\n",
    "print(\"Random seed:\", random_seed)\n",
    "\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"main.ipynb\"\n",
    "\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bcolors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKCYAN = '\\033[96m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "\n",
    "decoded_functions = {\n",
    "    # general\n",
    "    \"__init__\": 0,\n",
    "    \"forward\": 1,\n",
    "    \"train_loop\": 1,\n",
    "    \"test_loop\": 1,\n",
    "    \"plot_images\": 2,\n",
    "    # MultiResolution\n",
    "    \"_multiresolution_hash\": 2,\n",
    "    \"_scale_to_grid\": 3,\n",
    "    \"_calc_bilinear_coefficients\": 4,\n",
    "    \"_calc_dummies\": 5,\n",
    "    \"_calc_hash_collisions\": 6,\n",
    "    \"_calc_uniques\": 7,\n",
    "    # GeneralNeuralGaugeFields\n",
    "    \"_look_up\": 2,\n",
    "    \"_bilinear_interpolate\": 3,\n",
    "    # Loss\n",
    "    \"_calc_hist_pdf\": 2,\n",
    "    \"_kl_div\": 3\n",
    "}\n",
    "\n",
    "def log(texts, allowed, color: bcolors = bcolors.OKCYAN) -> None:\n",
    "    if allowed: # if allowed is not empty then check else do nothing\n",
    "        if decoded_functions[inspect.stack()[1][0].f_code.co_name] in allowed:\n",
    "            stack = traceback.extract_stack()\n",
    "            calling_frame = stack[-2]\n",
    "            calling_line = calling_frame.line\n",
    "            print(color, \"Line: \", calling_line, bcolors.ENDC)\n",
    "            for text in texts:\n",
    "                print(text)\n",
    "            print(color, \"-\"*20, bcolors.ENDC)\n",
    "\n",
    "\n",
    "def print_allocated_memory(log: bool = True):\n",
    "    if log:\n",
    "        stack = traceback.extract_stack()\n",
    "        calling_frame = stack[-2]\n",
    "        calling_line = calling_frame.line\n",
    "        print(bcolors.HEADER, \"Line: \", calling_line, bcolors.ENDC)\n",
    "\n",
    "        allocated_memory = torch.cuda.memory_allocated() / (1024 ** 3)  # Convert to gigabytes\n",
    "        print(f\"Allocated Memory: {allocated_memory:.2f} GB\")\n",
    "\n",
    "        peak_memory = torch.cuda.max_memory_allocated() / (1024 ** 3)  # Convert to gigabytes\n",
    "        print(f\"Peak Allocated Memory: {peak_memory:.2f} GB\")\n",
    "\n",
    "        print(bcolors.OKCYAN, \"-\"*20, bcolors.ENDC)\n",
    "\n",
    "\n",
    "def plot_images(outs: np.ndarray, targets: np.ndarray, allowed: List = []) -> None:\n",
    "    if allowed: # if allowed is not empty then check else do nothing\n",
    "        if decoded_functions[inspect.stack()[0][0].f_code.co_name] in allowed:\n",
    "            rows = outs.shape[0]\n",
    "            cols = 2\n",
    "\n",
    "            fig, axs = plt.subplots(rows, cols, figsize=(5 * cols, 5 * rows))\n",
    "            axs = axs.flatten()\n",
    "            for i in range(0, (rows * cols), cols):\n",
    "                axs[i + 0].imshow(outs[i//cols])\n",
    "                axs[i + 0].set_title(\"Prediction\")\n",
    "                axs[i + 1].imshow(targets[i//cols])\n",
    "                axs[i + 1].set_title(\"Target\")\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load wandb apikey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apikey_path = \".wandb_apikey.txt\"\n",
    "# if os.path.exists(apikey_path):\n",
    "#     with open(apikey_path, \"r\") as f:\n",
    "#         apikey = f.read()\n",
    "#         !wandb login {apikey} # --relogin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagesDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        root: str,\n",
    "        dir_name: str,\n",
    "        images_names: List[str],\n",
    "        should_random_permute_input: bool = False,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        root : str\n",
    "            Path to root directory.\n",
    "        dir_name : str\n",
    "            Name of directory.\n",
    "        images_names : List[str]\n",
    "            List of images names.\n",
    "        should_random_permute_input : bool, optional (default is False)\n",
    "            Should random permute input\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "\n",
    "        self._root: str = root\n",
    "        self._dir_name: str = dir_name\n",
    "        self._images_names: List[str] = images_names\n",
    "\n",
    "        self._should_random_permute_input: bool = should_random_permute_input\n",
    "\n",
    "        self._images_paths: List[str] = [\n",
    "            os.path.join(self._root, self._dir_name, image_name)\n",
    "            for image_name in self._images_names\n",
    "        ]\n",
    "    \n",
    "    def __getitem__(self, idx: torch.Tensor or int) -> Tuple[torch.Tensor, torch.Tensor, int, int]:\n",
    "        \"\"\"\n",
    "        Get data by indices.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        idx : torch.Tensor or int\n",
    "            Indices of data.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Tuple[torch.Tensor, torch.Tensor, int, int]\n",
    "            Tuple of images.\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        ValueError\n",
    "            If images have different sizes.\n",
    "        \"\"\"\n",
    "\n",
    "        if idx == -1:\n",
    "            idx = torch.arange(len(self._images_paths))\n",
    "        \n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx\n",
    "        else:\n",
    "            idx = torch.tensor(idx)\n",
    "\n",
    "        images: List = [\n",
    "            rearrange(io.read_image(self._images_paths[_id]).to(device), \"rgb h w -> h w rgb\")\n",
    "            for _id in idx\n",
    "        ]\n",
    "\n",
    "        heights, widths = list(set([image.shape[0] for image in images])), list(set([image.shape[1] for image in images]))\n",
    "\n",
    "        if len(heights) > 1 or len(widths) > 1:\n",
    "            raise ValueError(\"Images have different sizes.\")\n",
    "        else:\n",
    "            h = heights[0]\n",
    "            w = widths[0]\n",
    "\n",
    "        imgs_shape = h * w\n",
    "        \n",
    "        reordered_indices: torch.Tensor = torch.stack([\n",
    "            torch.zeros((imgs_shape, )).int()\n",
    "            for _ in images\n",
    "        ])\n",
    "\n",
    "        X: torch.Tensor = torch.zeros(idx.shape[0], imgs_shape, 2)\n",
    "        Y: torch.Tensor = torch.zeros(len(images), imgs_shape, images[0].shape[-1])\n",
    "\n",
    "        for i, image in enumerate(images):\n",
    "            if self._should_random_permute_input:\n",
    "                shuffled_indices = torch.randperm(imgs_shape).int()\n",
    "            else:\n",
    "                shuffled_indices = torch.arange(imgs_shape).int()\n",
    "            \n",
    "            reordered_indices[i][shuffled_indices] = torch.arange(imgs_shape).int()\n",
    "            \n",
    "            X[i] = torch.tensor(\n",
    "                np.stack(np.meshgrid(range(h), range(w), indexing=\"ij\"), axis=-1).reshape(-1, 2)\n",
    "            )[shuffled_indices]\n",
    "\n",
    "            Y[i] = rearrange(image, \"h w rgb -> (h w) rgb\")[shuffled_indices]\n",
    "\n",
    "        X = (\n",
    "            X.float() / (max(w, h)) # No (max(w, h) - 1)\n",
    "        ).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        Y = Y.float() / 255\n",
    "        \n",
    "        # else:\n",
    "        #     X: torch.Tensor = (\n",
    "        #         torch.stack([\n",
    "        #             torch.tensor(\n",
    "        #                 np.stack(np.meshgrid(range(h), range(w), indexing=\"ij\"), axis=-1).reshape(-1, 2)\n",
    "        #             )\n",
    "        #             for _ in images\n",
    "        #         ]).float() / (max(w, h)) # No (max(w, h) - 1)\n",
    "        #     ).unsqueeze(-1).unsqueeze(-1) #.requires_grad_()\n",
    "            \n",
    "        #     Y: torch.Tensor = torch.stack(\n",
    "        #         images\n",
    "        #     ).float() / 255\n",
    "\n",
    "        return X, Y, h, w, reordered_indices, self._images_names\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"\n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            Length of dataset.\n",
    "        \"\"\"\n",
    "        return len(self._images_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward Pass Differentiable Approximation\n",
    "[https://github.com/kitayama1234/Pytorch-BPDA]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BPDA(x, round_function):\n",
    "    forward_value = round_function(x)\n",
    "    out = x.clone()\n",
    "    out.data = forward_value.data\n",
    "    return out\n",
    "\n",
    "def differentiable_floor(x, round_function=torch.floor):\n",
    "    return BPDA(x, round_function)\n",
    "\n",
    "def differentiable_round(x, round_function=torch.round):\n",
    "    return BPDA(x, round_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Convolution Backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianConvolution(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x: torch.Tensor, hash_table_size: int):\n",
    "        # pdb.set_trace()\n",
    "        \n",
    "        ctx.save_for_backward(x)\n",
    "        ctx.hash_table_size = hash_table_size\n",
    "\n",
    "        indices = differentiable_round(x * hash_table_size)\n",
    "\n",
    "        # ctx.indices = indices\n",
    "        # ctx.save_for_backward(indices)\n",
    "\n",
    "        return indices\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output: torch.Tensor):\n",
    "        # pdb.set_trace()\n",
    "        \n",
    "        # indices = ctx.saved_tensors\n",
    "        x, = ctx.saved_tensors\n",
    "        hash_table_size = ctx.hash_table_size\n",
    "\n",
    "        indices = x * hash_table_size\n",
    "        # indices = ctx.indices\n",
    "\n",
    "        grad_x = grad_output * norm.pdf(np.arange(0, hash_table_size, 1), loc=indices, scale=1)\n",
    "\n",
    "        return grad_x, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Differentiable Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# Differentiable Histogram Counting Method\n",
    "#############################################\n",
    "# https://github.com/hyk1996/pytorch-differentiable-histogram\n",
    "def differentiable_histogram(x, bins=255, min=0.0, max=1.0):\n",
    "\n",
    "    if len(x.shape) == 4:\n",
    "        n_samples, n_chns, _, _ = x.shape\n",
    "    elif len(x.shape) == 2:\n",
    "        n_samples, n_chns = 1, 1\n",
    "    else:\n",
    "        raise AssertionError('The dimension of input tensor should be 2 or 4.')\n",
    "\n",
    "    hist_torch = torch.zeros(n_samples, n_chns, bins).to(x.device)\n",
    "    delta = (max - min) / bins\n",
    "\n",
    "    BIN_Table = torch.arange(start=0, end=bins, step=1) * delta\n",
    "\n",
    "    for dim in range(1, bins-1, 1):\n",
    "        h_r = BIN_Table[dim].item()             # h_r\n",
    "        h_r_sub_1 = BIN_Table[dim - 1].item()   # h_(r-1)\n",
    "        h_r_plus_1 = BIN_Table[dim + 1].item()  # h_(r+1)\n",
    "\n",
    "        mask_sub = ((h_r > x) & (x >= h_r_sub_1)).float()\n",
    "        mask_plus = ((h_r_plus_1 > x) & (x >= h_r)).float()\n",
    "\n",
    "        hist_torch[:, :, dim] += torch.sum(((x - h_r_sub_1) * mask_sub).view(n_samples, n_chns, -1), dim=-1)\n",
    "        hist_torch[:, :, dim] += torch.sum(((h_r_plus_1 - x) * mask_plus).view(n_samples, n_chns, -1), dim=-1)\n",
    "\n",
    "    return hist_torch / delta\n",
    "\n",
    "\n",
    "#############################################\n",
    "# Kornia Differentiable Histogram Counting Method\n",
    "#############################################\n",
    "# https://kornia.readthedocs.io/en/latest/_modules/kornia/enhance/histogram.html#histogram\n",
    "\n",
    "def marginal_pdf(\n",
    "    values: torch.Tensor, bins: torch.Tensor, sigma: torch.Tensor, epsilon: float = 1e-10\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"Calculate the marginal probability distribution function of the input tensor based on the number of\n",
    "    histogram bins.\n",
    "\n",
    "    Args:\n",
    "        values: shape [BxNx1].\n",
    "        bins: shape [NUM_BINS].\n",
    "        sigma: shape [1], gaussian smoothing factor.\n",
    "        epsilon: scalar, for numerical stability.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[torch.Tensor, torch.Tensor]:\n",
    "          - torch.Tensor: shape [BxN].\n",
    "          - torch.Tensor: shape [BxNxNUM_BINS].\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(values, torch.Tensor):\n",
    "        raise TypeError(f\"Input values type is not a torch.Tensor. Got {type(values)}\")\n",
    "\n",
    "    if not isinstance(bins, torch.Tensor):\n",
    "        raise TypeError(f\"Input bins type is not a torch.Tensor. Got {type(bins)}\")\n",
    "\n",
    "    if not isinstance(sigma, torch.Tensor):\n",
    "        raise TypeError(f\"Input sigma type is not a torch.Tensor. Got {type(sigma)}\")\n",
    "\n",
    "    if not values.dim() == 3:\n",
    "        raise ValueError(f\"Input values must be a of the shape BxNx1. Got {values.shape}\")\n",
    "\n",
    "    if not bins.dim() == 1:\n",
    "        raise ValueError(f\"Input bins must be a of the shape NUM_BINS. Got {bins.shape}\")\n",
    "\n",
    "    if not sigma.dim() == 0:\n",
    "        raise ValueError(f\"Input sigma must be a of the shape 1. Got {sigma.shape}\")\n",
    "\n",
    "    residuals = values - bins.unsqueeze(0).unsqueeze(0)\n",
    "    kernel_values = torch.exp(-0.5 * (residuals / sigma).pow(2))\n",
    "\n",
    "    pdf = torch.mean(kernel_values, dim=1)\n",
    "    normalization = torch.sum(pdf, dim=1).unsqueeze(1) + epsilon\n",
    "    pdf = pdf / normalization\n",
    "\n",
    "    return pdf, kernel_values\n",
    "\n",
    "def histogram(x: torch.Tensor, bins: torch.Tensor, bandwidth: torch.Tensor = None, epsilon: float = 1e-10) -> torch.Tensor:\n",
    "    \"\"\"Estimate the NORMALIZED histogram of the input tensor.\n",
    "\n",
    "    The calculation uses kernel density estimation which requires a bandwidth (smoothing) parameter.\n",
    "\n",
    "    Args:\n",
    "        x: Input tensor to compute the histogram with shape :math:`(B, D)`.\n",
    "        bins: The number of bins to use the histogram :math:`(N_{bins})`.\n",
    "        bandwidth: Gaussian smoothing factor with shape shape [1].\n",
    "        epsilon: A scalar, for numerical stability.\n",
    "\n",
    "    Returns:\n",
    "        Computed histogram of shape :math:`(B, N_{bins})`.\n",
    "\n",
    "    Examples:\n",
    "        >>> x = torch.rand(1, 10)\n",
    "        >>> bins = torch.torch.linspace(0, 255, 128)\n",
    "        >>> hist = histogram(x, bins, bandwidth=torch.tensor(0.9))\n",
    "        >>> hist.shape\n",
    "        torch.Size([1, 128])\n",
    "    \"\"\"\n",
    "\n",
    "    # x = rearrange(x, \"b d -> 1 (b d)\")\n",
    "    # x = rearrange(x, \"b d -> d b\")\n",
    "    # x = rearrange(x, \"b d -> (d b) 1\")\n",
    "    # print(x.shape, bins.shape, bandwidth.shape)\n",
    "\n",
    "    N = x.size(1)\n",
    "    if bandwidth is None:\n",
    "        std = torch.std(x)\n",
    "        q25 = np.percentile(x.detach().cpu().numpy(), 25)\n",
    "        q75 = np.percentile(x.detach().cpu().numpy(), 75)\n",
    "        iqr = torch.tensor(q75 - q25)\n",
    "        bandwidth = 0.9 * torch.min(std, iqr / 1.34) * (N **(-0.2))\n",
    "\n",
    "    # print(sigma_initial)\n",
    "\n",
    "    pdf, _ = marginal_pdf(x.unsqueeze(2), bins, bandwidth, epsilon)\n",
    "    # print(\"PDF:\", pdf, pdf.shape)\n",
    "\n",
    "    return pdf * (N + epsilon)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hash Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Student's T Table)[https://www.craftonhills.edu/current-students/tutoring-center/mathematics-tutoring/distribution_tables_normal_studentt_chisquared.pdf]  \n",
    "$\\alpha = 0.8$, $DF = +\\inf$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HashFunction(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_layers_widths: List[int],\n",
    "        input_dim: int = 2,\n",
    "        output_dim: int = 1,\n",
    "        hash_table_size: int = 2**14,\n",
    "        sigma_scale: float = 1.0,\n",
    "        hidden_layers_activation: nn.Module = nn.ReLU(),\n",
    "        should_normalize_levels: bool = False,\n",
    "        should_dropout: bool = False,\n",
    "        should_log: List = [], \n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Hash function module.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        hidden_layers_widths : List[int]\n",
    "            List of hidden layers widths.\n",
    "        input_dim : int, optional (default is 2)\n",
    "            Input dimension\n",
    "        output_dim : int, optional (default is 1)\n",
    "            Output dimension\n",
    "        hash_table_size : int, optional (default is 2**14)\n",
    "            Hash table size.\n",
    "        sigma_scale : float, optional (default is 1.0)\n",
    "            Sigma scale.\n",
    "        hidden_layers_activation : nn.Module, optional (default is nn.ReLU())\n",
    "            Hidden layers activation.\n",
    "        should_normalize_levels : bool, optional (default is False)\n",
    "            Whether to normalize levels or not.\n",
    "        should_dropout : bool, optional (default is False)\n",
    "            Should dropout.\n",
    "        should_log : List, optional (default is [])\n",
    "            List of decoded functions to log.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "\n",
    "        super(HashFunction, self).__init__()\n",
    "\n",
    "        self._hash_table_size: int = hash_table_size\n",
    "        self._sigma_scale: float = sigma_scale\n",
    "\n",
    "        self._alpha: float = 0.8 # student's t-distribution confidence level\n",
    "        \n",
    "        self._should_normalize_levels: bool = should_normalize_levels\n",
    "        self._should_dropout: bool = should_dropout\n",
    "        self._should_log: List = should_log\n",
    "\n",
    "        layers_widths: List[int] = [input_dim, *hidden_layers_widths, output_dim]\n",
    "\n",
    "        self.module_list: nn.ModuleList = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(in_features=layers_widths[i], out_features=layers_widths[i + 1]),\n",
    "                hidden_layers_activation if (i < (len(layers_widths) - 2)) else nn.Sigmoid()\n",
    "            ) for i in range(len(layers_widths) - 1)\n",
    "        ])\n",
    "\n",
    "        self._dropout: nn.Module = nn.Dropout(p=0.1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor]:\n",
    "        log((\"Input:\", x, x.shape), self._should_log)\n",
    "        log((\"Input grad:\", x.requires_grad, ), self._should_log)\n",
    "\n",
    "        # if self._should_normalize_levels:\n",
    "        #     x = x / self._levels.unsqueeze(-1)\n",
    "        #     log((\"normalized_input:\", x, x.shape), self._should_log)\n",
    "        #     log((\"normalized_input grads:\", x.requires_grad), self._should_log)\n",
    "\n",
    "        for i, layer in enumerate(self.module_list):\n",
    "            x = layer(x)\n",
    "            log((f\"After layer {i}:\", f\"Output: {x}, shape: {x.shape}, grad: {x.requires_grad}\"), self._should_log)\n",
    "\n",
    "        if self._should_dropout:\n",
    "            x = self._dropout(x)\n",
    "\n",
    "        log((f\"After layers:\", f\"Output: {x}, shape: {x.shape}\"), self._should_log)\n",
    "        log((f\"After layers:\", f\"Grad info: {x.requires_grad}, {x.grad_fn}\"), self._should_log)\n",
    "        \n",
    "        # x = torch.nan_to_num(x) # Sanitize nan to 0.0\n",
    "\n",
    "        if x.shape[-1] == 1: # directly indices\n",
    "            indices = GaussianConvolution.apply(x, (self._hash_table_size - 1))\n",
    "            log((\"GaussianConvolution:\", indices, indices.shape), self._should_log)\n",
    "            log((\"GaussianConvolution grad:\", indices.requires_grad, ), self._should_log)\n",
    "\n",
    "            sigma = None\n",
    "        else: # mu and sigma            \n",
    "            x = x.unsqueeze(-1)\n",
    "            log((\"x:\", x, x.shape), self._should_log)\n",
    "\n",
    "            sigma = (x[..., 1, :] * self._sigma_scale)\n",
    "            x = x[..., 0, :]\n",
    "            mu = (differentiable_round(x * (self._hash_table_size -1)))\n",
    "\n",
    "            log((\"Mu:\", mu, mu.shape), self._should_log)\n",
    "            log((\"Sigma:\", sigma, sigma.shape), self._should_log)\n",
    "\n",
    "            a, b = norm.interval(self._alpha, loc=mu.detach().cpu().numpy(), scale=sigma.detach().cpu().numpy()) # a -> at left of mean, b -> at right of mean\n",
    "            a, b = torch.tensor(np.round(a)).float(), torch.tensor(np.round(b)).float()\n",
    "            log((\"a:\", a, a.shape), self._should_log)\n",
    "            log((\"b:\", b, b.shape), self._should_log)\n",
    "\n",
    "            top_ks = torch.stack([a, b], dim=-1).squeeze(-2)\n",
    "            log((\"top_ks:\", top_ks, top_ks.shape), self._should_log)\n",
    "\n",
    "            del a, b\n",
    "\n",
    "        return x, mu, sigma, top_ks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiresolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Multiresolution(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_min: int,\n",
    "        n_max: int,\n",
    "        num_levels: int,\n",
    "        HashFunction: HashFunction,\n",
    "        hash_table_size: int = None,\n",
    "        input_dim: int = 2,\n",
    "        should_use_all_levels: bool = False,\n",
    "        should_fast_hash: bool = False,\n",
    "        should_log: List = []\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Multiresolution module.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_min : int\n",
    "            Minimum scaling factor.\n",
    "        n_max : int\n",
    "            Maximum scaling factor.\n",
    "        num_levels : int\n",
    "            Number of levels.\n",
    "        HashFunction : HashFunction\n",
    "            Hash function module.\n",
    "        hash_table_size : int, optional (default is None)\n",
    "            Hash table size. If None it will be taken from HashFunction.\n",
    "        input_dim : int, optional (default is 2)\n",
    "            Input dimension.\n",
    "        should_use_all_levels : bool, optional (default is False)\n",
    "            Whether to use all levels or only the ones with collisions.\n",
    "        should_fast_hash : bool, optional (default is False)\n",
    "            Whether to use fast hash instead of HashFunction or not.\n",
    "        should_log : List, optional (default is [])\n",
    "            List of decoded functions to log.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "\n",
    "        super(Multiresolution, self).__init__()\n",
    "\n",
    "        self.HashFunction: nn.Module = HashFunction\n",
    "\n",
    "        self._hash_table_size: int = (\n",
    "            hash_table_size \n",
    "            if hash_table_size is not None \n",
    "            else \n",
    "            self.HashFunction._hash_table_size\n",
    "        )\n",
    "        self._num_levels: int = num_levels\n",
    "        self._input_dim: int = input_dim\n",
    "        self._should_use_all_levels: bool = should_use_all_levels\n",
    "        self._should_fast_hash: bool = should_fast_hash\n",
    "        self._should_log: int = should_log\n",
    "\n",
    "        b: torch.Tensor = torch.tensor(np.exp((np.log(n_max) - np.log(n_min)) / (self._num_levels - 1))).float()\n",
    "        if b > 2 or b <= 1:\n",
    "            print(\n",
    "                f\"The between level scale is recommended to be <= 2 and needs to be > 1 but was {b:.4f}.\"\n",
    "            )\n",
    "        \n",
    "        self._levels: torch.Tensor = torch.stack([\n",
    "            torch.floor(n_min * (b ** l)) for l in range(self._num_levels)\n",
    "        ]).reshape(1, 1, -1, 1)\n",
    "        log((\"Levels:\", self._levels, self._levels.shape), self._should_log)\n",
    "        log((\"Levels grads:\", self._levels.requires_grad, ), self._should_log)\n",
    "\n",
    "        self._voxels_helper_hypercube: torch.Tensor = rearrange(\n",
    "            torch.tensor(\n",
    "                np.stack(np.meshgrid(range(2), range(2), range(self._input_dim - 1), indexing=\"ij\"), axis=-1)\n",
    "            ),\n",
    "            \"cols rows depths verts -> (depths rows cols) verts\"\n",
    "        ).T[:self._input_dim, :].unsqueeze(0).unsqueeze(2)\n",
    "        log((\"voxels_helper_hypercube:\", self._voxels_helper_hypercube, self._voxels_helper_hypercube.shape), self._should_log )\n",
    "        log((\"voxels_helper_hypercube grads:\", self._voxels_helper_hypercube.requires_grad), self._should_log)\n",
    "\n",
    "        if self._should_fast_hash:\n",
    "            self._prime_numbers = torch.nn.Parameter(\n",
    "                torch.from_numpy(\n",
    "                    np.array([1, 2654435761, 805459861])\n",
    "                ).to(device),\n",
    "                False\n",
    "            )\n",
    "    \n",
    "    def forward(\n",
    "        self, \n",
    "        x: torch.Tensor, \n",
    "        should_calc_hists: bool = False,\n",
    "    ) -> Tuple[torch.Tensor]:\n",
    "        log((\"x:\", x, x.shape), self._should_log)\n",
    "        log((\"x grads:\", x.requires_grad, ), self._should_log)\n",
    "\n",
    "        _, grid_coords, coeffs = self._scale_to_grid(x)\n",
    "        dummy_grids, og_indices, _ = self._calc_dummies(grid_coords=grid_coords)\n",
    "        min_possible_collisions, _ = self._calc_hash_collisions(dummy_grids=dummy_grids)\n",
    "\n",
    "        if self._should_fast_hash:\n",
    "            hashed = self._fast_hash(grid_coords)\n",
    "            probs = torch.ones_like(hashed)\n",
    "            sigmas = torch.zeros_like(hashed)\n",
    "            top_ks = repeat(hashed.clone().detach(), \"batch pixels levels verts 1 -> batch pixels levels verts k\", k=2)\n",
    "        else:\n",
    "            probs, hashed, sigmas, top_ks = (\n",
    "                self.HashFunction(grid_coords) \n",
    "                if self._should_use_all_levels \n",
    "                else \n",
    "                self._multiresolution_hash(grid_coords, min_possible_collisions)\n",
    "            )\n",
    "        del grid_coords\n",
    "\n",
    "        log((\"hashed:\", hashed, hashed.shape), self._should_log)\n",
    "        log((\"hashed grads:\", hashed.requires_grad, ), self._should_log)\n",
    "\n",
    "        log((\"probs:\", probs, probs.shape), self._should_log)\n",
    "        log((\"probs grads:\", probs.requires_grad, ), self._should_log)\n",
    "\n",
    "        log((\"sigmas:\", sigmas, sigmas.shape), self._should_log)\n",
    "        log((\"sigmas grads:\", sigmas.requires_grad, ), self._should_log)\n",
    "\n",
    "        log((\"top_ks:\", top_ks, top_ks.shape), self._should_log)\n",
    "\n",
    "        _, _, dummy_hashed = self._calc_dummies(hashed=hashed)\n",
    "\n",
    "        _, collisions = self._calc_hash_collisions(dummy_grids=dummy_grids, dummy_hashed=dummy_hashed)\n",
    "        del dummy_hashed\n",
    "\n",
    "        unique_probs, unique_hashed, unique_sigmas = self._calc_uniques(probs, hashed, sigmas, og_indices)\n",
    "        del og_indices\n",
    "\n",
    "        if should_calc_hists:\n",
    "            hists = self._hist_collisions(dummy_grids, unique_hashed, min_possible_collisions, should_show=False)\n",
    "        else:\n",
    "            hists = None\n",
    "        del dummy_grids#, sigmas\n",
    "\n",
    "        # return hashed, top_ks, coeffs, unique_hashed, unique_probs, unique_sigmas, collisions, min_possible_collisions, hists\n",
    "        return hashed, sigmas, coeffs, unique_hashed, unique_probs, unique_sigmas, collisions, min_possible_collisions, hists\n",
    "\n",
    "    def _multiresolution_hash(self, x: torch.Tensor, min_possible_collision: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Multiresolution hash function.\n",
    "        Calculates the hash of the input tensor only for levels with more than 0 min_possible_collisions.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor\n",
    "            Input tensor.\n",
    "        min_possible_collision : torch.Tensor\n",
    "            Minimum possible collisions.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Tuple[torch.Tensor, torch.Tensor, torch.Tensor]\n",
    "            Hashed tensor, probabilities and sigmas.\n",
    "        \"\"\"\n",
    "\n",
    "        # to prevent division by 0\n",
    "        sigmas_epsilon = 1e-10\n",
    "\n",
    "        hashed = torch.zeros((x.shape[0], x.shape[1], self._num_levels, self._input_dim**2, 1))\n",
    "        probs = torch.ones((x.shape[0], x.shape[1], self._num_levels, self._input_dim**2, 1))\n",
    "        sigmas = torch.zeros((x.shape[0], x.shape[1], self._num_levels, self._input_dim**2, 1)) + sigmas_epsilon\n",
    "        top_ks = torch.zeros((x.shape[0], x.shape[1], self._num_levels, self._input_dim**2, 2))\n",
    "\n",
    "        x_non_collisions_levels = x[:, :, min_possible_collision <= 0, :, :]\n",
    "\n",
    "        # TODO: check, input is ij so maybe (i + j * level)?\n",
    "        hashed_non_collisions_levels = (\n",
    "            (\n",
    "                (self._levels[:, :, min_possible_collision <= 0, :] + 1) \n",
    "                * \n",
    "                x_non_collisions_levels[:, :, :, :, 0]\n",
    "            ) \n",
    "            + \n",
    "            x_non_collisions_levels[:, :, :, :, 1]\n",
    "        )\n",
    "\n",
    "        log((\"Hashed indices of levels without collisions:\", hashed_non_collisions_levels, hashed_non_collisions_levels.shape), self._should_log)\n",
    "        hashed[:, :, min_possible_collision <= 0, :, :] = hashed_non_collisions_levels.unsqueeze(-1)\n",
    "        top_ks[:, :, min_possible_collision <= 0, :, 0] = hashed_non_collisions_levels.clone().detach()\n",
    "        top_ks[:, :, min_possible_collision <= 0, :, 1] = hashed_non_collisions_levels.clone().detach()\n",
    "\n",
    "        probs_collsions_levels, hashed_collisions_levels, sigmas_collisions_levels, top_ks_collisions_levels = self.HashFunction(x[:, :, min_possible_collision > 0, :, :])\n",
    "        probs[:, :, min_possible_collision > 0, :, :] = probs_collsions_levels\n",
    "        sigmas[:, :, min_possible_collision > 0, :, :] = sigmas_collisions_levels\n",
    "        hashed[:, :, min_possible_collision > 0, :, :] = hashed_collisions_levels\n",
    "        top_ks[:, :, min_possible_collision > 0, :, :] = top_ks_collisions_levels\n",
    "\n",
    "        del hashed_non_collisions_levels, probs_collsions_levels, hashed_collisions_levels, sigmas_collisions_levels\n",
    "\n",
    "        return probs, hashed, sigmas, top_ks\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _scale_to_grid(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, List[torch.Tensor]]:\n",
    "        \"\"\"\n",
    "        Scale coordinates to grid.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor\n",
    "            Original coordinates.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Tuple[torch.Tensor, torch.Tensor, List[torch.Tensor]\n",
    "            Scaled coordinates, grid coordinates and dummy grids.\n",
    "        \"\"\"\n",
    "\n",
    "        scaled_coords: torch.Tensor = x.float() * self._levels.float()\n",
    "        log((\"scaled_coords:\", scaled_coords, scaled_coords.shape), self._should_log)\n",
    "        log((\"scaled_coords grads:\", scaled_coords.requires_grad), self._should_log)\n",
    "\n",
    "        grid_coords: torch.Tensor = rearrange(\n",
    "            torch.add(\n",
    "                torch.floor(scaled_coords),\n",
    "                self._voxels_helper_hypercube\n",
    "            ),\n",
    "            \"batch pixels xyz levels verts -> batch pixels levels verts xyz\"\n",
    "        )\n",
    "\n",
    "        log((\"grid_coords:\", grid_coords, grid_coords.shape), self._should_log)\n",
    "        log((\"grid_coords grads:\", grid_coords.requires_grad), self._should_log)\n",
    "        \n",
    "        coeffs = self._calc_bilinear_coefficients(scaled_coords, grid_coords)\n",
    "\n",
    "        return _, grid_coords, coeffs\n",
    "\n",
    "    @torch.no_grad() #TODO Check if is correct\n",
    "    def _calc_bilinear_coefficients(self, scaled_coords: torch.Tensor, grid_coords: torch.Tensor) -> torch.Tensor:\n",
    "        log((\"SCALED COORDS:\", scaled_coords[0, :, :, 0, :], scaled_coords.shape), self._should_log)\n",
    "        log((\"GRID COORDS:\", grid_coords[0, :, 0, :, :], grid_coords.shape), self._should_log)\n",
    "\n",
    "        _as: torch.Tensor = grid_coords[:, :, :, 0, :].unsqueeze(-2)  # bottom-right vertices of cells\n",
    "        _ds: torch.Tensor = grid_coords[:, :, :, -1, :].unsqueeze(-2)  # top-left vertices of cells\n",
    "\n",
    "        log((\"_as:\", _as, _as.shape), self._should_log)\n",
    "        log((\"_ds:\", _ds, _ds.shape), self._should_log)\n",
    "\n",
    "        coeffs: torch.Tensor = torch.stack([\n",
    "            (_ds[:, :, :, :, 0] - scaled_coords[:, :, 0, :, :]) * (_ds[:, :, :, :, 1] - scaled_coords[:, :, 1, :, :]),  # (xd - x) * (yd - y)\n",
    "            (scaled_coords[:, :, 0, :, :] - _as[:, :, :, :, 0]) * (_ds[:, :, :, :, 1] - scaled_coords[:, :, 1, :, :]),  # (x - xa) * (yd - y)\n",
    "            (_ds[:, :, :, :, 0] - scaled_coords[:, :, 0, :, :]) * (scaled_coords[:, :, 1, :, :] - _as[:, :, :, :, 1]),  # (xd - x) * (y - ya)\n",
    "            (scaled_coords[:, :, 0, :, :] - _as[:, :, :, :, 0]) * (scaled_coords[:, :, 1, :, :] - _as[:, :, :, :, 1]),  # (x - xa) * (y - ya)\n",
    "        ], dim=-1).squeeze(-2).unsqueeze(2)#.to(device)\n",
    "        del _as\n",
    "        del _ds\n",
    "        log((\"COEFFS:\", coeffs, coeffs.shape), self._should_log)\n",
    "\n",
    "        return coeffs\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _calc_dummies(\n",
    "        self,\n",
    "        grid_coords: torch.Tensor | None = None,\n",
    "        hashed: torch.Tensor | None = None,\n",
    "    ) -> Tuple[List[torch.Tensor] | None, List[torch.Tensor] | None, List[torch.Tensor] | None]:\n",
    "        \"\"\"\n",
    "        Calculate dummies.\n",
    "        If grid_coords is None the dummy_grids won't be calculated.\n",
    "        If hashed is None the dummy_hashed won't be calculated.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        grid_coords : torch.Tensor or None, optional (default is None)\n",
    "            Grid coordinates.\n",
    "        hashed : torch.Tensor or None, optional (default is None)\n",
    "            Hashed grid coordinates.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Tuple[List[torch.Tensor] or None, List[torch.Tensor] or None, List[torch.Tensor] or None]\n",
    "            Dummy grids, original unique indices and dummy hashed .\n",
    "        \"\"\"\n",
    "\n",
    "        dummy_grids = None\n",
    "        og_indices = None\n",
    "        dummy_hashed = None\n",
    "\n",
    "        if grid_coords is not None:\n",
    "            dummy_grids: List[Tuple[torch.Tensor]] = [\n",
    "                # [\n",
    "                torch.unique(rearrange(grid_coords[0, :, l, :, :], \"pixels verts xyz -> (pixels verts) xyz\"), dim=0, return_inverse=True) # first dimension is 0 because images should have all same size\n",
    "                for l in range(self._num_levels)\n",
    "                # ] for b in range(grid_coords.shape[0])\n",
    "            ]\n",
    "\n",
    "            dummy_grids, dummy_grids_inverse_indices = zip(*dummy_grids)\n",
    "            log((\"dummy_grids:\", dummy_grids, [dummy_grids[l].shape for l in range(self._num_levels)]), self._should_log)\n",
    "            log((\"dummy_grids grads:\", [(dummy_grids[l].requires_grad, ) for l in range(self._num_levels)]), self._should_log)\n",
    "\n",
    "            og_indices = [\n",
    "                torch.tensor([np.where(dummy_grids_inverse_indices[l].detach().cpu().numpy() == i)[0][0] for i in range(len(dummy_grids[l]))])\n",
    "                for l in range(self._num_levels)\n",
    "            ]\n",
    "            log((\"og_indices:\", [(og_indices[l], og_indices[l].shape) for l in range(self._num_levels)]), self._should_log)\n",
    "            log((\"og_indices grads:\", [(og_indices[l].requires_grad, ) for l in range(self._num_levels)]), self._should_log)\n",
    "\n",
    "        if hashed is not None:\n",
    "            dummy_hashed: List[torch.Tensor] = [\n",
    "                # [\n",
    "                torch.unique(rearrange(hashed[0, :, l, :, :], \"pixels verts xyz -> (pixels verts) xyz\"), dim=0, return_inverse=False) # first dimension is 0 because images should have all same size\n",
    "                for l in range(self._num_levels)\n",
    "                # ] for b in range(hashed.shape[0])\n",
    "            ]\n",
    "            log((\"dummy_hashed:\", dummy_hashed, [dummy_hashed[l].shape for l in range(self._num_levels)]), self._should_log)\n",
    "            log((\"dummy_hashed grads:\", [(dummy_hashed[l].requires_grad, ) for l in range(self._num_levels)]), self._should_log)\n",
    "\n",
    "        return dummy_grids, og_indices, dummy_hashed \n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def _calc_hash_collisions(\n",
    "        self, \n",
    "        dummy_grids: List[torch.Tensor] , \n",
    "        dummy_hashed: List[torch.Tensor] | None = None\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Calculate hash collisions.\n",
    "        If dummy_hashed is None the min_possible_collision will be calculated while collisions won't.\n",
    "        If dummy_hashed is not None the min_possible_collision won't be calculated while collisions will.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        dummy_grid_coords : List[torch.Tensor]\n",
    "            Grid coordinates.\n",
    "        dummy_hashed : List[torch.Tensor] or None, optional (default is None)\n",
    "            Hashed grid coordinates.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Tuple[torch.Tensor or None, torch.Tensor or None]\n",
    "            Minimum possible collisions and actual collisions at each level.\n",
    "        \"\"\"\n",
    "\n",
    "        min_possible_collisions = None\n",
    "        collisions = None\n",
    "\n",
    "        if dummy_hashed is None:\n",
    "            min_possible_collisions: torch.Tensor = torch.stack([\n",
    "                torch.tensor((dummy_grids[l].shape[0]) - self._hash_table_size)\n",
    "                for l in range(self._num_levels)\n",
    "            ])\n",
    "            min_possible_collisions[min_possible_collisions < 0] = 0\n",
    "            log((\"min_possible_collisions:\", min_possible_collisions, min_possible_collisions.shape), self._should_log)\n",
    "            log((\"min_possible_collisions grads:\", min_possible_collisions.requires_grad), self._should_log)\n",
    "        else:\n",
    "            collisions: torch.Tensor = torch.stack([\n",
    "                # [\n",
    "                torch.tensor(float(dummy_grids[l].shape[0] - torch.unique(dummy_hashed[l], dim=0).shape[0]))#, requires_grad=True)\n",
    "                for l in range(self._num_levels)\n",
    "                # ] \n",
    "                # for b in range(hashed.shape[0])\n",
    "            ])\n",
    "            log((\"collisions:\", collisions, collisions.shape, collisions.dtype), self._should_log)\n",
    "            log((\"collisions grads:\", collisions.requires_grad, ), self._should_log)\n",
    "\n",
    "        return min_possible_collisions, collisions\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _calc_uniques(\n",
    "        self,\n",
    "        probs: torch.Tensor,\n",
    "        hashed: torch.Tensor,\n",
    "        sigmas: torch.Tensor,\n",
    "        og_indices: List[torch.Tensor]\n",
    "    ) -> Tuple[torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Calculate uniques.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        probs : torch.Tensor\n",
    "            Probabilities.\n",
    "        hashed : torch.Tensor\n",
    "            Hashed grid coordinates.\n",
    "        sigmas : torch.Tensor\n",
    "            Sigmas of hashed grid coordinates.\n",
    "        og_indices : List[torch.Tensor]\n",
    "            Original unique indices.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Tuple[torch.Tensor]\n",
    "            Unique probabilities, unique hashed, and unique_sigmas.\n",
    "        \"\"\"\n",
    "\n",
    "        unique_probs: List[torch.Tensor] = [\n",
    "            # [\n",
    "            F.softmax(rearrange(probs[0, :, l, :, :], \"pixels verts xyz -> (pixels verts) xyz\")[og_indices[l]], dim=0)\n",
    "            for l in range(self._num_levels)\n",
    "            # ]\n",
    "            # for b in range(probs.shape[0])\n",
    "        ]\n",
    "        log((\"unique_probs:\", [(unique_probs[b][l], unique_probs[b][l].shape) for l in range(self._num_levels) for b in range(probs.shape[0])]), self._should_log)\n",
    "        log((\"unique_probs:\", [(unique_probs[l], unique_probs[l].shape) for l in range(self._num_levels)]), self._should_log)\n",
    "\n",
    "        unique_hashed: List[torch.Tensor] = [\n",
    "            # [\n",
    "            rearrange(hashed[0, :, l, :, :], \"pixels verts xyz -> (pixels verts) xyz\")[og_indices[l]]\n",
    "            for l in range(self._num_levels)\n",
    "            # ]\n",
    "            # for b in range(probs.shape[0])\n",
    "        ]\n",
    "        log((\"unique_hashed:\", [(unique_hashed[b][l], unique_hashed[b][l].shape) for l in range(self._num_levels) for b in range(probs.shape[0])]), self._should_log)\n",
    "        log((\"unique_hashed:\", [(unique_hashed[l], unique_hashed[l].shape) for l in range(self._num_levels)]), self._should_log)\n",
    "\n",
    "        unique_sigmas: List[torch.Tensor] = [\n",
    "            # [\n",
    "            rearrange(sigmas[0, :, l, :, :], \"pixels verts xyz -> (pixels verts) xyz\")[og_indices[l]]\n",
    "            for l in range(self._num_levels)\n",
    "            # ]\n",
    "            # for b in range(probs.shape[0])\n",
    "        ]\n",
    "        log((\"unique_sigmas:\", [(unique_sigmas[b][l], unique_sigmas[b][l].shape) for l in range(self._num_levels) for b in range(probs.shape[0])]), self._should_log)\n",
    "        log((\"unique_sigmas:\", [(unique_sigmas[l], unique_sigmas[l].shape) for l in range(self._num_levels)]), self._should_log)\n",
    "\n",
    "\n",
    "        return unique_probs, unique_hashed, unique_sigmas\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _hist_collisions(\n",
    "        self,\n",
    "        dummy_grids: List[torch.Tensor],\n",
    "        dummy_hashed: List[torch.Tensor],\n",
    "        min_possible_collisions: torch.Tensor,\n",
    "        should_show: bool = False\n",
    "    ) -> List[plt.Figure]:\n",
    "        \"\"\"\n",
    "        Show collisions.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        dummy_grids : List[torch.Tensor]\n",
    "            Grid coordinates.\n",
    "        dummy_hashed : List[torch.Tensor]\n",
    "            Hashed grid coordinates.\n",
    "        min_possible_collisions : torch.Tensor\n",
    "            Minimum possible collisions for each level.\n",
    "        should_show : bool, optional (default is False)\n",
    "            Whether to show figure.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        List[plt.Figure]\n",
    "            Histograms of collisions, one per level.\n",
    "        \"\"\"\n",
    "\n",
    "        figs=[]\n",
    "\n",
    "        # for l in range(self._num_levels):\n",
    "        for l, min_collisions in enumerate(min_possible_collisions):\n",
    "\n",
    "            if (min_collisions <= 0) and not self._should_fast_hash:\n",
    "                figs.append(None)\n",
    "                continue\n",
    "\n",
    "            indices = dummy_hashed[l].detach().cpu().numpy()\n",
    "\n",
    "            fig, ax = plt.subplots(figsize=(15, 5))\n",
    "            ax.hist(\n",
    "                indices,\n",
    "                bins=self._hash_table_size,\n",
    "                range=(0, self._hash_table_size),\n",
    "                edgecolor='grey', \n",
    "                linewidth=0.5\n",
    "            )\n",
    "\n",
    "            ax.set_xlim(-1, self._hash_table_size)\n",
    "            ax.xaxis.set_ticks(np.arange(0, self._hash_table_size, 10))\n",
    "\n",
    "            start, end = ax.get_ylim()\n",
    "            step = int(end * 0.1)\n",
    "            ax.yaxis.set_ticks(np.arange(0, end, step if step > 0 else 1))\n",
    "\n",
    "            plt.title(f\"Level {l} ({int(self._levels[0, 0, l, 0].item())})\")\n",
    "            plt.xlabel(\"Hashed indices\")\n",
    "            plt.ylabel(\"Counts\")\n",
    "\n",
    "            figs.append(fig)\n",
    "\n",
    "            if should_show:\n",
    "                plt.show()\n",
    "            \n",
    "            plt.close()\n",
    "\n",
    "        return figs\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _fast_hash(self, grid: torch.Tensor) -> torch.Tensor:\n",
    "        '''\n",
    "        Implements the hash function proposed by NVIDIA.\n",
    "        Args:\n",
    "            grid: A tensor of the shape (batch, pixels, levels, 2^input_dim, input_dim).\n",
    "               This tensor should contain the vertices of the hyper cube\n",
    "               for each level.\n",
    "        Returns:\n",
    "            A tensor of the shape (batch, pixels, levels, 2^input_dim, 1) containing the\n",
    "            indices into the hash table for all vertices.\n",
    "        '''\n",
    "        tmp = torch.zeros(\n",
    "            (grid.shape[0], grid.shape[1], self._num_levels, 2**self._input_dim),\n",
    "            device=device\n",
    "        ).to(int)\n",
    "\n",
    "        for i in range(self._input_dim):\n",
    "            tmp = torch.bitwise_xor(\n",
    "                (grid[:, :, :, :, i].to(int) * self._prime_numbers[i]),\n",
    "                tmp\n",
    "            )\n",
    "\n",
    "        hash = torch.remainder(tmp, self._hash_table_size).unsqueeze(-1).float() # TODO: check if self._hash_table_size - 1 is correct\n",
    "        del tmp\n",
    "\n",
    "        return hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Neural Gauge Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneralNeuralGaugeFields(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        batch_size: int,\n",
    "        hidden_layers_widths: List[int],\n",
    "        MultiresolutionModel: nn.Module,\n",
    "        feature_dim: int = 2,\n",
    "        topk: int = 1,\n",
    "        num_levels: int = None,\n",
    "        hash_table_size: int = None,\n",
    "        should_circular_topk: bool = False,\n",
    "        should_bw: bool = False,\n",
    "        should_log: List = []\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        General Neural Gauge Fields module.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        batch_size : int\n",
    "            Batch size.\n",
    "        hidden_layers_widths : List[int]\n",
    "            List of hidden layers widths.\n",
    "        MultiresolutionModel : nn.Module\n",
    "            Multiresolution module.\n",
    "        feature_dim : int, optional (default is 2)\n",
    "            Feature dimension.\n",
    "        topk : int, optional (default is 1)\n",
    "            Lookup features top k.\n",
    "        num_levels : int, optional (default is None)\n",
    "            Number of levels. If None it will be taken from MultiresolutionModel.\n",
    "        hash_table_size : int, optional (default is None)\n",
    "            Hash table size. If None it will be taken from MultiresolutionModel.\n",
    "        should_circular_topk : bool, optional (default is False)\n",
    "            Whether to use circular topk or not.\n",
    "        should_bw : bool, optional (default is False)\n",
    "            Whether to output black and white images or not.\n",
    "        should_log : List, optional (default is [])\n",
    "            List of decoded functions to log.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        \n",
    "        super(GeneralNeuralGaugeFields, self).__init__()\n",
    "\n",
    "        self._batch_size: int = batch_size\n",
    "        self.MultiresolutionModel: nn.Module = MultiresolutionModel\n",
    "        self._hash_table_size: int = (\n",
    "            hash_table_size \n",
    "            if hash_table_size is not None \n",
    "            else \n",
    "            self.MultiresolutionModel._hash_table_size\n",
    "        )\n",
    "        self._num_levels: int = (\n",
    "            num_levels \n",
    "            if num_levels is not None \n",
    "            else \n",
    "            self.MultiresolutionModel._num_levels\n",
    "        )\n",
    "        self._feature_dim: int = feature_dim\n",
    "        self._topk = topk\n",
    "\n",
    "        self._should_circular_topk: bool = should_circular_topk\n",
    "        self._should_bw: bool = should_bw\n",
    "        self._should_log: int = should_log\n",
    "\n",
    "        self._hash_tables: torch.nn.ModuleList = torch.nn.ModuleList(\n",
    "            [\n",
    "                torch.nn.ModuleList([\n",
    "                    torch.nn.Embedding(self._hash_table_size, self._feature_dim, device=device)\n",
    "                    for _ in range(self._num_levels)\n",
    "                ])\n",
    "                for _ in range(self._batch_size)\n",
    "            ]\n",
    "        )\n",
    "        log((\"HASH TABLE level 0:\", self._hash_tables[0][0].weight, self._hash_tables[0][0].weight.shape), self._should_log)\n",
    "\n",
    "        self._apply_init(torch.nn.init.uniform_, -10.0**(-4), 10.0**(-4))\n",
    "        log((\"INITIALIZED HASH TABLE level 0:\", self._hash_tables[0][0].weight, self._hash_tables[0][0].weight.shape), self._should_log)\n",
    "        \n",
    "        layers_widths: List[int] = [(self._num_levels * self._feature_dim), *hidden_layers_widths, (3 if not self._should_bw else 1)]\n",
    "        self.mlp = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(in_features=layers_widths[i], out_features=layers_widths[i + 1]),\n",
    "                nn.ReLU() if (i < (len(layers_widths) - 2)) else nn.Sigmoid()\n",
    "            )\n",
    "            for i in range(len(layers_widths) - 1)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x: torch.Tensor, should_calc_hists: bool = False) -> Tuple[torch.Tensor]:\n",
    "        # hashed, top_ks, coeffs, unique_hashed, unique_probs, unique_sigmas, collisions, min_possible_collisions, hists = self.MultiresolutionModel(x, should_calc_hists=should_calc_hists)\n",
    "        hashed, sigmas, coeffs, unique_hashed, unique_probs, unique_sigmas, collisions, min_possible_collisions, hists = self.MultiresolutionModel(x, should_calc_hists=should_calc_hists)\n",
    "\n",
    "        looked_up: torch.Tensor = self._look_up(hashed, sigmas)\n",
    "\n",
    "        x: torch.Tensor = self._bilinear_interpolate(coeffs, looked_up)\n",
    "\n",
    "        for layer in self.mlp:\n",
    "            x = layer(x)\n",
    "\n",
    "        return x, hashed, unique_hashed, unique_probs, unique_sigmas, collisions, min_possible_collisions, hists\n",
    "\n",
    "    def _look_up(self, indices: torch.Tensor, sigmas: torch.Tensor) -> torch.Tensor:\n",
    "        log((\"indices:\", indices, indices.shape), self._should_log)\n",
    "        # batch, pixels, levels, verts, 1\n",
    "\n",
    "        topk = torch.arange(-(self._topk // 2), (self._topk // 2) + 1).float()\n",
    "        log((\"topk:\", topk, topk.shape), self._should_log, color=bcolors.FAIL)\n",
    "\n",
    "        new_indices = indices + topk\n",
    "\n",
    "        if self._should_circular_topk:\n",
    "            # CIRCULAR IMPLEMENTATION\n",
    "            new_indices = torch.remainder(new_indices, self._hash_table_size)\n",
    "        else:\n",
    "            # LINEAR IMPLEMENTATION\n",
    "            new_indices[new_indices < 0] = 0\n",
    "            new_indices[new_indices >= self._hash_table_size] = self._hash_table_size - 1\n",
    "        log((\"new_indices:\", new_indices, new_indices.shape), self._should_log)\n",
    "        \n",
    "        looked_up: torch.Tensor = rearrange(\n",
    "            torch.stack([ # (batch, levels, pixels, verts, k, features)\n",
    "                torch.stack([\n",
    "                    self._hash_tables[b][l](\n",
    "                        images[:, l, :, :].int() # TODO topk?\n",
    "                    )\n",
    "                    for l in range(self._num_levels)\n",
    "                ])\n",
    "                for b, images in enumerate(new_indices) # (batch, pixels, levels, verts, k)\n",
    "            ]),\n",
    "            \"batch levels pixels verts k features -> batch pixels levels features verts k\"\n",
    "        )\n",
    "        log((\"looked_up:\", looked_up, looked_up.shape), self._should_log)\n",
    "        # batch, pixels, levels, features, verts, k\n",
    "\n",
    "        log((\"sigmas:\", sigmas, sigmas.shape), self._should_log)\n",
    "\n",
    "        # Calculate the Gaussian probabilities\n",
    "        \n",
    "        # gaussian_probs = torch.exp(-(1/2) * ((topk - 0) / (sigmas))**2) / ((sigmas) * torch.sqrt(2 * torch.tensor(3.141592653589793)))\n",
    "        # log((\"gaussian_probs:\", gaussian_probs, gaussian_probs.shape), self._should_log, color=bcolors.WARNING)\n",
    "\n",
    "        gaussian_probs = (\n",
    "            torch.exp(-(1/2) * ((topk - 0) / (sigmas))**2) / ((sigmas) * torch.sqrt(2 * torch.tensor(np.pi)))\n",
    "        ).unsqueeze(3)\n",
    "        log((\"gaussian_probs:\", gaussian_probs, gaussian_probs.shape), self._should_log, color=bcolors.WARNING)\n",
    "\n",
    "        # (weighted avg) sum(looked_up * topk)/sum(topk)\n",
    "        looked_up = rearrange(\n",
    "            torch.sum(looked_up * gaussian_probs, dim=-1) / torch.sum(gaussian_probs, dim=-1),\n",
    "            \"batch pixels levels features verts -> batch pixels features levels verts\"\n",
    "        )\n",
    "\n",
    "        log((\"Weighted avg looked_up:\", looked_up, looked_up.shape), self._should_log)\n",
    "        # batch, pixels, features, levels, verts\n",
    "\n",
    "        return looked_up\n",
    "\n",
    "    def _bilinear_interpolate(self, coeffs: torch.Tensor, features: torch.Tensor) -> torch.Tensor:\n",
    "        log((\"COEFFS:\", coeffs, coeffs.shape), self._should_log)\n",
    "        log((\"FEATURES:\", features, features.shape), self._should_log)\n",
    "\n",
    "        weighted_features: torch.Tensor = features * coeffs\n",
    "        del coeffs\n",
    "        log((\"W_FEATURES:\", weighted_features, weighted_features.shape), self._should_log)\n",
    "\n",
    "        weighted_summed_features: torch.Tensor = torch.sum(weighted_features, dim=-1)#.to(device)\n",
    "        del weighted_features\n",
    "        log((\"W_S_FEATURES:\", weighted_summed_features, weighted_summed_features.shape), self._should_log)\n",
    "        \n",
    "        stack: torch.Tensor = rearrange(weighted_summed_features, \"batch pixels features levels -> batch pixels (levels features)\")#.to(device)\n",
    "        del weighted_summed_features\n",
    "        log((\"STACK:\", stack, stack.shape), self._should_log)\n",
    "\n",
    "        return stack\n",
    "\n",
    "    def _apply_init(self, init_func, *args) -> None:\n",
    "        \"\"\"\n",
    "        Initializes the hash tables weights with a random uniform function\n",
    "        \"\"\"\n",
    "        for b in range(self._batch_size):\n",
    "            for i in range(self._num_levels):\n",
    "                init_func(self._hash_tables[b][i].weight, *args)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics, Loss & Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(predicted: np.ndarray, target: np.ndarray, size: int) -> float:\n",
    "    return (np.equal(predicted, target).sum() / size) * 100\n",
    "\n",
    "def calc_psnr(pred: np.ndarray, target: np.ndarray) -> float:\n",
    "    mse = np.square(pred - target).mean()\n",
    "    return 20 * np.log10(np.max(target)) - 10 * np.log10(mse) # psne\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        delta: float = 1,\n",
    "        hash_table_size: int = 2**14,\n",
    "        kl_div_reduction: str = \"batchmean\",\n",
    "        should_kl_hist: bool = False,\n",
    "        should_diff_hist_optimized: bool = False,\n",
    "        should_use_all_levels: bool = False,\n",
    "        should_fast_hash: bool = False,\n",
    "        should_log: List = [],\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Loss module.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        delta : float, optional (default is 1)\n",
    "            Delta parameter for collision loss.\n",
    "        hash_table_size : int, optional (default is 2**14)\n",
    "            Hash table size.\n",
    "        kl_div_reduction : str, optional (default is \"batchmean\")\n",
    "            KL divergence reduction.\n",
    "        should_kl_hist : bool, optional (default is False)\n",
    "            Whether to calculate KL with histograms or not.\n",
    "        should_diff_hist_optimized: bool, optional (default is False)\n",
    "            Whether to use optimized differentiable histogram or not.\n",
    "        should_use_all_levels : bool, optional (default is False)\n",
    "            Whether to use all levels or only the ones with collisions.\n",
    "        should_fast_hash : bool, optional (default is False)\n",
    "            Whether to use fast hash or not.\n",
    "        should_log : List, optional (default is [])\n",
    "            List of decoded functions to log.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "\n",
    "        super(Loss, self).__init__()\n",
    "\n",
    "        self._delta = delta\n",
    "        self._hash_table_size = hash_table_size\n",
    "        self._should_kl_hist = should_kl_hist\n",
    "        self._should_diff_hist_optimized = should_diff_hist_optimized\n",
    "        self._should_use_all_levels = should_use_all_levels\n",
    "        self._should_fast_hash = should_fast_hash\n",
    "        self._should_log = should_log\n",
    "\n",
    "        self.kl_div_loss = nn.KLDivLoss(reduction=kl_div_reduction)\n",
    "        self.mse_loss = nn.MSELoss(reduction=\"mean\")\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        collisions: List,\n",
    "        min_possible_collisions: List,\n",
    "        x: List, # levels pixels (verts xyz) \n",
    "        sigmas: torch.Tensor,\n",
    "        predicted_images: torch.Tensor,\n",
    "        target_images: torch.Tensor,\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "\n",
    "        delta = min_possible_collisions.clone()\n",
    "        delta[delta <= 0] = self._delta\n",
    "    \n",
    "        collisions_losses: torch.Tensor = (collisions - min_possible_collisions) / delta\n",
    "        log((\"Collisions Losses:\", collisions_losses), self._should_log)\n",
    "        log((\"Collisions Losses grads:\", collisions_losses.requires_grad), self._should_log)\n",
    "\n",
    "        zero_bins_per_level = torch.zeros(min_possible_collisions.shape)\n",
    "        kl_div_losses = torch.zeros(x.shape[0])\n",
    "\n",
    "        for l, level in enumerate(x):\n",
    "            if not self._should_use_all_levels and min_possible_collisions[l] <= 0:\n",
    "                continue\n",
    "            \n",
    "            p, zero_bins = self._calc_hist_pdf(level)\n",
    "            zero_bins_per_level[l] = zero_bins\n",
    "\n",
    "            kl_div_losses[l] = self._kl_div(l, p)\n",
    "\n",
    "        log((\"KL Losses:\", kl_div_losses), self._should_log)\n",
    "\n",
    "        sigma_losses = torch.stack([\n",
    "            self.mse_loss(sigma, torch.zeros_like(sigma))\n",
    "            for sigma in sigmas\n",
    "        ])\n",
    "\n",
    "        images_loss = self.mse_loss(predicted_images, target_images)\n",
    "\n",
    "        return collisions_losses, kl_div_losses, sigma_losses, zero_bins_per_level, images_loss\n",
    "\n",
    "    def _calc_hist_pdf(\n",
    "        self,\n",
    "        x: torch.Tensor,\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Calculate histogram PDF.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor\n",
    "            Indices to which calculate histogram PDF.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Tuple[torch.Tensor, torch.Tensor]\n",
    "            Histogram PDF and count of zerobins.\n",
    "        \"\"\"\n",
    "        \n",
    "        log((f\"x: {x}, shape: {x.shape}, requires_grad: {x.requires_grad}\", ), self._should_log)\n",
    "\n",
    "        hist_p_nondiff = torch.histc(x, bins=self._hash_table_size, min=0, max=self._hash_table_size) # ? maybe max=(self._hash_table_size - 1)\n",
    "        log((f\"hist_p_nondiff: {hist_p_nondiff}, shape: {hist_p_nondiff.shape}, sum: {torch.sum(hist_p_nondiff)}, requires_grad: {hist_p_nondiff.requires_grad}\", ), self._should_log, color=bcolors.WARNING)\n",
    "\n",
    "        if self._should_diff_hist_optimized:\n",
    "            hist_p = torch.sum(histogram(x, bins=torch.torch.linspace(0, self._hash_table_size, self._hash_table_size), bandwidth=torch.tensor(0.5)), dim=0)\n",
    "        else:\n",
    "            hist_p = differentiable_histogram(x, bins=self._hash_table_size, min=0, max=self._hash_table_size).squeeze(0).squeeze(0)\n",
    "        log((f\"hist_p_diff   : {hist_p.long()}, shape: {hist_p.shape}, sum: {torch.sum(hist_p)}, requires_grad: {hist_p.requires_grad}\", ), self._should_log)\n",
    "\n",
    "        # assert torch.allclose(hist_p_nondiff, hist_p, atol=1), f\"hist_p_nondiff != hist_p: {(hist_p_nondiff - hist_p)}\"\n",
    "\n",
    "        p = hist_p / torch.sum(hist_p) #torch.prod(torch.tensor(x.shape))\n",
    "        log((f\"p: {p}, shape: {p.shape}, requires_grad: {p.requires_grad}\", ), self._should_log)\n",
    "\n",
    "        zero_bins = torch.sum(p == 0)\n",
    "        log((f\"zero_bins: {zero_bins}, shape: {zero_bins.shape}, requires_grad: {zero_bins.requires_grad}\", ), self._should_log)\n",
    "\n",
    "        p[p == 0] = 1e-10\n",
    "        # log((f\"after p: {p}, shape: {p.shape}, requires_grad: {p.requires_grad}\", ), self._should_log)\n",
    "\n",
    "        return p, zero_bins\n",
    "\n",
    "    def _kl_div(\n",
    "        self,\n",
    "        level: int,\n",
    "        p: torch.Tensor,\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Calculate KL divergence loss.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        level : int\n",
    "            Level.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            KL divergence loss.\n",
    "        \"\"\"\n",
    "\n",
    "        log((f\"p: {p}, shape: {p.shape}, requires_grad: {p.requires_grad}\", ), self._should_log)\n",
    "\n",
    "        if self._should_kl_hist:\n",
    "            q = torch.ones(self._hash_table_size) / self._hash_table_size\n",
    "        else:\n",
    "            # q = torch.ones(level) / level\n",
    "            q = torch.arange(level, dtype=torch.float32)\n",
    "            log((f\"before q: {q}, shape: {q.shape}, requires_grad: {q.requires_grad}\", ), self._should_log)\n",
    "\n",
    "            q = torch.softmax(q, dim=-1)\n",
    "\n",
    "        log((f\"after q: {q}, shape: {q.shape}, requires_grad: {q.requires_grad}\", ), self._should_log)\n",
    "\n",
    "        kl_div_loss = self.kl_div_loss(p.log(), q)\n",
    "\n",
    "        log((f\"kl_div_loss: {kl_div_loss}, shape: {kl_div_loss.shape}, requires_grad: {kl_div_loss.requires_grad}\", ), self._should_log, color=bcolors.OKGREEN)\n",
    "\n",
    "        return kl_div_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(\n",
    "    net: torch.nn.Module,\n",
    "    features_lr: float,\n",
    "    MLP_lr: float,\n",
    "    features_weight_decay: float,\n",
    "    MLP_weight_decay: float,\n",
    "    hash_lr: float = None,\n",
    "    hash_weight_decay: float = None,\n",
    "    betas: tuple = (0.9, 0.99),\n",
    "    eps: float = 1e-15\n",
    "):\n",
    "\n",
    "    params = [\n",
    "        {\"params\": net._hash_tables.parameters(), \"lr\": features_lr, \"weight_decay\": features_weight_decay},\n",
    "        {\"params\": net.mlp.parameters(), \"lr\": MLP_lr, \"weight_decay\": MLP_weight_decay}\n",
    "    ]\n",
    "\n",
    "    if net.MultiresolutionModel.HashFunction is not None:\n",
    "        params.append(\n",
    "            {\"params\": net.MultiresolutionModel.HashFunction.parameters(), \"lr\": hash_lr, \"weight_decay\": hash_weight_decay},\n",
    "        )\n",
    "\n",
    "    optimizer = torch.optim.Adam(\n",
    "        params,\n",
    "        betas=betas,\n",
    "        eps=eps,\n",
    "    )\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Test Loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(\n",
    "    x: torch.Tensor,\n",
    "    target: torch.Tensor,\n",
    "    h: int,\n",
    "    w: int,\n",
    "    model: nn.Module,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    loss_fn: nn.Module,\n",
    "    norm_regularization_order: int,\n",
    "    l_collisions: float,\n",
    "    l_kl_loss: float,\n",
    "    l_sigma_loss: float,\n",
    "    l_zero_bins: float,\n",
    "    l_l2_reg: float,\n",
    "    l_images_mse: float,\n",
    "    gradient_clip: float = None,\n",
    "    should_calc_hists: bool = False,\n",
    "    should_kl_hist: bool = False,\n",
    "    should_log: List = [],\n",
    "    excluded_params_from_l2_reg: np.ndarray[str] = np.array([\"_prime_numbers\", \"_hash_tables\"])\n",
    ") -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, List[plt.Figure], torch.Tensor, torch.Tensor, float]:\n",
    "    \"\"\"\n",
    "    Train loop.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : torch.Tensor\n",
    "        Train input data.\n",
    "    target : torch.Tensor\n",
    "        Target data.\n",
    "    h : int\n",
    "        Height of images.\n",
    "    w : int\n",
    "        Width of images.\n",
    "    model : nn.Module\n",
    "        Model to train.\n",
    "    optimizer : torch.optim.Optimizer\n",
    "        Optimizer.\n",
    "    loss_fn : nn.Module\n",
    "        Loss function.\n",
    "    norm_regularization_order : int\n",
    "        Norm regularization order.\n",
    "    l_collisions : float\n",
    "        Collisions loss lambda.\n",
    "    l_kl_loss : float\n",
    "        KL loss lambda.\n",
    "    l_sigma_loss : float\n",
    "        Sigma loss lambda.\n",
    "    l_zero_bins : float\n",
    "        Zero bins loss lambda.\n",
    "    l_l2_reg : float, optional (default is 0)\n",
    "        L2 regularization lambda.\n",
    "    l_images_mse : float\n",
    "        Images MSE loss lambda.\n",
    "    gradient_clip : float, optional (default is None)\n",
    "        Gradient clip value.\n",
    "    should_calc_hists : bool, optional (default is False)\n",
    "        Whether to calculate histograms or not.\n",
    "    should_kl_hist : bool, optional (default is False)\n",
    "        Whether to calculate KL with histograms or not.\n",
    "    should_log : List, optional (default is [])\n",
    "        - 1: Log\n",
    "        - 2: Log and plot.\n",
    "    excluded_params_from_l2_reg : np.ndarray[str], optional (default is np.array([\"_prime_numbers\", \"_hash_tables\"]))\n",
    "        Excluded parameters from L2 regularization.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[np.ndarray, np.ndarray, List, torch.Tensor, torch.Tensor, List[plt.Figure], torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, float, float, float]\n",
    "        Predicted images, target images, images PSNR, collisions, minimum possible collisions, histograms, collisions losses, KL losses, sigma loss, zero bins per level, l2_reg loss, images loss loss.\n",
    "    \"\"\"\n",
    "    log((\"Train loop\", ), should_log, color=bcolors.WARNING)\n",
    "    \n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    out, indices, unique_hashed, unique_probs, unique_sigmas, collisions, min_possible_collisions, hists = model(\n",
    "        x, \n",
    "        should_calc_hists=should_calc_hists \n",
    "    )\n",
    "\n",
    "    log((\"Out\", out, out.shape), should_log)\n",
    "\n",
    "    # print(\"indices shape:\", indices.shape)\n",
    "\n",
    "    # print(f\"Unique hashed: {[unique_hashed[l].shape for l in range(len(unique_hashed))]}\")\n",
    "\n",
    "    # print(f\"Softmax Unique hashed: {torch.softmax(unique_hashed[0].squeeze(-1), dim=-1), unique_hashed[0].shape}\")\n",
    "\n",
    "    # print(f\"Unique probs: {unique_probs[0], unique_probs[0].shape}\")\n",
    "\n",
    "    # print(\"indices\", indices)\n",
    "\n",
    "    collisions_losses, kl_div_losses, sigma_losses, zero_bins_per_level, images_loss = loss_fn(\n",
    "        collisions, \n",
    "        min_possible_collisions, \n",
    "        unique_probs if not should_kl_hist else rearrange(indices, \"batch pixels levels verts xyz -> batch levels pixels (verts xyz)\")[0], #unique_hashed,  \n",
    "        unique_sigmas,\n",
    "        out,\n",
    "        target\n",
    "    )\n",
    "\n",
    "    # L2 regularization\n",
    "    l2_reg_loss = torch.tensor(0.0)\n",
    "    for name, param in model.named_parameters():\n",
    "        if np.sum(np.isin(np.array(name.split('.')), excluded_params_from_l2_reg)) == 0:\n",
    "            l2_reg_loss += torch.linalg.norm(param, ord=norm_regularization_order)\n",
    "\n",
    "    collisions_loss = torch.sum(collisions_losses)\n",
    "    kl_loss = kl_div_losses.sum()\n",
    "    sigma_loss = sigma_losses.sum()\n",
    "    zero_bins_loss = zero_bins_per_level.sum()\n",
    "\n",
    "    loss = (\n",
    "        (l_collisions * collisions_loss) \n",
    "        + (l_kl_loss * kl_loss) \n",
    "        + (l_sigma_loss * sigma_loss) \n",
    "        + (l_zero_bins * zero_bins_loss)\n",
    "        + (l_l2_reg * l2_reg_loss)\n",
    "        + (l_images_mse * images_loss)\n",
    "    )\n",
    "\n",
    "    log((\"Loss grads:\", loss.requires_grad, ), should_log, color=bcolors.HEADER)\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    # output gradients .grad\n",
    "\n",
    "\n",
    "    if gradient_clip is not None:\n",
    "        torch.nn.utils.clip_grad_norm_(model.MultiresolutionModel.HashFunction.parameters(), gradient_clip)\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    output_images = (out * 255).reshape(-1, h, w, 3).to(int).detach().cpu().numpy()\n",
    "    target_images = (target * 255).reshape(-1, h, w, 3).to(int).detach().cpu().numpy()\n",
    "\n",
    "    plot_images(output_images, target_images, should_log)\n",
    "\n",
    "    images_psnr = [calc_psnr(output_images[i], target_images[i]) for i in range(output_images.shape[0])]\n",
    "    \n",
    "    return output_images, target_images, images_psnr, collisions, min_possible_collisions, hists, collisions_losses, kl_div_losses, sigma_losses, zero_bins_per_level, l2_reg_loss.item(), images_loss.item(), loss.item()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(\n",
    "    x: torch.Tensor,\n",
    "    target: torch.Tensor,\n",
    "    h: int,\n",
    "    w: int,\n",
    "    model: nn.Module,\n",
    "    loss_fn: nn.Module,\n",
    "    norm_regularization_order: int,\n",
    "    l_collisions: float,\n",
    "    l_kl_loss: float,\n",
    "    l_sigma_loss: float,\n",
    "    l_zero_bins: float,\n",
    "    l_l2_reg: float,\n",
    "    l_images_mse: float,\n",
    "    should_calc_hists: bool = False,\n",
    "    should_kl_hist: bool = False,\n",
    "    should_log: List = [],\n",
    "    excluded_params_from_l2_reg: np.ndarray[str] = np.array([\"_prime_numbers\", \"_hash_tables\"])\n",
    ") -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, List[plt.Figure], torch.Tensor, torch.Tensor, float]:\n",
    "    \"\"\"\n",
    "    Test loop.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : torch.Tensor\n",
    "        Test input data.\n",
    "    target : torch.Tensor\n",
    "        Target data.\n",
    "    h : int\n",
    "        Height of images.\n",
    "    w : int\n",
    "        Width of images.\n",
    "    model : nn.Module\n",
    "        Model to test.\n",
    "    loss_fn : nn.Module\n",
    "        Loss function.\n",
    "    norm_regularization_order : int\n",
    "        Norm regularization order.\n",
    "    l_collisions : float\n",
    "        Collisions loss lambda.\n",
    "    l_kl_loss : float\n",
    "        KL loss lambda.\n",
    "    l_sigma_loss : float\n",
    "        Sigma loss lambda.\n",
    "    l_zero_bins : float\n",
    "        Zero bins loss lambda.\n",
    "    l_l2_reg : float, optional (default is 0)\n",
    "        L2 regularization lambda.\n",
    "    l_images_mse : float\n",
    "        Images MSE loss lambda.\n",
    "    should_calc_hists : bool, optional (default is False)\n",
    "        Whether to calculate histograms or not.\n",
    "    should_kl_hist : bool, optional (default is False)\n",
    "        Whether to calculate KL with histograms or not.\n",
    "    should_log : List, optional (default is [])\n",
    "        - 1: Log\n",
    "        - 2: Plot.\n",
    "    excluded_params_from_l2_reg : np.ndarray[str], optional (default is np.array([\"_prime_numbers\", \"_hash_tables\"]))\n",
    "        Excluded parameters from L2 regularization.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[np.ndarray, np.ndarray, List, torch.Tensor, torch.Tensor, List[plt.Figure], torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, float, float, float]\n",
    "        Predicted images, target images, images PSNR, collisions, minimum possible collisions, histograms, collisions losses, KL losses, sigma loss, zero bins per level, l2_reg loss, images loss, loss.\n",
    "    \"\"\"\n",
    "    log((\"Test loop\", ), should_log, color=bcolors.FAIL)\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    out, indices, unique_hashed, unique_probs, unique_sigmas, collisions, min_possible_collisions, hists = model(\n",
    "        x, \n",
    "        should_calc_hists=should_calc_hists \n",
    "    )\n",
    "\n",
    "    collisions_losses, kl_div_losses, sigma_losses, zero_bins_per_level, images_loss = loss_fn(\n",
    "        collisions, \n",
    "        min_possible_collisions, \n",
    "        unique_probs if not should_kl_hist else rearrange(indices, \"batch pixels levels verts xyz -> batch levels pixels (verts xyz)\")[0], #unique_hashed, \n",
    "        unique_sigmas,\n",
    "        out,\n",
    "        target\n",
    "    )\n",
    "\n",
    "    # L2 regularization\n",
    "    l2_reg_loss = torch.tensor(0.0)\n",
    "    for name, param in model.named_parameters():\n",
    "        if np.sum(np.isin(np.array(name.split('.')), excluded_params_from_l2_reg)) == 0:\n",
    "            l2_reg_loss += torch.linalg.norm(param, ord=norm_regularization_order)\n",
    "\n",
    "    collisions_loss = torch.sum(collisions_losses)\n",
    "    kl_loss = kl_div_losses.sum()\n",
    "    sigma_loss = sigma_losses.sum()\n",
    "    zero_bins_loss = zero_bins_per_level.sum()\n",
    "\n",
    "    loss = (\n",
    "        (l_collisions * collisions_loss) \n",
    "        + (l_kl_loss * kl_loss) \n",
    "        + (l_sigma_loss * sigma_loss) \n",
    "        + (l_zero_bins * zero_bins_loss)\n",
    "        + (l_l2_reg * l2_reg_loss)\n",
    "        + (l_images_mse * images_loss)\n",
    "    )\n",
    "\n",
    "    output_images = (out * 255).reshape(-1, h, w, 3).to(int).detach().cpu().numpy()\n",
    "    target_images = (target * 255).reshape(-1, h, w, 3).to(int).detach().cpu().numpy()\n",
    "\n",
    "    plot_images(output_images, target_images, should_log)\n",
    "\n",
    "    images_psnr = [calc_psnr(output_images[i], target_images[i]) for i in range(output_images.shape[0])]\n",
    "\n",
    "    return output_images, target_images, images_psnr, collisions, min_possible_collisions, hists, collisions_losses, kl_div_losses, sigma_losses, zero_bins_per_level, l2_reg_loss.item(), images_loss.item(), loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early stopper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopper:\n",
    "    def __init__(self, tolerance: int = 5, min_delta: int = 0, should_reset: bool = True):\n",
    "        self.tolerance: int = tolerance\n",
    "        self.min_delta: int = min_delta\n",
    "        self.best_loss: float = np.inf\n",
    "        self.counter: int = 0\n",
    "        self.early_stop: bool = False\n",
    "        self._should_reset: bool = should_reset\n",
    "\n",
    "    def __call__(self, loss):\n",
    "        # print(f\"best_loss: {self.best_loss}, loss: {loss}, counter: {self.counter}\")\n",
    "\n",
    "        if abs(self.best_loss - loss) < self.min_delta and (loss < self.best_loss):\n",
    "            # print(\"Stall\")\n",
    "            self.counter += 1\n",
    "        elif abs(self.best_loss - loss) > self.min_delta and (loss > self.best_loss):\n",
    "            # print(\"Growing\")\n",
    "            self.counter += 1\n",
    "        else:\n",
    "            if not self._should_reset:\n",
    "                if self.counter <= 0:\n",
    "                    self.counter = 0\n",
    "                else:\n",
    "                    self.counter -= 1\n",
    "            else:\n",
    "                self.counter = 0\n",
    "                self.best_loss = loss\n",
    "\n",
    "        if self.counter >= self.tolerance:\n",
    "            self.early_stop = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN: 20240112111403\n"
     ]
    }
   ],
   "source": [
    "root_dir = \"./images\"\n",
    "test_size = 0.2\n",
    "\n",
    "train_images, test_images = train_test_split(\n",
    "    [\n",
    "        file for file in os.listdir(root_dir) if (\"silhouette\" in file) and (file.endswith(\".jpg\") or file.endswith(\".png\") or file.endswith(\".jpeg\"))\n",
    "    ], \n",
    "    test_size=test_size, \n",
    "    random_state=65535#random_seed\n",
    ")\n",
    "\n",
    "train_images = [\"macaw2.jpg\"]\n",
    "\n",
    "wandb_entity = \"fedemonti00\"\n",
    "wandb_project = \"project_course\"\n",
    "# wandb_name = \"hash_function_training\"\n",
    "\n",
    "try:\n",
    "    time = wandb_name\n",
    "except NameError:\n",
    "    time = (datetime.now(ZoneInfo(\"Europe/Rome\"))).strftime(\"%Y%m%d%H%M%S\")\n",
    "print(\"RUN:\", time)\n",
    "\n",
    "histogram_rate = 10\n",
    "\n",
    "scheduler = None # None, StepLR or CosineAnnealingLR or CosineAnnealingWarmRestarts\n",
    "should_fast_hash = False\n",
    "\n",
    "hyperparameters = {\n",
    "    \"train_images\": train_images,\n",
    "    \"hash_table_size\": 2**8,\n",
    "    \"n_min\": 8,\n",
    "    \"n_max\": 32,\n",
    "    \"num_levels\": 4,\n",
    "    \"output_dim\": 2,\n",
    "    \"feature_dim\": 2,\n",
    "    \"topk\": 5, # must be odd\n",
    "    \"hash_function_hidden_layers_widths\": [8, 32, 8],\n",
    "    \"gngf_hidden_layers_widths\": [64, 64],\n",
    "    \"hash_function_hidden_layers_activations\": nn.Tanh() if not should_fast_hash else None,\n",
    "    \"features_lr\": 1e-3,\n",
    "    \"features_weight_decay\": 0,\n",
    "    \"hash_lr\": 1e-3 if not should_fast_hash else None,\n",
    "    \"hash_weight_decay\": 1e-6 if not should_fast_hash else None,\n",
    "    \"MLP_lr\": 1e-2,\n",
    "    \"MLP_weight_decay\": 1e-6,\n",
    "    \"sigma_scale\": 1 if not should_fast_hash else None,\n",
    "    \"kl_div_reduction\": \"sum\", # \"batchmean\" or \"sum\"\n",
    "    \"norm_regularization_order\": 2,\n",
    "    \"kl_hist_loss\": True,\n",
    "    \"differentiable_histogram_optimized\": False,\n",
    "    \"should_dropout_hash_function\": False if not should_fast_hash else False,\n",
    "    \"should_fast_hash\": should_fast_hash,\n",
    "    \"should_use_all_levels\": False if not should_fast_hash else True, # !! should be true if NOT using kl_hist_loss !!\n",
    "    \"should_random_permute_input\": False,\n",
    "    \"should_normalize_levels\": False,\n",
    "    \"should_bw\": False,\n",
    "    \"should_circular_topk\": True,\n",
    "    \"should_xavier_initialization\": None if not should_fast_hash else None, # \"uniform\", \"normal\" or None\n",
    "    \"lambdas_decay\": -1, # -1 to disable\n",
    "    \"scheduler\": scheduler,\n",
    "    \"scheduler_gamma\": None if not scheduler else (0.9 if scheduler == \"StepLR\" else 1e-4),\n",
    "    \"l_collisions\": 0 if not should_fast_hash else 0, # !! not useful, not differentiable\n",
    "    \"l_kl_loss\": 1 if not should_fast_hash else 0, # 1e2\n",
    "    \"l_sigma_loss\": 1e1 if not should_fast_hash else 0,\n",
    "    \"l_zero_bins\": 0 if not should_fast_hash else 0, # !! not useful, not differentiable\n",
    "    \"l_l2_reg\": 1e-1 if not should_fast_hash else 0, # 1e-1\n",
    "    \"l_images_mse\": 1e2,\n",
    "    \"exclude_params_from_l2_reg\": np.array([\"_prime_numbers\", \"_hash_tables\"]),\n",
    "    \"gradient_clipping\": None, # None to disable or int\n",
    "    \"epochs\": 3000,\n",
    "    # \"epochs\": 999,\n",
    "    # \"epochs\": 1,\n",
    "    \"random_seed\": random_seed,\n",
    "}\n",
    "\n",
    "early_stopper_tolerance = 100 # hyperparameters[\"epochs\"] // 4\n",
    "early_stopper_min_delta = 1e-4 # 1e-6 \n",
    "\n",
    "should_log = False\n",
    "# should_log = True\n",
    "should_wandb = True if hyperparameters[\"epochs\"] > 999 else False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xavier Weights Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xavier_init_weights(model: nn.Module):\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "            # Applying Xavier initialization to linear and convolutional layers\n",
    "            if hyperparameters[\"should_xavier_initialization\"] == \"uniform\":\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "            elif hyperparameters[\"should_xavier_initialization\"] == \"normal\":\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfedemonti00\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/federicomontagna/collision_handling_in_instantNGP/wandb/run-20240112_111404-06niae06</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/fedemonti00/project_course/runs/06niae06' target=\"_blank\">20240112111403</a></strong> to <a href='https://wandb.ai/fedemonti00/project_course' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/fedemonti00/project_course' target=\"_blank\">https://wandb.ai/fedemonti00/project_course</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/fedemonti00/project_course/runs/06niae06' target=\"_blank\">https://wandb.ai/fedemonti00/project_course/runs/06niae06</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if should_wandb:\n",
    "    # start a new wandb run to track this script\n",
    "    wandb.init(\n",
    "        entity = wandb_entity,\n",
    "        # set the wandb project where this run will be logged\n",
    "        project = wandb_project,\n",
    "\n",
    "        name = time,\n",
    "\n",
    "        # track hyperparameters and run metadata\n",
    "        config = hyperparameters,\n",
    "        # config = {\n",
    "        #     \"id_grid_search_params\":        id_param,\n",
    "        #     \"grid_search_params\":           params,\n",
    "        #     \"random_seed\":                  random_seed,\n",
    "        #     \"HPD_learning_rate\":            HPD_lr,\n",
    "        #     \"encoding_learning_rate\":       encoding_lr,\n",
    "        #     \"MLP_learning_rate\":            MLP_lr,\n",
    "        #     \"encoding_weight_decay\":        encoding_weight_decay,\n",
    "        #     \"HPD_weight_decay\":             HPD_weight_decay,\n",
    "        #     \"MLP_weight_decay\":             MLP_weight_decay,\n",
    "        #     \"batch_size%\":                  batch_size,\n",
    "        #     \"shuffled_pixels\":              should_shuffle_pixels,\n",
    "        #     \"normalized_data\":              True if not should_batchnorm_data else \"BatchNorm1d\",\n",
    "        #     \"architecture\":                 \"GeneralNeuralGaugeFields\",\n",
    "        #     \"dataset\":                      image_name,\n",
    "        #     \"epochs\":                       epochs,\n",
    "        #     \"color\":                        'RGB' if not should_bw else 'BW',\n",
    "        #     \"hash_table_size\":              hash_table_size,\n",
    "        #     \"num_levels\":                   num_levels,\n",
    "        #     \"n_min\":                        n_min,\n",
    "        #     \"n_max\":                        n_max,\n",
    "        #     \"MLP_hidden_layers_widths\":     str(MLP_hidden_layers_widths),\n",
    "        #     \"HPD_hidden_layers_widths\":     str(HPD_hidden_layers_widths),\n",
    "        #     \"HPD_out_features\":             HPD_out_features,\n",
    "        #     \"feature_dim\":                  feature_dim,\n",
    "        #     \"topk_k\":                       topk_k,\n",
    "        #     \"loss_type\":                    \"JS+KLDiv\" if should_sum_js_kl_div else (\"KLDiv\" if not should_js_div else \"JSDiv\"),\n",
    "        #     \"loss_lambda_MSE\":              l_mse,\n",
    "        #     \"loss_lambda_JS_KL\":            l_js_kl,\n",
    "        #     \"loss_lambda_collisions\":       l_collisions,\n",
    "        #     \"loss_gamma\":                   loss_gamma,\n",
    "        #     \"loss_epsilon\":                 loss_epsilon,\n",
    "        #     \"inplace_scatter\":              should_inplace_scatter,\n",
    "        #     \"MLP_activations\":              \"LeakyReLU\" if should_leaky_relu else \"ReLU\",\n",
    "        #     \"collisions_loss_probs\":        \"topk_only\" if should_keep_topk_only else \"hash_table_size\",\n",
    "        #     \"avg_topk_features\":            \"softmax_avg\" if should_softmax_topk_features else (\"weighted_avg\" if should_softmax_topk_features != None else None),\n",
    "        #     \"hash_type\":                    \"HPD\" if not should_use_hash_function else \"hash_function\"\n",
    "        # }\n",
    "\n",
    "        save_code = False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wandb_log(\n",
    "    e: int,\n",
    "    lr: float,\n",
    "    l_zero_bins: float,\n",
    "    l_kl_loss: float,\n",
    "    train: Tuple = None,\n",
    "    test: Tuple = None,\n",
    "    fast_hash: Tuple = None,\n",
    "    should_log_hists: bool = False\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Log to wandb.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    e : int\n",
    "        Epoch.\n",
    "    lr : float\n",
    "        Learning rate modified by the scheduler.\n",
    "    l_zero_bins : float\n",
    "        Zero bins loss lambda.\n",
    "    l_kl_loss : float\n",
    "        KL loss lambda.\n",
    "    # train_loss : float\n",
    "    #     Train loss.\n",
    "    # train_collisions : torch.Tensor\n",
    "    #     Train collisions.\n",
    "    # train_min_possible_collisions : torch.Tensor\n",
    "    #     Train minimum possible collisions.\n",
    "    # train_collisions_losses : torch.Tensor\n",
    "    #     Train collisions losses.\n",
    "    # train_kl_losses : torch.Tensor\n",
    "    #     Train KL losses.\n",
    "    # train_sigma_losses : torch.Tensor\n",
    "    #     Train sigma losses.\n",
    "    # train_l2_reg_loss : float\n",
    "    #     Train L2 regularization loss.\n",
    "    # train_zero_bins : torch.Tensor\n",
    "    #     Train zero bins.\n",
    "    # train_hists : List[plt.Figure]\n",
    "    #     Train histograms.\n",
    "    # test_loss : float\n",
    "    #     Test loss.\n",
    "    # test_collisions : torch.Tensor\n",
    "    #     Test collisions.\n",
    "    # test_min_possible_collisions : torch.Tensor\n",
    "    #     Test minimum possible collisions.\n",
    "    # test_collisions_losses : torch.Tensor\n",
    "    #     Test collisions losses.\n",
    "    # test_kl_losses : torch.Tensor\n",
    "    #     Test KL losses.\n",
    "    # test_sigma_losses : torch.Tensor\n",
    "    #     Test sigma losses.\n",
    "    # test_l2_reg_loss : float\n",
    "    #     Test L2 regularization loss.\n",
    "    # test_zero_bins : torch.Tensor\n",
    "    #     Test zero bins.\n",
    "    # test_hists : List[plt.Figure]\n",
    "    #     Test histograms.\n",
    "    should_log_hists : bool, optional (default is False)\n",
    "        Whether to log histograms or not.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    log = {}\n",
    "\n",
    "    if hyperparameters[\"lambdas_decay\"] > -1:\n",
    "        log[\"l_zero_bins\"] = l_zero_bins\n",
    "        log[\"l_kl_loss\"] = l_kl_loss\n",
    "\n",
    "    if hyperparameters[\"scheduler\"] is not None:\n",
    "        log[\"lr\"] = lr\n",
    "\n",
    "    if fast_hash is not None:\n",
    "        fast_hash_pred_images, fast_hash_target_images, fast_hash_images_psnr, fast_hash_collisions, fast_hash_min_possible_collisions, fast_hash_hists, fast_hash_collisions_losses, fast_hash_kl_losses, fast_hash_sigma_losses, fast_hash_zero_bins, fast_hash_l2_reg_loss, fast_hash_images_loss, fast_hash_loss = fast_hash\n",
    "        log[\"fast_hash/loss\"] = fast_hash_loss\n",
    "        log[\"fast_hash/l2_reg_loss\"] = fast_hash_l2_reg_loss\n",
    "        log[\"fast_hash/images_loss\"] = fast_hash_images_loss\n",
    "        \n",
    "        for l in range(hyperparameters[\"num_levels\"]):\n",
    "            log[f\"fast_hash/collisions_level_{l}\"] = fast_hash_collisions[l].item()\n",
    "            log[f\"fast_hash/min_possible_collisions_level_{l}\"] = fast_hash_min_possible_collisions[l].item()\n",
    "            log[f\"fast_hash/collisions_loss_level_{l}\"] = fast_hash_collisions_losses[l].item()\n",
    "            log[f\"fast_hash/kl_loss_level_{l}\"] = fast_hash_kl_losses[l].item()\n",
    "            log[f\"fast_hash/sigma_loss_level_{l}\"] = fast_hash_sigma_losses[l].item()\n",
    "            log[f\"fast_hash/zero_bins_level_{l}\"] = fast_hash_zero_bins[l].item()\n",
    "        \n",
    "            if should_log_hists and fast_hash_hists[l] is not None:\n",
    "                log[f\"fast_hash/media/hist_counts_level_{l}\"] = wandb.Image(\n",
    "                    fast_hash_hists[l],\n",
    "                    caption=f\"Hashed indices counts at level {l} at epoch {e}\"\n",
    "                )\n",
    "        \n",
    "        for i in range(fast_hash_pred_images.shape[0]):\n",
    "            log[f\"fast_hash/media/pred_image_{i}\"] = wandb.Image(\n",
    "                fast_hash_pred_images[i],\n",
    "                caption=f\"Predicted image {i} at epoch {e}\"\n",
    "            )\n",
    "            log[f\"fast_hash/media/target_image_{i}\"] = wandb.Image(\n",
    "                fast_hash_target_images[i],\n",
    "                caption=f\"Target image {i} at epoch {e}\"\n",
    "            )\n",
    "            log[f\"fast_hash/psnr_image_{i}\"] = fast_hash_images_psnr[i]\n",
    "    \n",
    "    if train is not None:\n",
    "        train_pred_images, train_target_images, train_images_psnr, train_collisions, train_min_possible_collisions, train_hists, train_collisions_losses, train_kl_losses, train_sigma_losses, train_zero_bins, train_l2_reg_loss, train_images_loss, train_loss = train\n",
    "\n",
    "        log[\"train/loss\"] = train_loss\n",
    "        log[\"train/l2_reg_loss\"] = train_l2_reg_loss\n",
    "        log[\"train/images_loss\"] = train_images_loss\n",
    "\n",
    "        for l in range(hyperparameters[\"num_levels\"]):\n",
    "            log[f\"train/collisions_level_{l}\"] = train_collisions[l].item()\n",
    "            log[f\"train/min_possible_collisions_level_{l}\"] = train_min_possible_collisions[l].item()\n",
    "            log[f\"train/collisions_loss_level_{l}\"] = train_collisions_losses[l].item()\n",
    "            log[f\"train/kl_loss_level_{l}\"] = train_kl_losses[l].item()\n",
    "            log[f\"train/sigma_loss_level_{l}\"] = train_sigma_losses[l].item()\n",
    "            log[f\"train/zero_bins_level_{l}\"] = train_zero_bins[l].item()\n",
    "            \n",
    "            if should_log_hists and train_hists[l] is not None:\n",
    "                log[f\"train/media/hist_counts_level_{l}\"] = wandb.Image(\n",
    "                    train_hists[l],\n",
    "                    caption=f\"Hashed indices counts at level {l} at epoch {e}\"\n",
    "                )\n",
    "\n",
    "        for i in range(train_pred_images.shape[0]):\n",
    "            log[f\"train/media/pred_image_{i}\"] = wandb.Image(\n",
    "                train_pred_images[i],\n",
    "                caption=f\"Predicted image {i} at epoch {e}\"\n",
    "            )\n",
    "            log[f\"train/media/target_image_{i}\"] = wandb.Image(\n",
    "                train_target_images[i],\n",
    "                caption=f\"Target image {i} at epoch {e}\"\n",
    "            )\n",
    "            log[f\"train/psnr_image_{i}\"] = train_images_psnr[i]\n",
    "\n",
    "    if test is not None:\n",
    "        test_pred_images, test_target_images, test_images_psnr, test_collisions, test_min_possible_collisions, test_hists, test_collisions_losses, test_kl_losses, test_sigma_losses, test_zero_bins, test_l2_reg_loss, test_images_loss, test_loss = test\n",
    "\n",
    "        log[\"test/loss\"] = test_loss\n",
    "        log[\"test/l2_reg_loss\"] = test_l2_reg_loss\n",
    "        log[\"test/images_loss\"] = test_images_loss\n",
    "\n",
    "        for l in range(hyperparameters[\"num_levels\"]):\n",
    "            log[f\"test/collisions_level_{l}\"] = test_collisions[l].item()\n",
    "            log[f\"test/min_possible_collisions_level_{l}\"] = test_min_possible_collisions[l].item()\n",
    "            log[f\"test/collisions_loss_level_{l}\"] = test_collisions_losses[l].item()\n",
    "            log[f\"test/kl_loss_level_{l}\"] = test_kl_losses[l].item()\n",
    "            log[f\"test/sigma_loss_level_{l}\"] = test_sigma_losses[l].item()\n",
    "            log[f\"test/zero_bins_level_{l}\"] = test_zero_bins[l].item()\n",
    "\n",
    "            if should_log_hists and test_hists[l] is not None:\n",
    "                log[f\"test/media/hist_counts_level_{l}\"] = wandb.Image(\n",
    "                    test_hists[l],\n",
    "                    caption=f\"Hashed indices counts at level {l} at epoch {e}\"\n",
    "                )\n",
    "\n",
    "        for i in range(test_pred_images.shape[0]):\n",
    "            log[f\"test/media/pred_image_{i}\"] = wandb.Image(\n",
    "                test_pred_images[i],\n",
    "                caption=f\"Predicted image {i} at epoch {e}\"\n",
    "            )\n",
    "            log[f\"test/media/target_image_{i}\"] = wandb.Image(\n",
    "                test_target_images[i],\n",
    "                caption=f\"Target image {i} at epoch {e}\"\n",
    "            )\n",
    "            log[f\"test/psnr_image_{i}\"] = test_images_psnr[i]\n",
    "\n",
    "    wandb.log(log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImagesDataset(\n",
    "    root=root_dir.split(\"/\")[0],\n",
    "    dir_name=root_dir.split(\"/\")[1],\n",
    "    images_names=train_images,\n",
    "    # images_names=[\"macaw2.jpg\", \"strawberry.jpeg\"],\n",
    "    should_random_permute_input=hyperparameters[\"should_random_permute_input\"]\n",
    ")\n",
    "x, y, h, w, reordered_indices, names = train_dataset[-1]\n",
    "\n",
    "test_dataset = ImagesDataset(\n",
    "    root=root_dir.split(\"/\")[0],\n",
    "    dir_name=root_dir.split(\"/\")[1],\n",
    "    images_names=test_images, #[\"strawberry_small.jpg\"\"]\n",
    "    # should_random_permute_input=hyperparameters[\"should_random_permute_input\"]\n",
    ")\n",
    "eval_x, eval_y, eval_h, eval_w, _, eval_names = test_dataset[-1]\n",
    "\n",
    "input_dim = x.shape[-3]\n",
    "batch = x.shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeneralNeuralGaugeFields(\n",
      "  (MultiresolutionModel): Multiresolution(\n",
      "    (HashFunction): HashFunction(\n",
      "      (module_list): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): Linear(in_features=2, out_features=8, bias=True)\n",
      "          (1): Tanh()\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): Linear(in_features=8, out_features=32, bias=True)\n",
      "          (1): Tanh()\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=8, bias=True)\n",
      "          (1): Tanh()\n",
      "        )\n",
      "        (3): Sequential(\n",
      "          (0): Linear(in_features=8, out_features=2, bias=True)\n",
      "          (1): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "      (_dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (_hash_tables): ModuleList(\n",
      "    (0): ModuleList(\n",
      "      (0-3): 4 x Embedding(256, 2)\n",
      "    )\n",
      "  )\n",
      "  (mlp): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=8, out_features=64, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=3, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "  )\n",
      ") , Fast-hash: False\n"
     ]
    }
   ],
   "source": [
    "if not hyperparameters[\"should_fast_hash\"]:\n",
    "    hashFunction = HashFunction(\n",
    "        hidden_layers_widths=hyperparameters[\"hash_function_hidden_layers_widths\"],\n",
    "        input_dim=input_dim,\n",
    "        output_dim=hyperparameters[\"output_dim\"],\n",
    "        hash_table_size=hyperparameters[\"hash_table_size\"],\n",
    "        sigma_scale=hyperparameters[\"sigma_scale\"],\n",
    "        hidden_layers_activation=hyperparameters[\"hash_function_hidden_layers_activations\"],\n",
    "        should_normalize_levels=hyperparameters[\"should_normalize_levels\"],\n",
    "        should_dropout=hyperparameters[\"should_dropout_hash_function\"],\n",
    "        should_log=[] if should_log else []\n",
    "    )\n",
    "    if hyperparameters[\"should_xavier_initialization\"] is not None:\n",
    "        hashFunction.apply(xavier_init_weights)\n",
    "\n",
    "multires = Multiresolution(\n",
    "    n_min=hyperparameters[\"n_min\"],\n",
    "    n_max=hyperparameters[\"n_max\"],\n",
    "    num_levels=hyperparameters[\"num_levels\"],\n",
    "    HashFunction=hashFunction if not hyperparameters[\"should_fast_hash\"] else None,\n",
    "    hash_table_size=None if not hyperparameters[\"should_fast_hash\"] else hyperparameters[\"hash_table_size\"],\n",
    "    input_dim=input_dim,\n",
    "    should_use_all_levels=hyperparameters[\"should_use_all_levels\"],\n",
    "    should_fast_hash=hyperparameters[\"should_fast_hash\"],\n",
    "    should_log=[] if should_log else []\n",
    ")\n",
    "\n",
    "gngf = GeneralNeuralGaugeFields(\n",
    "    batch_size=batch,\n",
    "    hidden_layers_widths=hyperparameters[\"gngf_hidden_layers_widths\"],\n",
    "    MultiresolutionModel=multires,\n",
    "    feature_dim=hyperparameters[\"feature_dim\"],\n",
    "    topk=hyperparameters[\"topk\"],\n",
    "    should_circular_topk=hyperparameters[\"should_circular_topk\"],\n",
    "    should_bw=hyperparameters[\"should_bw\"],\n",
    "    should_log=[2] if should_log else []\n",
    ")\n",
    "\n",
    "loss_fn = Loss(\n",
    "    hash_table_size=hyperparameters[\"hash_table_size\"],\n",
    "    kl_div_reduction=hyperparameters[\"kl_div_reduction\"],\n",
    "    should_kl_hist=hyperparameters[\"kl_hist_loss\"],\n",
    "    should_diff_hist_optimized=hyperparameters[\"differentiable_histogram_optimized\"],\n",
    "    should_use_all_levels=hyperparameters[\"should_use_all_levels\"],\n",
    "    should_fast_hash=hyperparameters[\"should_fast_hash\"],\n",
    "    should_log=[] if should_log else []\n",
    ")\n",
    "\n",
    "optimizer = get_optimizer(\n",
    "    net=gngf,\n",
    "    features_lr=hyperparameters[\"features_lr\"],\n",
    "    hash_lr=hyperparameters[\"hash_lr\"],\n",
    "    MLP_lr=hyperparameters[\"MLP_lr\"],\n",
    "    features_weight_decay=hyperparameters[\"features_weight_decay\"],\n",
    "    hash_weight_decay=hyperparameters[\"hash_weight_decay\"],\n",
    "    MLP_weight_decay=hyperparameters[\"MLP_weight_decay\"],\n",
    ")\n",
    "\n",
    "if hyperparameters[\"epochs\"] > 1:\n",
    "    if hyperparameters[\"scheduler\"] == \"CosineAnnealingLR\":\n",
    "        scheduler = CosineAnnealingLR(optimizer, T_max=hyperparameters[\"epochs\"]//4, eta_min=hyperparameters[\"scheduler_gamma\"])\n",
    "    elif hyperparameters[\"scheduler\"] == \"CosineAnnealingWarmRestarts\":\n",
    "        scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=hyperparameters[\"epochs\"]//4, T_mult=1, eta_min=hyperparameters[\"scheduler_gamma\"])\n",
    "    elif hyperparameters[\"scheduler\"] == \"StepLR\":\n",
    "        scheduler = StepLR(optimizer, step_size=int(0.05 * hyperparameters[\"epochs\"]), gamma=hyperparameters[\"scheduler_gamma\"])\n",
    "\n",
    "early_stopper = EarlyStopper(\n",
    "    tolerance=early_stopper_tolerance,\n",
    "    min_delta=early_stopper_min_delta\n",
    ")\n",
    "\n",
    "print(gngf, \", Fast-hash:\", gngf.MultiresolutionModel._should_fast_hash)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65, Loss: 41.576194763183594, Collisions: tensor([  0.,   0., 287., 731.], device='cuda:0'), PSNR: [14.400812912314166]:   2%|         | 66/3000 [02:56<2:07:04,  2.60s/it]"
     ]
    }
   ],
   "source": [
    "plt.ioff()\n",
    "should_calc_hists = False\n",
    "\n",
    "pbar = tqdm(range(0, hyperparameters[\"epochs\"]))\n",
    "\n",
    "for e in pbar:\n",
    "    should_calc_hists = ((e == hyperparameters[\"epochs\"] - 1) or (e % histogram_rate == 0) or early_stopper.early_stop)\n",
    "    if hyperparameters[\"should_fast_hash\"] and (e > 0):\n",
    "        should_calc_hists = False\n",
    "\n",
    "    train = train_loop(\n",
    "        x=x,\n",
    "        target=y,\n",
    "        h=h,\n",
    "        w=w,\n",
    "        model=gngf,\n",
    "        optimizer=optimizer,\n",
    "        loss_fn=loss_fn,\n",
    "        norm_regularization_order=hyperparameters[\"norm_regularization_order\"],\n",
    "        l_collisions=hyperparameters[\"l_collisions\"],\n",
    "        l_kl_loss=hyperparameters[\"l_kl_loss\"],\n",
    "        l_sigma_loss=hyperparameters[\"l_sigma_loss\"],\n",
    "        l_zero_bins=hyperparameters[\"l_zero_bins\"],\n",
    "        l_l2_reg=hyperparameters[\"l_l2_reg\"],\n",
    "        l_images_mse=hyperparameters[\"l_images_mse\"],\n",
    "        gradient_clip=hyperparameters[\"gradient_clipping\"],\n",
    "        # Calc histograns at: first epoch, last epoch, every histogram_rate epochs, every time early stopper stops\n",
    "        should_calc_hists=should_calc_hists,\n",
    "        should_kl_hist=hyperparameters[\"kl_hist_loss\"],\n",
    "        should_log=[] if should_log else [],\n",
    "        excluded_params_from_l2_reg=hyperparameters[\"exclude_params_from_l2_reg\"]\n",
    "    )\n",
    "\n",
    "    # test = test_loop(\n",
    "    #     x=eval_x,\n",
    "    #     target=eval_y,\n",
    "    #     h=eval_h,\n",
    "    #     w=eval_w,\n",
    "    #     model=gngf,\n",
    "    #     loss_fn=loss_fn,\n",
    "    #     norm_regularization_order=hyperparameters[\"norm_regularization_order\"],\n",
    "    #     l_collisions=hyperparameters[\"l_collisions\"],\n",
    "    #     l_kl_loss=hyperparameters[\"l_kl_loss\"],\n",
    "    #     l_sigma_loss=hyperparameters[\"l_sigma_loss\"],\n",
    "    #     l_zero_bins=hyperparameters[\"l_zero_bins\"],\n",
    "    #     l_l2_reg=hyperparameters[\"l_l2_reg\"],\n",
    "    #     l_images_mse=hyperparameters[\"l_images_mse\"],\n",
    "    #     # Calc histograns at: first epoch, last epoch, every histogram_rate epochs, every time early stopper stops\n",
    "    #     should_calc_hists=should_calc_hists,\n",
    "    #     should_kl_hist=hyperparameters[\"kl_hist_loss\"],\n",
    "    #     should_log=[2] if should_log else [],\n",
    "    #     excluded_params_from_l2_reg=hyperparameters[\"exclude_params_from_l2_reg\"]\n",
    "    # )\n",
    "\n",
    "    if should_wandb:\n",
    "        wandb_log(\n",
    "            e=e,\n",
    "            lr=scheduler.get_last_lr()[0] if hyperparameters[\"scheduler\"] is not None else None, \n",
    "            l_zero_bins=hyperparameters[\"l_zero_bins\"],\n",
    "            l_kl_loss=hyperparameters[\"l_kl_loss\"],\n",
    "            train=train,\n",
    "            # test=test,\n",
    "            should_log_hists=should_calc_hists\n",
    "        )\n",
    "\n",
    "    if (hyperparameters[\"lambdas_decay\"] > -1) and e != 0 and e % hyperparameters[\"lambdas_decay\"] == 0:\n",
    "        hyperparameters[\"l_zero_bins\"] = hyperparameters[\"l_zero_bins\"] * 0.9\n",
    "        hyperparameters[\"l_kl_loss\"] = hyperparameters[\"l_kl_loss\"] * 1.001\n",
    "    \n",
    "    if hyperparameters[\"scheduler\"] is not None and hyperparameters[\"epochs\"] > 1:\n",
    "        scheduler.step()\n",
    "    \n",
    "    # if np.isnan(train_loss):\n",
    "    if np.isnan(train[-1]):\n",
    "        break \n",
    "\n",
    "    # pbar.set_description(f\"Epoch {e}, Loss: {test_loss}, Collisions: {test_collisions}\")\n",
    "    pbar.set_description(f\"Epoch {e}, Loss: {train[-1]}, Collisions: {train[3]}, PSNR: {train[2]}\")\n",
    "\n",
    "    # for name, param in multires.named_parameters():\n",
    "    #     print(f'Parameter: {name}, Gradient: {param.grad}')\n",
    "\n",
    "    if early_stopper.early_stop:\n",
    "        print(\"!!! Stopping at epoch:\", e, \"!!!\")\n",
    "        break\n",
    "\n",
    "    # early_stopper(test_loss)\n",
    "    early_stopper(train[-2]) #images_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if should_wandb:\n",
    "    wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
