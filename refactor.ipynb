{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NeRF: Collision Handling in Instant Neural Graphics Primitives\n",
    "Federico Montagna (fedemonti00@gmail.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda avilable: True\n",
      "Available device 0: NVIDIA GeForce RTX 2070\n",
      "Available device 1: NVIDIA GeForce RTX 2070\n",
      "Current device 0: NVIDIA GeForce RTX 2070\n",
      "Random seed: 31504\n"
     ]
    }
   ],
   "source": [
    "# Types\n",
    "from typing import List, Tuple, Dict, Any, Optional, Union, Callable, TypeVar\n",
    "\n",
    "# Numpy\n",
    "import numpy as np\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Einops\n",
    "from einops import rearrange, reduce, repeat\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam, SGD, AdamW\n",
    "from torch.optim.lr_scheduler import StepLR, CosineAnnealingLR, CosineAnnealingWarmRestarts\n",
    "from torchvision import io\n",
    "\n",
    "# datetime\n",
    "try:\n",
    "    from zoneinfo import ZoneInfo\n",
    "except ImportError:\n",
    "    from backports.zoneinfo import ZoneInfo\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# other\n",
    "import traceback\n",
    "import inspect\n",
    "import os\n",
    "import random\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "print(\"Cuda avilable:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"Available device {i}:\", torch.cuda.get_device_name(i))\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Current device {torch.cuda.current_device()}:\", torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "\n",
    "# torch.set_default_device(device)\n",
    "\n",
    "random_seed = 31504 #np.random.randint(0, (2**16 - 1)) # 4129\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "torch.random.manual_seed(random_seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(random_seed)\n",
    "print(\"Random seed:\", random_seed)\n",
    "\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"main.ipynb\"\n",
    "\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bcolors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKCYAN = '\\033[96m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "\n",
    "decoded_functions = {\n",
    "    # Dataset\n",
    "    \"__getitem__\": 0,\n",
    "    # general\n",
    "    \"__init__\": 0,\n",
    "    \"forward\": 1,\n",
    "    \"train_loop\": 1,\n",
    "    \"test_loop\": 1,\n",
    "    \"plot_images\": 2,\n",
    "    # MultiResolution\n",
    "    \"_multiresolution_hash\": 2,\n",
    "    \"_scale_to_grid\": 3,\n",
    "    \"_calc_bilinear_coefficients\": 4,\n",
    "    \"_calc_dummies\": 5,\n",
    "    \"_calc_hash_collisions\": 6,\n",
    "    \"_calc_uniques\": 7,\n",
    "    \"_hist_collisions\": 8,\n",
    "    # GeneralNeuralGaugeFields\n",
    "    \"_look_up_features\": 2,\n",
    "    \"_bilinear_interpolation\": 3,\n",
    "    # Loss\n",
    "    \"_calc_hist_pdf\": 2,\n",
    "    \"_kl_div\": 3,\n",
    "    \"differentiable_histogram\": 4,\n",
    "}\n",
    "\n",
    "\n",
    "def log(texts, allowed: List | bool, color: bcolors = bcolors.OKCYAN) -> None:\n",
    "    should_log = (\n",
    "        (type(allowed) == bool and allowed)\n",
    "        or \n",
    "        (type(allowed) == list and decoded_functions[inspect.stack()[1][0].f_code.co_name] in allowed)\n",
    "    )\n",
    "\n",
    "    if should_log:\n",
    "        stack = traceback.extract_stack()\n",
    "        calling_frame = stack[-2]\n",
    "        calling_line = calling_frame.line\n",
    "        print(color, \"Line: \", calling_line, bcolors.ENDC)\n",
    "\n",
    "        try:\n",
    "            print(*texts)\n",
    "        except:\n",
    "            print(texts)\n",
    "\n",
    "        # print_allocated_memory(True)\n",
    "        \n",
    "        print(color, \"-\"*20, bcolors.ENDC)\n",
    "\n",
    "\n",
    "def print_allocated_memory(log: bool = True):\n",
    "    if log:\n",
    "        stack = traceback.extract_stack()\n",
    "        calling_frame = stack[-2]\n",
    "        calling_line = calling_frame.line\n",
    "        print(bcolors.HEADER, \"Line: \", calling_line, \", from: \", inspect.stack()[1][0].f_code.co_name, bcolors.ENDC)\n",
    "\n",
    "        allocated_memory = torch.cuda.memory_allocated() / (1024 ** 3)  # Convert to gigabytes\n",
    "        print(f\"Allocated Memory: {allocated_memory:.2f} GB\")\n",
    "\n",
    "        peak_memory = torch.cuda.max_memory_allocated() / (1024 ** 3)  # Convert to gigabytes\n",
    "        print(f\"Peak Allocated Memory: {peak_memory:.2f} GB\")\n",
    "\n",
    "        print(bcolors.OKCYAN, \"-\"*20, bcolors.ENDC)\n",
    "\n",
    "\n",
    "def plot_images(outs: np.ndarray, targets: np.ndarray, allowed: List = []) -> None:\n",
    "    if allowed: # if allowed is not empty then check else do nothing\n",
    "        if decoded_functions[inspect.stack()[0][0].f_code.co_name] in allowed:\n",
    "            rows = outs.shape[0]\n",
    "            cols = 2\n",
    "\n",
    "            fig, axs = plt.subplots(rows, cols, figsize=(5 * cols, 5 * rows))\n",
    "            axs = axs.flatten()\n",
    "            for i in range(0, (rows * cols), cols):\n",
    "                axs[i + 0].imshow(outs[i//cols])\n",
    "                axs[i + 0].set_title(\"Prediction\")\n",
    "                axs[i + 1].imshow(targets[i//cols])\n",
    "                axs[i + 1].set_title(\"Target\")\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Wandb Api Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apikey_path = \".wandb_apikey.txt\"\n",
    "# if os.path.exists(apikey_path):\n",
    "#     with open(apikey_path, \"r\") as f:\n",
    "#         apikey = f.read()\n",
    "#         !wandb login {apikey} # --relogin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(\n",
    "        self, \n",
    "        images_paths: List[str],\n",
    "        should_randomize_input: bool = False,\n",
    "        should_log: List[int] = []\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        images_paths : List[str]\n",
    "            List of paths to images.\n",
    "        should_randomize_input : bool, optional (default is False)\n",
    "            Should randomize the images.\n",
    "        should_log : List[int], optional (default is [])\n",
    "            List of decoded functions to log.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        super(ImageDataset, self).__init__()\n",
    "\n",
    "        self._images_paths: List[str] = images_paths\n",
    "        self._should_randomize_input: bool = should_randomize_input\n",
    "        self._should_log: List[int] = should_log\n",
    "\n",
    "    def __getitem__(self, idx: torch.Tensor or int) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        idx : torch.Tensor or int\n",
    "            Index of the image.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Dict[str, torch.Tensor]\n",
    "            Dictionary with image and target.\n",
    "        \n",
    "        Raises\n",
    "        ------\n",
    "        RuntimeError\n",
    "            If error occurs while reading images.\n",
    "        \"\"\"\n",
    "\n",
    "        if idx == -1:\n",
    "            idx = torch.arange(len(self._images_paths), device=\"cpu\")\n",
    "        \n",
    "        if not torch.is_tensor(idx):\n",
    "            idx = torch.tensor([idx], device=\"cpu\")\n",
    "        \n",
    "        try:\n",
    "            images: torch.Tensor = torch.stack([\n",
    "                rearrange(\n",
    "                    io.read_image(self._images_paths[id]).cpu(),\n",
    "                    \"rgb h w -> h w rgb\"\n",
    "                )\n",
    "                for id in idx\n",
    "            ])\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Error while reading images: {e}\")\n",
    "        \n",
    "        h, w = images.shape[1], images.shape[2]\n",
    "        images_shape = h * w\n",
    "\n",
    "        reordered_indices: torch.Tensor = torch.zeros(\n",
    "            (images.shape[0], images_shape),\n",
    "            dtype=torch.int64,\n",
    "            device=\"cpu\"\n",
    "        )\n",
    "        log((\"Reordered indices:\", reordered_indices.shape), self._should_log)\n",
    "\n",
    "        X: torch.Tensor = torch.zeros((images.shape[0], images_shape, 2), device=\"cpu\")\n",
    "        log((\"X:\", X.shape), self._should_log)\n",
    "\n",
    "        Y: torch.Tensor = torch.zeros((images.shape[0], images_shape, images.shape[-1]), device=\"cpu\")\n",
    "        log((\"Y:\", Y.shape), self._should_log)\n",
    "\n",
    "        for i in range(images.shape[0]):\n",
    "            if self._should_randomize_input:\n",
    "                shuffled_indices: torch.Tensor = (\n",
    "                    torch.randperm(images_shape, device=\"cpu\") \n",
    "                )\n",
    "                log((\"Shuffled indices:\", shuffled_indices, shuffled_indices.shape), self._should_log)\n",
    "\n",
    "                reordered_indices[i][shuffled_indices] = torch.arange(images_shape, device=\"cpu\")\n",
    "            else:\n",
    "                reordered_indices[i] = torch.arange(images_shape, device=\"cpu\")\n",
    "\n",
    "            X[i] = torch.tensor(\n",
    "                np.stack(np.meshgrid(range(h), range(w), indexing=\"ij\"), axis=-1).reshape(-1, 2)\n",
    "            )\n",
    "        \n",
    "            Y[i] = rearrange(\n",
    "                images[i],\n",
    "                \"h w rgb -> (h w) rgb\"\n",
    "            )\n",
    "            \n",
    "            if self._should_randomize_input:\n",
    "                X[i] = X[i][shuffled_indices]\n",
    "                Y[i] = Y[i][shuffled_indices]\n",
    "\n",
    "        X = (\n",
    "            X.float() / max(h, w)\n",
    "        ).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        Y = Y.float() / 255\n",
    "        \n",
    "        to_return = {\n",
    "            \"X\": X,\n",
    "            \"Y\": Y,\n",
    "            \"h\": h,\n",
    "            \"w\": w,\n",
    "            \"reordered_indices\": reordered_indices\n",
    "        }\n",
    "\n",
    "        return to_return\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self._images_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward Pass Differentiable Approximation\n",
    "[https://github.com/kitayama1234/Pytorch-BPDA]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def differentiable_round(x, round_function=torch.round):\n",
    "    forward_value = round_function(x)\n",
    "    out = x.clone()\n",
    "    out.data = forward_value.data\n",
    "\n",
    "    def backward(grad_output):\n",
    "        return grad_output\n",
    "\n",
    "    out.register_hook(backward)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Differentiable Hisogram\n",
    "[https://github.com/hyk1996/pytorch-differentiable-histogram]()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# Differentiable Histogram Counting Method\n",
    "#############################################\n",
    "# https://github.com/hyk1996/pytorch-differentiable-histogram\n",
    "\n",
    "# TAKES UP TO 1GB OF GPU FOR EACH LEVEL for macaw2\n",
    "def differentiable_histogram(x, bins=255, min=0.0, max=1.0, should_log: List[int] = []):\n",
    "\n",
    "    if len(x.shape) == 4:\n",
    "        n_samples, n_chns, _, _ = x.shape\n",
    "    elif len(x.shape) == 2:\n",
    "        n_samples, n_chns = 1, 1\n",
    "    else:\n",
    "        raise AssertionError('The dimension of input tensor should be 2 or 4.')\n",
    "\n",
    "    hist_torch = torch.zeros(n_samples, n_chns, bins).to(x.device)\n",
    "    log((\"hist_torch:\", hist_torch.shape), should_log)\n",
    "    delta = (max - min) / bins\n",
    "\n",
    "    BIN_Table = torch.arange(start=0, end=bins, step=1) * delta\n",
    "    log((\"BIN_Table:\", BIN_Table.shape), should_log)\n",
    "\n",
    "    for dim in range(1, bins-1, 1):\n",
    "        h_r = BIN_Table[dim].item()             # h_r\n",
    "        h_r_sub_1 = BIN_Table[dim - 1].item()   # h_(r-1)\n",
    "        h_r_plus_1 = BIN_Table[dim + 1].item()  # h_(r+1)\n",
    "\n",
    "        mask_sub = ((h_r > x) & (x >= h_r_sub_1)).float()\n",
    "        mask_plus = ((h_r_plus_1 > x) & (x >= h_r)).float()\n",
    "\n",
    "        hist_torch[:, :, dim] += torch.sum(((x - h_r_sub_1) * mask_sub).view(n_samples, n_chns, -1), dim=-1)\n",
    "        hist_torch[:, :, dim] += torch.sum(((h_r_plus_1 - x) * mask_plus).view(n_samples, n_chns, -1), dim=-1)\n",
    "\n",
    "        del mask_sub\n",
    "        del mask_plus\n",
    "        del h_r\n",
    "        del h_r_sub_1\n",
    "        del h_r_plus_1\n",
    "\n",
    "    log((\"hist_torch:\", hist_torch.shape), should_log)\n",
    "\n",
    "    del BIN_Table\n",
    "\n",
    "    return hist_torch / delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hash Function Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HashFunctionModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_layers_widths: List[int],\n",
    "        input_size: int = 2,\n",
    "        output_size: int = 2,\n",
    "        hash_table_size: int = 2**14,\n",
    "        sigmas_scale: float = 1.0,\n",
    "        hidden_layers_activation: nn.Module = nn.Tanh(),\n",
    "        should_log: List[int] = []\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        hidden_layers_widths : List[int]\n",
    "            List of hidden layers widths.\n",
    "        input_size : int, optional (default is 2)\n",
    "            Input size.\n",
    "        output_size : int, optional (default is 2)\n",
    "            Output size.\n",
    "        hash_table_size : int, optional (default is 2**14)\n",
    "            Hash table size.\n",
    "        sigmas_scale : float, optional (default is 1.0)\n",
    "            Sigmas scale.\n",
    "        hidden_layers_activation : nn.Module, optional (default is nn.Tanh())\n",
    "            Activation function for hidden layers.\n",
    "        should_log : List[int], optional (default is [])\n",
    "            List of decoded functions to log.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        super(HashFunctionModel, self).__init__()\n",
    "\n",
    "        self._input_size: int = input_size\n",
    "        self._output_size: int = output_size\n",
    "        self._hash_table_size: int = hash_table_size\n",
    "        self._sigmas_scale: float = sigmas_scale\n",
    "\n",
    "        self._should_log: List[int] = should_log\n",
    "\n",
    "        layers_widths = [input_size, *hidden_layers_widths, output_size]\n",
    "\n",
    "        self._module_list: nn.ModuleList = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(\n",
    "                    in_features=layers_widths[i], \n",
    "                    out_features=layers_widths[i + 1],\n",
    "                    device=device\n",
    "                ),\n",
    "                hidden_layers_activation if (i < len(layers_widths) - 2) else nn.Sigmoid()\n",
    "            )\n",
    "            for i in range(len(layers_widths) - 1)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Hashes the coordinates.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor\n",
    "            Images' grid coordinates.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Tuple[torch.Tensor, torch.Tensor]\n",
    "            The hashed coordinates and their uncertainty.\n",
    "        \"\"\"\n",
    "\n",
    "        log((\"x:\", x, x.shape, x.requires_grad, x.is_leaf), self._should_log)\n",
    "\n",
    "        # for layer in self._module_list:\n",
    "        for i, layer in enumerate(self._module_list):\n",
    "            x = layer(x)\n",
    "            log((f\"After layer {i}:\", x, x.shape, x.requires_grad, x.is_leaf), self._should_log)\n",
    "\n",
    "        x = x.unsqueeze(-1)\n",
    "        indices = differentiable_round(x[..., 0, :] * (self._hash_table_size - 1))\n",
    "        log((\"indices:\", indices, indices.shape, indices.requires_grad, indices.is_leaf), self._should_log)\n",
    "        sigmas = x[..., 1, :] * self._sigmas_scale\n",
    "        log((\"sigmas:\", sigmas, sigmas.shape, sigmas.requires_grad, sigmas.is_leaf), self._should_log)\n",
    "\n",
    "        del x\n",
    "        \n",
    "        return indices, sigmas\n",
    "    \n",
    "    def get_hash_table_size(self) -> int:\n",
    "        \"\"\"\n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            Hash table size.\n",
    "        \"\"\"\n",
    "        return self._hash_table_size\n",
    "    \n",
    "    def get_input_size(self) -> int:\n",
    "        \"\"\"\n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            Input size.\n",
    "        \"\"\"\n",
    "        return self._input_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Multiresolution Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiresolutionModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_min: int,\n",
    "        n_max: int,\n",
    "        num_levels: int,\n",
    "        hashModel: HashFunctionModel | None,\n",
    "        hash_table_size: int | None = None,\n",
    "        input_size: int | None = None,\n",
    "        should_use_all_levels: bool = False,\n",
    "        should_fast_hash: bool = False,\n",
    "        should_calc_collisions: bool = False,\n",
    "        should_log: List[int] = []\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        n_min : int\n",
    "            Minimum scaling factor.\n",
    "        n_max : int\n",
    "            Maximum scaling factor.\n",
    "        num_levels : int\n",
    "            Number of levels.\n",
    "        HashFunctionModel : HashFunctionModel | None\n",
    "            Hash function model.\n",
    "        hash_table_size : int | None, optional (default is None)\n",
    "            Hash table size. If None then HashFunctionModel's hash_table_size is used.\n",
    "        input_size : int | None, optional (default is None)\n",
    "            Input size. If None then HashFunctionModel's input_size is used.\n",
    "        should_use_all_levels : bool, optional (default is False)\n",
    "            Whether to use all levels or only the ones with collisions.\n",
    "        should_fast_hash : bool, optional (default is False)\n",
    "            Whether to use fast hash instead of HashFunction or not.\n",
    "        should_calc_collisions : bool, optional (default is False)\n",
    "            Whether to calculate collisions or not.\n",
    "        should_log : List[int], optional (default is [])\n",
    "            List of decoded functions to log.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        super(MultiresolutionModel, self).__init__()\n",
    "\n",
    "        self._n_min: int = n_min\n",
    "        self._n_max: int = n_max\n",
    "        self._num_levels: int = num_levels\n",
    "\n",
    "        self.hashModel: HashFunctionModel = hashModel\n",
    "        self._hash_table_size: int = hash_table_size if hash_table_size is not None else self.hashModel.get_hash_table_size()\n",
    "        self._input_size: int = input_size if input_size is not None else self.hashModel.get_input_size()\n",
    "\n",
    "        self._should_use_all_levels: bool = should_use_all_levels\n",
    "        self._should_fast_hash: bool = should_fast_hash\n",
    "        self._should_calc_collisions: bool = should_calc_collisions\n",
    "        self._should_log: List[int] = should_log\n",
    "\n",
    "        b: torch.Tensor = torch.tensor(np.exp((np.log(n_max) - np.log(n_min)) / (self._num_levels - 1))).float()\n",
    "        if b > 2 or b <= 1:\n",
    "            print(\n",
    "                f\"The between level scale is recommended to be <= 2 and needs to be > 1 but was {b:.4f}.\"\n",
    "            )\n",
    "        \n",
    "        self._levels: torch.Tensor = torch.stack([\n",
    "            torch.floor(n_min * (b ** l)) for l in range(self._num_levels)\n",
    "        ]).reshape(1, 1, -1, 1).to(device)\n",
    "        log((\"Levels:\", self._levels, self._levels.shape, self._levels.requires_grad, ), self._should_log)\n",
    "\n",
    "        self._voxels_helper_hypercube: torch.Tensor = rearrange(\n",
    "            torch.tensor(\n",
    "                np.stack(np.meshgrid(range(2), range(2), range(self._input_size - 1), indexing=\"ij\"), axis=-1),\n",
    "                device=device\n",
    "            ),\n",
    "            \"cols rows depths verts -> (depths rows cols) verts\"\n",
    "        ).T[:self._input_size, :].unsqueeze(0).unsqueeze(2)\n",
    "        log((\"voxels_helper_hypercube:\", self._voxels_helper_hypercube, self._voxels_helper_hypercube.shape, self._voxels_helper_hypercube.requires_grad), self._should_log)\n",
    "\n",
    "        if self._should_fast_hash:\n",
    "            self._prime_numbers = torch.nn.Parameter(\n",
    "                torch.from_numpy(\n",
    "                    np.array([1, 2654435761, 805459861])\n",
    "                ).to(device),\n",
    "                False\n",
    "            )\n",
    "\n",
    "    def forward(\n",
    "        self, \n",
    "        x: torch.Tensor, \n",
    "        should_calc_hists: bool = False, \n",
    "        should_show_hists: bool = False\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor | None, torch.Tensor, List[plt.Figure] | None]:\n",
    "        log((\"x:\", x, x.shape, x.requires_grad, x.is_leaf), self._should_log)\n",
    "\n",
    "        grid_coords, coeffs = self._scale_to_grid(x)\n",
    "        log((\"grid_coords:\", grid_coords, grid_coords.shape, grid_coords.requires_grad, grid_coords.is_leaf), self._should_log)\n",
    "        log((\"coeffs:\", coeffs, coeffs.shape, coeffs.requires_grad, coeffs.is_leaf), self._should_log)\n",
    "        \n",
    "        dummy_grids, og_indices, _ = self._calc_dummies(grid_coords=grid_coords)\n",
    "        min_possible_collisions, _ = self._calc_hash_collisions(dummy_grids=dummy_grids)\n",
    "        del _\n",
    "        log((\"dummy_grids:\", dummy_grids, [dummy_grids[l].shape for l in range(self._num_levels)]), self._should_log)\n",
    "        log((\"og_indices:\", og_indices, [(og_indices[l], og_indices[l].shape) for l in range(self._num_levels)]), self._should_log)\n",
    "        log((\"min_possible_collisions:\", min_possible_collisions, min_possible_collisions.shape, min_possible_collisions.requires_grad), self._should_log)\n",
    "\n",
    "        hashed, sigmas = (\n",
    "            self._fast_hash(grid_coords)\n",
    "            if self._should_fast_hash\n",
    "            else (\n",
    "                self.hashModel(grid_coords)\n",
    "                if self._should_use_all_levels\n",
    "                else\n",
    "                self._multiresolution_hash(grid_coords, min_possible_collisions)\n",
    "            )\n",
    "        )\n",
    "        del grid_coords\n",
    "        log((\"hashed:\", hashed, hashed.shape, hashed.requires_grad, hashed.is_leaf), self._should_log)\n",
    "        log((\"sigmas:\", sigmas, sigmas.shape, sigmas.requires_grad, sigmas.is_leaf), self._should_log)\n",
    "\n",
    "        _, _, dummy_hashed = self._calc_dummies(hashed=hashed)\n",
    "        log((\"dummy_hashed:\", dummy_hashed, [dummy_hashed[l].shape for l in range(self._num_levels)]), self._should_log)\n",
    "\n",
    "        collisions = None\n",
    "        if self._should_calc_collisions:\n",
    "            _, collisions = self._calc_hash_collisions(dummy_grids=dummy_grids, dummy_hashed=dummy_hashed)\n",
    "            del _, dummy_grids, dummy_hashed\n",
    "            log((\"collisions:\", collisions, collisions.shape, collisions.requires_grad, collisions.is_leaf), self._should_log)\n",
    "\n",
    "        hists = self._hist_collisions(hashed, og_indices, min_possible_collisions, should_show=should_show_hists) if should_calc_hists else None\n",
    "        del og_indices\n",
    "\n",
    "        return hashed, sigmas, min_possible_collisions, collisions, coeffs, hists\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _scale_to_grid(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor\n",
    "            Coordinates to scale. (batch, pixels, xyz, 1, 1)\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Tuple[torch.Tensor, torch.Tensor]\n",
    "            Scaled grid coordinates and coefficients for bilinear interpolation.\n",
    "        \"\"\"\n",
    "\n",
    "        scaled_coords: torch.Tensor = x.float() * self._levels # (batch, pixels, xyz, levels, 1)\n",
    "        log((\"scaled_coords:\", scaled_coords, scaled_coords.shape, scaled_coords.requires_grad, scaled_coords.is_leaf), self._should_log)\n",
    "\n",
    "        grid_coords: torch.Tensor = rearrange(\n",
    "            torch.add(\n",
    "                torch.floor(scaled_coords),\n",
    "                self._voxels_helper_hypercube\n",
    "            ),\n",
    "            \"batch pixels xyz levels verts -> batch pixels levels verts xyz\"\n",
    "        )\n",
    "        log((\"grid_coords:\", grid_coords, grid_coords.shape, grid_coords.requires_grad, grid_coords.is_leaf), self._should_log)\n",
    "\n",
    "        coeffs: torch.Tensor = self._calc_bilinear_coefficients(scaled_coords, grid_coords)\n",
    "        log((\"coeffs:\", coeffs, coeffs.shape, coeffs.requires_grad, coeffs.is_leaf), self._should_log)\n",
    "\n",
    "        del scaled_coords\n",
    "\n",
    "        return grid_coords, coeffs\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _calc_bilinear_coefficients(self, scaled_coords: torch.Tensor, grid_coords: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        scaled_coords : torch.Tensor\n",
    "            Scaled coordinates.\n",
    "        grid_coords : torch.Tensor\n",
    "            Grid coordinates.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            Coefficients for bilinear interpolation.\n",
    "        \"\"\"\n",
    "\n",
    "        log((\"SCALED COORDS:\", scaled_coords[0, :, :, 0, :], scaled_coords.shape), self._should_log)\n",
    "        log((\"GRID COORDS:\", grid_coords[0, :, 0, :, :], grid_coords.shape), self._should_log)\n",
    "\n",
    "        _as: torch.Tensor = grid_coords[:, :, :, 0, :].unsqueeze(-2)  # bottom-right vertices of cells\n",
    "        _ds: torch.Tensor = grid_coords[:, :, :, -1, :].unsqueeze(-2)  # top-left vertices of cells\n",
    "\n",
    "        log((\"_as:\", _as, _as.shape), self._should_log)\n",
    "        log((\"_ds:\", _ds, _ds.shape), self._should_log)\n",
    "\n",
    "        coeffs: torch.Tensor = torch.stack([\n",
    "            (_ds[:, :, :, :, 0] - scaled_coords[:, :, 0, :, :]) * (_ds[:, :, :, :, 1] - scaled_coords[:, :, 1, :, :]),  # (xd - x) * (yd - y)\n",
    "            (scaled_coords[:, :, 0, :, :] - _as[:, :, :, :, 0]) * (_ds[:, :, :, :, 1] - scaled_coords[:, :, 1, :, :]),  # (x - xa) * (yd - y)\n",
    "            (_ds[:, :, :, :, 0] - scaled_coords[:, :, 0, :, :]) * (scaled_coords[:, :, 1, :, :] - _as[:, :, :, :, 1]),  # (xd - x) * (y - ya)\n",
    "            (scaled_coords[:, :, 0, :, :] - _as[:, :, :, :, 0]) * (scaled_coords[:, :, 1, :, :] - _as[:, :, :, :, 1]),  # (x - xa) * (y - ya)\n",
    "        ], dim=-1).squeeze(-2).unsqueeze(2)#.to(device)\n",
    "        \n",
    "        del _as\n",
    "        del _ds\n",
    "        del scaled_coords\n",
    "        del grid_coords\n",
    "\n",
    "        log((\"COEFFS:\", coeffs, coeffs.shape), self._should_log)\n",
    "\n",
    "        return coeffs\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _calc_dummies(\n",
    "        self, \n",
    "        grid_coords: torch.Tensor | None = None, \n",
    "        hashed: torch.Tensor | None = None\n",
    "    ) -> Tuple[torch.Tensor | None, torch.Tensor | None, torch.Tensor | None]:\n",
    "        \"\"\"\n",
    "        Calculates unique values for the grid coordinates or hashed coordinates.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        grid_coords : torch.Tensor | None, optional (default is None)\n",
    "            Grid coordinates. \n",
    "        hashed : torch.Tensor | None, optional (default is None)\n",
    "            Hashed coordinates. \n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        Tuple[torch.Tensor | None, torch.Tensor | None, torch.Tensor | None]\n",
    "            Unique grid coordinates, original unique indices and unique hashed coordinates. \n",
    "        \"\"\"\n",
    "\n",
    "        dummy_grids = None\n",
    "        og_indices = None\n",
    "        dummy_hashed = None\n",
    "\n",
    "        if grid_coords is not None:\n",
    "            log((\"grid_coords:\", grid_coords, grid_coords.shape, grid_coords.requires_grad, grid_coords.is_leaf), self._should_log)\n",
    "            dummy_grids: List[Tuple[torch.Tensor]] = [\n",
    "                # [\n",
    "                torch.unique(rearrange(grid_coords[0, :, l, :, :], \"pixels verts xyz -> (pixels verts) xyz\"), dim=0, return_inverse=True) # first dimension is 0 because images should have all same size\n",
    "                for l in range(self._num_levels)\n",
    "                # ] for b in range(grid_coords.shape[0])\n",
    "            ]\n",
    "\n",
    "            dummy_grids, dummy_grids_inverse_indices = zip(*dummy_grids)\n",
    "            log((\"dummy_grids:\", dummy_grids, [dummy_grids[l].shape for l in range(self._num_levels)]), self._should_log)\n",
    "            log((\"dummy_grids grads:\", [(dummy_grids[l].requires_grad, ) for l in range(self._num_levels)]), self._should_log)\n",
    "\n",
    "            og_indices = [\n",
    "                torch.tensor(\n",
    "                    [np.where(dummy_grids_inverse_indices[l].detach().cpu().numpy() == i)[0][0] for i in range(len(dummy_grids[l]))],\n",
    "                    device=device\n",
    "                )\n",
    "                for l in range(self._num_levels)\n",
    "            ]\n",
    "            log((\"og_indices:\", [(og_indices[l], og_indices[l].shape) for l in range(self._num_levels)]), self._should_log)\n",
    "            log((\"og_indices grads:\", [(og_indices[l].requires_grad, ) for l in range(self._num_levels)]), self._should_log)\n",
    "\n",
    "        if hashed is not None:\n",
    "            log((\"hashed:\", hashed, hashed.shape, hashed.requires_grad, hashed.is_leaf), self._should_log)\n",
    "            \n",
    "            dummy_hashed: List[torch.Tensor] = [\n",
    "                # [\n",
    "                torch.unique(rearrange(hashed[0, :, l, :, :], \"pixels verts xyz -> (pixels verts) xyz\"), dim=0, return_inverse=False) # first dimension is 0 because images should have all same size\n",
    "                for l in range(self._num_levels)\n",
    "                # ] for b in range(hashed.shape[0])\n",
    "            ]\n",
    "            log((\"dummy_hashed:\", dummy_hashed, [dummy_hashed[l].shape for l in range(self._num_levels)]), self._should_log)\n",
    "            log((\"dummy_hashed grads:\", [(dummy_hashed[l].requires_grad, ) for l in range(self._num_levels)]), self._should_log)\n",
    "\n",
    "        return dummy_grids, og_indices, dummy_hashed\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _calc_hash_collisions(\n",
    "        self,\n",
    "        dummy_grids: List[torch.Tensor],\n",
    "        dummy_hashed: List[torch.Tensor] | None = None\n",
    "    ) -> Tuple[torch.Tensor | None, torch.Tensor | None]:\n",
    "        \"\"\"\n",
    "        Calculates the hash collisions.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        dummy_grids : List[torch.Tensor]\n",
    "            List of unique grid coordinates.\n",
    "        dummy_hashed : List[torch.Tensor] | None, optional (default is None)\n",
    "            List of unique hashed coordinates.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Tuple[torch.Tensor | None, torch.Tensor | None]\n",
    "            Minimum possible collisions and actual collisions at each level.\n",
    "        \"\"\"\n",
    "\n",
    "        min_possible_collisions = None\n",
    "        collisions = None\n",
    "\n",
    "        if dummy_hashed is None:\n",
    "            min_possible_collisions: torch.Tensor = torch.stack([\n",
    "                torch.tensor(\n",
    "                    (dummy_grids[l].shape[0]) - self._hash_table_size,\n",
    "                    device=device\n",
    "                )\n",
    "                for l in range(self._num_levels)\n",
    "            ])\n",
    "            min_possible_collisions[min_possible_collisions < 0] = 0\n",
    "            log((\"min_possible_collisions:\", min_possible_collisions, min_possible_collisions.shape, min_possible_collisions.requires_grad), self._should_log)\n",
    "        else:\n",
    "            collisions: torch.Tensor = torch.stack([\n",
    "                torch.tensor(\n",
    "                    float(dummy_grids[l].shape[0] - torch.unique(dummy_hashed[l], dim=0).shape[0]),\n",
    "                    device=device\n",
    "                )\n",
    "                for l in range(self._num_levels)\n",
    "            ])\n",
    "            log((\"collisions:\", collisions, collisions.shape, collisions.dtype, collisions.requires_grad), self._should_log)\n",
    "\n",
    "        return min_possible_collisions, collisions\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _calc_uniques(\n",
    "        self, \n",
    "        hashed: torch.Tensor,\n",
    "        og_indices: torch.Tensor\n",
    "    ) -> List[torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Calculates the unique values for the hashed coordinates.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        hashed : torch.Tensor\n",
    "            Hashed coordinates.\n",
    "        og_indices : torch.Tensor\n",
    "            Original unique indices.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        List[torch.Tensor]\n",
    "            List of unique hashed coordinates one for each level.\n",
    "        \"\"\"\n",
    "        \n",
    "        unique_hashed: List[torch.Tensor] = [\n",
    "            rearrange(hashed[0, :, l, :, :], \"pixels verts xyz -> (pixels verts) xyz\")[og_indices[l]] # first dimension is 0 because images should have all same size\n",
    "            for l in range(self._num_levels)\n",
    "        ]\n",
    "        log((\"unique_hashed:\", [(unique_hashed[b][l], unique_hashed[b][l].shape) for l in range(self._num_levels) for b in range(hashed.shape[0])]), self._should_log)\n",
    "        log((\"unique_hashed:\", [(unique_hashed[l], unique_hashed[l].shape) for l in range(self._num_levels)]), self._should_log)\n",
    "\n",
    "        return unique_hashed\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _hist_collisions(\n",
    "        self,\n",
    "        hashed: torch.Tensor,\n",
    "        og_indices: torch.Tensor,\n",
    "        min_possible_collisions: torch.Tensor,\n",
    "        should_show: bool = False\n",
    "    ) -> List[plt.Figure]:\n",
    "        \"\"\"\n",
    "        Calculates the histogram of the collisions, one for each level.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        hashed : torch.Tensor\n",
    "            Hashed coordinates.\n",
    "        og_indices : torch.Tensor\n",
    "            Original unique indices.\n",
    "        min_possible_collisions : torch.Tensor\n",
    "            Minimum possible collisions, one for each level.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        List[plt.Figure]\n",
    "            List of histograms, one for each level.\n",
    "        \"\"\"\n",
    "\n",
    "        figs=[]\n",
    "\n",
    "        unique_hashed = self._calc_uniques(hashed, og_indices)\n",
    "        log((\"unique_hashed:\", unique_hashed, [unique_hashed[l].shape for l in range(self._num_levels)], unique_hashed[0].requires_grad, unique_hashed[0].is_leaf), self._should_log)\n",
    "\n",
    "        for l, min_collisions in enumerate(min_possible_collisions):\n",
    "            \n",
    "            if (min_collisions <= 0) and not self._should_fast_hash:\n",
    "                figs.append(None)\n",
    "                continue\n",
    "\n",
    "            indices = unique_hashed[l].detach().cpu().numpy()\n",
    "\n",
    "            fig, ax = plt.subplots(figsize=(15, 5))\n",
    "            ax.hist(\n",
    "                indices,\n",
    "                bins=self._hash_table_size,\n",
    "                range=(0, self._hash_table_size),\n",
    "                edgecolor='grey', \n",
    "                linewidth=0.5\n",
    "            )\n",
    "\n",
    "            ax.set_xlim(-1, self._hash_table_size)\n",
    "            ax.xaxis.set_ticks(np.arange(0, self._hash_table_size, 10))\n",
    "\n",
    "            start, end = ax.get_ylim()\n",
    "            step = int(end * 0.1)\n",
    "            ax.yaxis.set_ticks(np.arange(0, end, step if step > 0 else 1))\n",
    "\n",
    "            plt.title(f\"Level {l} ({int(self._levels[0, 0, l, 0].item())})\")\n",
    "            plt.xlabel(\"Hashed indices\")\n",
    "            plt.ylabel(\"Counts\")\n",
    "\n",
    "            figs.append(fig)\n",
    "\n",
    "            if should_show:\n",
    "                plt.show()\n",
    "\n",
    "            plt.close()\n",
    "        \n",
    "        del unique_hashed\n",
    "\n",
    "        return figs\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def _fast_hash(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Implements the hash function proposed by NVIDIA.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor\n",
    "            Grid coordinates to hash of shape (batch, pixels, levels, 2^input_dim, input_dim)\n",
    "            This tensor should contain the vertices of the hyper cube for each level.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Tuple[torch.Tensor, torch.Tensor]\n",
    "            Hashed coordinates and their uncertainty.\n",
    "        \"\"\"\n",
    "        tmp = torch.zeros(\n",
    "            (x.shape[0], x.shape[1], self._num_levels, 2**self._input_size),\n",
    "            device=device\n",
    "        ).to(int)\n",
    "\n",
    "        for i in range(self._input_size):\n",
    "            tmp = torch.bitwise_xor(\n",
    "                (x[:, :, :, :, i].to(int) * self._prime_numbers[i]),\n",
    "                tmp\n",
    "            )\n",
    "\n",
    "        hash = torch.remainder(tmp, self._hash_table_size).unsqueeze(-1).float() # TODO: check if self._hash_table_size - 1 is correct\n",
    "        del tmp\n",
    "\n",
    "        sigmas: torch.Tensor = torch.zeros_like(hash, dtype=torch.float32, device=device) + 1e-10 # to prevent division by zero\n",
    "\n",
    "        return hash, sigmas\n",
    "\n",
    "    def _multiresolution_hash(\n",
    "        self,\n",
    "        x: torch.Tensor,\n",
    "        min_possible_collisions: torch.Tensor,\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor\n",
    "            Grid coordinates to hash of shape (batch, pixels, levels, 2^input_dim, input_dim)\n",
    "            This tensor should contain the vertices of the hyper cube for each level.\n",
    "        min_possible_collisions : torch.Tensor\n",
    "            Minimum possible hash collisions for each level.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Tuple[torch.Tensor, torch.Tensor]\n",
    "            Hashed coordinates and their uncertainty.\n",
    "        \"\"\"\n",
    "        log((\"x:\", x, x.shape, x.requires_grad, x.is_leaf), self._should_log)\n",
    "        log((\"min_possible_collisions:\", min_possible_collisions, min_possible_collisions.shape, min_possible_collisions.requires_grad), self._should_log)\n",
    "\n",
    "        sigma_epsilon = 1e-10 # to prevent division by zero\n",
    "\n",
    "        hashed: torch.Tensor = torch.zeros((x.shape[0], x.shape[1], self._num_levels, 2**self._input_size, 1), device=device)\n",
    "        sigmas: torch.Tensor = torch.zeros((x.shape[0], x.shape[1], self._num_levels, 2**self._input_size, 1), device=device) + sigma_epsilon\n",
    "\n",
    "        x_non_collisions_levels = x[:, :, min_possible_collisions <= 0, :, :]\n",
    "\n",
    "        hashed_non_collisions_levels = (\n",
    "            (\n",
    "                (self._levels[:, :, min_possible_collisions <= 0, :] + 1) \n",
    "                * \n",
    "                x_non_collisions_levels[:, :, :, :, 0]\n",
    "            ) \n",
    "            + \n",
    "            x_non_collisions_levels[:, :, :, :, 1]\n",
    "        )\n",
    "        log((\"Hashed indices of levels without collisions:\", hashed_non_collisions_levels, hashed_non_collisions_levels.shape), self._should_log)\n",
    "        hashed[:, :, min_possible_collisions <= 0, :, :] = hashed_non_collisions_levels.unsqueeze(-1)\n",
    "\n",
    "        hashed_collisions_levels, sigmas_collisions_levels = self.hashModel(x[:, :, min_possible_collisions > 0, :, :])\n",
    "        sigmas[:, :, min_possible_collisions > 0, :, :] = sigmas_collisions_levels\n",
    "        hashed[:, :, min_possible_collisions > 0, :, :] = hashed_collisions_levels\n",
    "        del hashed_collisions_levels\n",
    "        del sigmas_collisions_levels\n",
    "        del x_non_collisions_levels\n",
    "\n",
    "        log((\"hashed:\", hashed, hashed.shape, hashed.requires_grad, hashed.is_leaf), self._should_log)\n",
    "        log((\"sigmas:\", sigmas, sigmas.shape, sigmas.requires_grad, sigmas.is_leaf), self._should_log)\n",
    "\n",
    "        return hashed, sigmas\n",
    "\n",
    "    def get_hash_table_size(self) -> int:\n",
    "        \"\"\"\n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            Hash table size.\n",
    "        \"\"\"\n",
    "        return self._hash_table_size\n",
    "    \n",
    "    def get_num_levels(self) -> int:\n",
    "        \"\"\"\n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            Number of levels.\n",
    "        \"\"\"\n",
    "        return self._num_levels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Neural Gauge Fields Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNGFModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        batch_size: int,\n",
    "        hidden_layers_widths: List[int],\n",
    "        multiresModel: MultiresolutionModel,\n",
    "        feature_size: int = 2,\n",
    "        topk: int = 1,\n",
    "        num_levels: int | None = None,\n",
    "        hash_table_size: int | None = None,\n",
    "        should_circular_topk: bool = True,\n",
    "        should_learn_images: bool = False,\n",
    "        should_log: List[int] = []\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        batch_size : int\n",
    "            Batch size.\n",
    "        hidden_layers_widths : List[int]\n",
    "            List of hidden layers widths.\n",
    "        multiresModel : MultiresolutionModel\n",
    "            Multiresolution model.\n",
    "        feature_size : int, optional (default is 2)\n",
    "            Feature size.\n",
    "        topk : int, optional (default is 1)\n",
    "            Top k. If -1 then all the hashed coordinates are used.\n",
    "        num_levels : int | None, optional (default is None)\n",
    "            Number of levels. If None then MultiresolutionModel's num_levels is used.\n",
    "        hash_table_size : int | None, optional (default is None)\n",
    "            Hash table size. If None then MultiresolutionModel's hash_table_size is used.\n",
    "        should_circular_topk : bool, optional (default is True)\n",
    "            Whether to use circular topk or not.\n",
    "        should_learn_images : bool, optional (default is False)\n",
    "            Whether to learn the images or not.\n",
    "        should_log : List[int], optional (default is [])\n",
    "            List of decoded functions to log.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        super(GNGFModel, self).__init__()\n",
    "\n",
    "        self._batch_size: int = batch_size\n",
    "        self.multiresModel: MultiresolutionModel = multiresModel\n",
    "\n",
    "        self._feature_size: int = feature_size\n",
    "        self._topk: int = topk\n",
    "        self._num_levels: int = num_levels if num_levels is not None else self.multiresModel.get_num_levels()\n",
    "        self._hash_table_size: int = hash_table_size if hash_table_size is not None else self.multiresModel.get_hash_table_size()\n",
    "\n",
    "        self._should_circular_topk: bool = should_circular_topk\n",
    "        self._should_learn_images: bool = should_learn_images\n",
    "        self._should_log: List[int] = should_log\n",
    "\n",
    "        self.hash_tables: torch.nn.ModuleList = torch.nn.ModuleList([\n",
    "            torch.nn.ModuleList([\n",
    "                torch.nn.Embedding(self._hash_table_size, self._feature_size, device=device)\n",
    "                for _ in range(self._num_levels)\n",
    "            ])\n",
    "            for _ in range(self._batch_size)\n",
    "        ])\n",
    "        log((\"Hash table image 0 level 0:\", self.hash_tables[0][0].weight, self.hash_tables[0][0].weight.shape), self._should_log)\n",
    "\n",
    "        self._apply_init(torch.nn.init.uniform_, -1.0, 1.0)\n",
    "        log((\"Initialized hash table image 0 level 0:\", self.hash_tables[0][0].weight, self.hash_tables[0][0].weight.shape), self._should_log)\n",
    "\n",
    "        layers_widths = [(self._num_levels * self._feature_size), *hidden_layers_widths, 3]\n",
    "        self.mlp: nn.ModuleList = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(\n",
    "                    in_features=layers_widths[i], \n",
    "                    out_features=layers_widths[i + 1],\n",
    "                    device=device\n",
    "                ),\n",
    "                nn.ReLU() if (i < (len(layers_widths) - 2)) else nn.Sigmoid()\n",
    "            )\n",
    "            for i in range(len(layers_widths) - 1)\n",
    "        ])\n",
    "\n",
    "    def forward(\n",
    "        self, \n",
    "        x: torch.Tensor,\n",
    "        should_calc_hists: bool = False,\n",
    "        should_show_hists: bool = False\n",
    "    ) -> Tuple[torch.Tensor | None, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor | None, List[plt.Figure] | None]:\n",
    "        \n",
    "        hashed, sigmas, min_possible_collisions, collisions, coeffs, hists = self.multiresModel(x, should_calc_hists, should_show_hists)\n",
    "        del x\n",
    "\n",
    "        out = None\n",
    "        if self._should_learn_images:\n",
    "            out = self._look_up_features(hashed, sigmas)\n",
    "\n",
    "            out = self._bilinear_interpolation(out, coeffs)\n",
    "            del coeffs\n",
    "\n",
    "            for i, layer in enumerate(self.mlp):\n",
    "                out = layer(out)\n",
    "                log((f\"After layer {i}:\", out, out.shape, out.requires_grad, out.is_leaf), self._should_log)\n",
    "\n",
    "        return out, hashed, sigmas, min_possible_collisions, collisions, hists\n",
    "    \n",
    "    def _look_up_features(self, indices: torch.Tensor, sigmas: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Looks up features from the hash tables.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        indices : torch.Tensor\n",
    "            Hashed coordinates.\n",
    "        sigmas : torch.Tensor\n",
    "            Hashed coordinates' uncertainty.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            Looked up features.\n",
    "        \"\"\"\n",
    "        log((\"indices:\", indices, indices.shape, indices.requires_grad, indices.is_leaf), self._should_log)\n",
    "        log((\"sigmas:\", sigmas, sigmas.shape, sigmas.requires_grad, sigmas.is_leaf), self._should_log)\n",
    "\n",
    "        if self._topk == -1: # use all hashed coordinates\n",
    "            topks = torch.arange(\n",
    "                self._hash_table_size,\n",
    "                dtype=torch.float32,\n",
    "                device=device\n",
    "            )\n",
    "        else:\n",
    "            topks = torch.arange(\n",
    "                -(self._topk // 2), (self._topk // 2) + 1,\n",
    "                dtype=torch.float32,\n",
    "                device=device\n",
    "            )\n",
    "        log((\"topks:\", topks, topks.shape), self._should_log, color=bcolors.FAIL)\n",
    "\n",
    "        new_indices = indices + topks\n",
    "\n",
    "        if self._should_circular_topk: # CIRCULAR IMPLEMENTATION\n",
    "            new_indices = torch.remainder(new_indices, self._hash_table_size)\n",
    "        else: # LINEAR IMPLEMENTATION\n",
    "            new_indices[new_indices < 0] = 0\n",
    "            new_indices[new_indices >= self._hash_table_size] = self._hash_table_size - 1\n",
    "        log((\"new_indices:\", new_indices, new_indices.shape), self._should_log)\n",
    "\n",
    "        looked_up: torch.Tensor = rearrange(\n",
    "            torch.stack([\n",
    "                torch.stack([\n",
    "                    self.hash_tables[b][l](\n",
    "                        x[:, l, :, :].int()\n",
    "                    )\n",
    "                    for l in range(self._num_levels)\n",
    "                ])\n",
    "                for b, x in enumerate(new_indices)\n",
    "            ]),\n",
    "            \"batch levels pixels verts k features -> batch pixels levels features verts k\"\n",
    "        )\n",
    "        log((\"looked_up:\", looked_up, looked_up.shape), self._should_log)\n",
    "\n",
    "        del new_indices\n",
    "\n",
    "        # Calculate the Gaussian probabilities\n",
    "        gaussian_probs = (\n",
    "            torch.exp(-(1/2) * ((topks - 0) / (sigmas))**2) / ((sigmas) * torch.sqrt(2 * torch.tensor(np.pi)))\n",
    "        ).unsqueeze(3)\n",
    "        log((\"gaussian_probs:\", gaussian_probs, gaussian_probs.shape), self._should_log, color=bcolors.WARNING)\n",
    "        del topks\n",
    "\n",
    "        # (weighted avg) sum(looked_up * topk)/sum(topk)\n",
    "        looked_up = rearrange(\n",
    "            torch.sum(looked_up * gaussian_probs, dim=-1) / torch.sum(gaussian_probs, dim=-1),\n",
    "            \"batch pixels levels features verts -> batch pixels features levels verts\"\n",
    "        )\n",
    "        log((\"Weighted avg looked_up:\", looked_up, looked_up.shape), self._should_log)\n",
    "\n",
    "        del gaussian_probs\n",
    "\n",
    "        return looked_up\n",
    "\n",
    "    def _bilinear_interpolation(self, features: torch.Tensor, coeffs: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Bilinear interpolate features with coefficients.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        features : torch.Tensor\n",
    "            Features to interpolate.\n",
    "        coeffs : torch.Tensor\n",
    "            Coefficients for bilinear interpolation.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            Interpolated features.\n",
    "        \"\"\"\n",
    "        log((\"coeffs:\", coeffs, coeffs.shape), self._should_log)\n",
    "        log((\"features:\", features, features.shape), self._should_log)\n",
    "\n",
    "        weighted_features: torch.Tensor = features * coeffs\n",
    "        del features\n",
    "        del coeffs\n",
    "        log((\"weighted_features:\", weighted_features, weighted_features.shape), self._should_log)\n",
    "\n",
    "        weighted_summed_features: torch.Tensor = torch.sum(weighted_features, dim=-1)#.to(device)\n",
    "        del weighted_features\n",
    "        log((\"weighted_summed_features:\", weighted_summed_features, weighted_summed_features.shape), self._should_log)\n",
    "        \n",
    "        stack: torch.Tensor = rearrange(weighted_summed_features, \"batch pixels features levels -> batch pixels (levels features)\")#.to(device)\n",
    "        del weighted_summed_features\n",
    "        log((\"stacked:\", stack, stack.shape), self._should_log)\n",
    "\n",
    "        return stack\n",
    "    \n",
    "    def _apply_init(self, init_func, *args) -> None:\n",
    "        \"\"\"\n",
    "        Initializes the hash tables weights with a random uniform function\n",
    "        \"\"\"\n",
    "        for b in range(self._batch_size):\n",
    "            for i in range(self._num_levels):\n",
    "                init_func(self.hash_tables[b][i].weight, *args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics, Loss and Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(predicted: np.ndarray, target: np.ndarray, size: int) -> float:\n",
    "    return (np.equal(predicted, target).sum() / size) * 100\n",
    "\n",
    "def calc_psnr(pred: np.ndarray, target: np.ndarray) -> float:\n",
    "    mse = np.square(pred - target).mean()\n",
    "    return 20 * np.log10(np.max(target)) - 10 * np.log10(mse) # psne\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        hash_table_size: int,\n",
    "        kl_div_reduction: str = \"batchmean\",\n",
    "        should_use_all_levels: bool = False,\n",
    "        should_log: List[int] = []\n",
    "\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        hash_table_size : int\n",
    "            Hash table size.\n",
    "        kl_div_reduction : str, optional (default is \"batchmean\")\n",
    "            KL divergence reduction.\n",
    "        should_use_all_levels : bool, optional (default is False)\n",
    "            Whether to use all levels or only the ones with collisions.\n",
    "        should_log : List[int], optional (default is [])\n",
    "            List of decoded functions to log.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        super(Loss, self).__init__()\n",
    "\n",
    "        self._hash_table_size: int = hash_table_size\n",
    "\n",
    "        self._should_use_all_levels: bool = should_use_all_levels\n",
    "        self._should_log: List[int] = should_log\n",
    "\n",
    "        self._KLDiv: nn.KLDivLoss = nn.KLDivLoss(reduction=kl_div_reduction)\n",
    "        self._sigmas_MSE: nn.MSELoss = nn.MSELoss(reduction=\"mean\")\n",
    "        self._images_MSE: nn.MSELoss = nn.MSELoss(reduction=\"mean\")\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        min_possible_collisions: torch.Tensor,\n",
    "        indices: torch.Tensor,\n",
    "        sigmas: torch.Tensor,\n",
    "        collisions: torch.Tensor | None = None,\n",
    "        pred: torch.Tensor | None = None,\n",
    "        target: torch.Tensor | None = None,\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor | None, torch.Tensor | None]:\n",
    "        \n",
    "        levels: int = min_possible_collisions.shape[0]\n",
    "\n",
    "        collisions_losses: torch.Tensor | None = None\n",
    "        # if collisions is not None:\n",
    "        #     delta: torch.Tensor = min_possible_collisions.clone()\n",
    "        #     delta[delta <= 0] = 1\n",
    "\n",
    "        #     collisions_losses: torch.Tensor = (collisions - min_possible_collisions) / delta\n",
    "        #     log((\"collisions_losses:\", collisions_losses, collisions_losses.shape, collisions_losses.requires_grad, collisions_losses.is_leaf), self._should_log)\n",
    "\n",
    "        kl_div_losses: torch.Tensor = torch.zeros(levels, device=device)\n",
    "        for l in range(levels):\n",
    "            if not self._should_use_all_levels and min_possible_collisions[l] <= 0:\n",
    "                continue\n",
    "\n",
    "            kl_div_losses[l] = self._kl_div(self._calc_hist_pdf(indices[l]))\n",
    "        log((\"kl_div_losses:\", kl_div_losses, kl_div_losses.shape, kl_div_losses.requires_grad, kl_div_losses.is_leaf), self._should_log)\n",
    "        \n",
    "        sigmas_losses: torch.Tensor = torch.stack([\n",
    "            self._sigmas_MSE(sigmas[l], torch.zeros_like(sigmas[l]))\n",
    "            for l in range(levels)\n",
    "        ])\n",
    "        log((\"sigmas_losses:\", sigmas_losses, sigmas_losses.shape, sigmas_losses.requires_grad, sigmas_losses.is_leaf), self._should_log)\n",
    "\n",
    "        images_losses: torch.Tensor | None = None\n",
    "        if pred is not None and target is not None:\n",
    "            batch_size = pred.shape[0]\n",
    "\n",
    "            images_losses: torch.Tensor = torch.stack([\n",
    "                self._images_MSE(pred[b], target[b])\n",
    "                for b in range(batch_size)\n",
    "            ])\n",
    "            log((\"images_losses:\", images_losses, images_losses.shape, images_losses.requires_grad, images_losses.is_leaf), self._should_log)\n",
    "\n",
    "        return kl_div_losses, sigmas_losses, collisions_losses, images_losses\n",
    "\n",
    "    def _calc_hist_pdf(\n",
    "        self,\n",
    "        indices: torch.Tensor,\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Calculates the histogram pdf.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        indices : torch.Tensor\n",
    "            Hashed coordinates.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            Histogram pdf.\n",
    "        \"\"\"\n",
    "        log((\"indices:\", indices, indices.shape, indices.requires_grad, indices.is_leaf), self._should_log)\n",
    "\n",
    "        hist_p = differentiable_histogram(indices, bins=self._hash_table_size, min=0, max=self._hash_table_size, should_log=self._should_log).squeeze(0).squeeze(0)\n",
    "        log((f\"hist_p_diff   : {hist_p.long()}, shape: {hist_p.shape}, sum: {torch.sum(hist_p)}, requires_grad: {hist_p.requires_grad}\", ), self._should_log)\n",
    "\n",
    "        # Real implemenation of histogram pdf, but not differentiable\n",
    "        # hist_p_nondiff = torch.histc(indices, bins=self._hash_table_size, min=0, max=self._hash_table_size) # ? maybe max=(self._hash_table_size - 1)\n",
    "        # log((f\"hist_p_nondiff: {hist_p_nondiff}, shape: {hist_p_nondiff.shape}, sum: {torch.sum(hist_p_nondiff)}, requires_grad: {hist_p_nondiff.requires_grad}\", ), self._should_log, color=bcolors.WARNING)\n",
    "        del indices\n",
    "\n",
    "        p = hist_p / torch.sum(hist_p)\n",
    "        log((\"p:\", p, p.shape, p.requires_grad, p.is_leaf), self._should_log)\n",
    "\n",
    "        del hist_p\n",
    "\n",
    "        p[p == 0] = 1e-10\n",
    "        # log((\"p after:\", p, p.shape, p.requires_grad, p.is_leaf), self._should_log)\n",
    "\n",
    "        return p\n",
    "\n",
    "    def _kl_div(\n",
    "        self,\n",
    "        p: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Calculates the KL divergence.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        p : torch.Tensor\n",
    "            Histogram pdf.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            KL divergence.\n",
    "        \"\"\"\n",
    "        log((\"p:\", p, p.shape, p.requires_grad, p.is_leaf), self._should_log)\n",
    "\n",
    "        q = torch.ones(\n",
    "            self._hash_table_size, \n",
    "            device=device\n",
    "        ) / self._hash_table_size\n",
    "        log((\"q:\", q, q.shape, q.requires_grad, q.is_leaf), self._should_log)\n",
    "\n",
    "        kl_div_loss = self._KLDiv(p.log(), q)\n",
    "        log((\"kl_div_loss:\", kl_div_loss, kl_div_loss.shape, kl_div_loss.requires_grad, kl_div_loss.is_leaf), self._should_log)\n",
    "        \n",
    "        del p\n",
    "        del q\n",
    "\n",
    "        return kl_div_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(\n",
    "    models_parameters: Dict[str, Any],\n",
    "    optimizers: List[torch.optim.Optimizer] = [torch.optim.Adam, torch.optim.AdamW],\n",
    ") -> Dict[str, torch.optim.Optimizer]:\n",
    "    \n",
    "    optims = {}\n",
    "    \n",
    "    for model, optimizer in zip(models_parameters.items(), optimizers):\n",
    "        models_params = []\n",
    "\n",
    "        for m in model[1][\"each\"]:\n",
    "            param, lr, weight_decay= m.values()\n",
    "\n",
    "            models_params.append({\n",
    "                \"params\": param, \"lr\": lr, \"weight_decay\": weight_decay\n",
    "            })\n",
    "        \n",
    "        betas = model[1][\"betas\"]\n",
    "        eps = model[1][\"eps\"]\n",
    "\n",
    "        optims[model[0]] = optimizer(\n",
    "            models_params,\n",
    "            betas=betas,\n",
    "            eps=eps,\n",
    "        )\n",
    "    \n",
    "    return optims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Test Loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(\n",
    "    x: torch.Tensor,\n",
    "    y: torch.Tensor,\n",
    "    h: int,\n",
    "    w: int,\n",
    "    model: nn.Module,\n",
    "    optimizers: List[torch.optim.Optimizer],\n",
    "    loss_fn: nn.Module,\n",
    "    l_kl_loss: float,\n",
    "    l_sigmas_loss: float,\n",
    "    l_collisions_loss: float,\n",
    "    l_images_loss: float,\n",
    "    l_reg_loss: float,\n",
    "    norm_regularization_order: int = 2,\n",
    "    gradient_clipping: float | None = None,\n",
    "    should_calc_hists: bool = False,\n",
    "    should_learn_images: bool = False,\n",
    "    excluded_params_from_reg_loss: List[str] = [\"_prime_numbers\", \"hash_tables\", \"mlp\"],\n",
    "    should_log: List[int] = [],\n",
    "    should_log_grads: bool = False,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Trains the model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : torch.Tensor\n",
    "        Input data.\n",
    "    y : torch.Tensor\n",
    "        Target data.\n",
    "    h : int\n",
    "        Imags height.\n",
    "    w : int\n",
    "        Images width.\n",
    "    model : nn.Module\n",
    "        Model to train.\n",
    "    optimizers : List[torch.optim.Optimizer]\n",
    "        List of optimizers.\n",
    "    loss_fn : nn.Module\n",
    "        Loss function.\n",
    "    l_kl_loss : float\n",
    "        KL divergence loss lambda.\n",
    "    l_sigmas_loss : float\n",
    "        Sigmas loss lambda.\n",
    "    l_collisions_loss : float\n",
    "        Collisions loss lambda.\n",
    "    l_images_loss : float\n",
    "        Images loss lambda.\n",
    "    l_reg_loss : float\n",
    "        Regularization loss lambda.\n",
    "    norm_regularization_order : int, optional (default is 2)\n",
    "        Norm regularization order.\n",
    "    gradient_clipping : float | None, optional (default is None)\n",
    "        Gradient clipping value. If None then no clipping is applied.\n",
    "    should_calc_hists : bool, optional (default is False)\n",
    "        Whether to calculate histograms or not.\n",
    "    should_learn_images : bool, optional (default is False)\n",
    "        Whether to learn the images or not.\n",
    "    excluded_params_from_reg_loss : List[str], optional (default is [\"_prime_numbers\", \"hash_tables\", \"mlp])\n",
    "        List of parameters to exclude from the regularization loss.\n",
    "    should_log : List[int], optional (default is [])\n",
    "        - 1: Log\n",
    "        - 2: Log and plot.\n",
    "    should_log_grads : bool, optional (default is False)\n",
    "        Whether to log the gradients or not.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Dict[str, Any]\n",
    "        Dictionary with the loss and the predictions.\n",
    "    \"\"\"\n",
    "    log((\"Train loop\", ), should_log, color=bcolors.WARNING)\n",
    "\n",
    "    model.train()\n",
    "    for key, optimizer in optimizers.items():\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    pred, hashed, sigmas, min_possible_collisions, collisions, hists = model(x, should_calc_hists=should_calc_hists, should_show_hists=(2 in should_log))\n",
    "\n",
    "    # print(torch.count_nonzero(hashed[0] != hashed[1])) # == 0\n",
    "    # print(torch.count_nonzero(sigmas[0] != sigmas[1])) # == 0\n",
    "    \n",
    "    if should_learn_images:\n",
    "        log((\"pred:\", pred, pred.shape, pred.requires_grad, pred.is_leaf), should_log)\n",
    "\n",
    "    kl_div_losses, sigmas_losses, collisions_losses, images_losses = loss_fn(\n",
    "        min_possible_collisions=min_possible_collisions,\n",
    "        indices=rearrange(hashed, \"batch pixels levels verts 1 -> batch levels pixels (verts 1)\")[0],\n",
    "        sigmas=rearrange(sigmas, \"batch pixels levels verts 1 -> batch levels pixels (verts 1)\")[0],\n",
    "        pred=pred,\n",
    "        target=y,\n",
    "        collisions=collisions,\n",
    "    )\n",
    "    log((\"kl_div_losses:\", kl_div_losses, kl_div_losses.shape, kl_div_losses.requires_grad, kl_div_losses.is_leaf), should_log)\n",
    "    log((\"sigmas_losses:\", sigmas_losses, sigmas_losses.shape, sigmas_losses.requires_grad, sigmas_losses.is_leaf), should_log)\n",
    "    if collisions_losses is not None:\n",
    "        log((\"collisions_losses:\", collisions_losses, collisions_losses.shape, collisions_losses.requires_grad, collisions_losses.is_leaf), should_log)\n",
    "    if images_losses is not None:\n",
    "        log((\"images_losses:\", images_losses, images_losses.shape, images_losses.requires_grad, images_losses.is_leaf), should_log)\n",
    "\n",
    "    regularization_loss = torch.tensor(0.0, device=device)\n",
    "    for name, param in model.named_parameters():\n",
    "        # if np.sum(np.isin(np.array(name.split('.')), excluded_params_from_reg_loss)) == 0:\n",
    "        if not any([excluded_param in name for excluded_param in excluded_params_from_reg_loss]):\n",
    "            # print(name)\n",
    "            regularization_loss += torch.linalg.norm(param, ord=norm_regularization_order)\n",
    "\n",
    "    loss = (\n",
    "        (l_kl_loss * torch.sum(kl_div_losses)) +\n",
    "        (l_sigmas_loss * torch.sum(sigmas_losses)) +\n",
    "        ( \n",
    "            (l_collisions_loss * torch.sum(collisions_losses)) \n",
    "            if collisions_losses is not None else\n",
    "            torch.tensor(0.0, device=device)\n",
    "        ) +\n",
    "        (\n",
    "            (l_images_loss * torch.sum(images_losses)) \n",
    "            if images_losses is not None else\n",
    "            torch.tensor(0.0, device=device)\n",
    "        ) +\n",
    "        (l_reg_loss * regularization_loss)\n",
    "    )\n",
    "    log((\"loss:\", loss, loss.shape, loss.requires_grad, loss.is_leaf), should_log)\n",
    "\n",
    "    if gradient_clipping is not None:\n",
    "        torch.nn.utils.clip_grad_norm_(model.multiresModel.hashModel.parameters(), gradient_clipping)\n",
    "\n",
    "    if should_log_grads:\n",
    "        if pred is not None:\n",
    "            pred.retain_grad()\n",
    "        hashed.retain_grad()\n",
    "        sigmas.retain_grad()\n",
    "    \n",
    "    loss.backward()\n",
    "\n",
    "    if should_log_grads:\n",
    "        if pred is not None:\n",
    "            log((\"Pred gradient: \", pred.grad, pred.grad_fn, pred.shape), True, color=bcolors.OKGREEN)\n",
    "        log((\"Hashed gradient: \", hashed.grad, hashed.grad_fn, hashed.shape), True, color=bcolors.OKGREEN)\n",
    "        log((\"Sigmas gradient: \", sigmas.grad, sigmas.grad_fn, sigmas.shape), True, color=bcolors.OKGREEN)\n",
    "\n",
    "\n",
    "    for key, optimizer in optimizers.items():\n",
    "        # TODO HOW?\n",
    "        ######\n",
    "        # Lastly, we skip Adam steps for hash table entries whose gradient is exactly 0. \n",
    "        # This saves ∼ 10% performance when gradients are sparse, which is a common occurrence with 𝑇 ≫ BatchSize. \n",
    "        # Even though this heuristic violates some of the assumptions behind Adam, we observe no degradation in convergence.\n",
    "        ######\n",
    "        optimizer.step()\n",
    "\n",
    "    pred_images = None\n",
    "    target_images = None\n",
    "    images_psnr = None\n",
    "    if should_learn_images:\n",
    "        pred_images = (pred * 255).reshape(-1, h, w, 3).to(int).detach().cpu().numpy()\n",
    "        target_images = (y * 255).reshape(-1, h, w, 3).to(int).detach().cpu().numpy()\n",
    "\n",
    "        plot_images(pred_images, target_images, should_log)\n",
    "\n",
    "        images_psnr = [calc_psnr(pred_images[i], target_images[i]) for i in range(pred_images.shape[0])]\n",
    "\n",
    "    to_return = {\n",
    "        \"pred_images\": pred_images,\n",
    "        \"target_images\": target_images,\n",
    "        \"images_psnr\": images_psnr,\n",
    "        \"min_possible_collisions\": min_possible_collisions.detach().cpu().numpy(),\n",
    "        \"collisions\": collisions.detach().cpu().numpy() if collisions is not None else None,\n",
    "        \"histograms\": hists,\n",
    "        \"kl_div_losses\": kl_div_losses.detach().cpu().numpy(),\n",
    "        \"sigmas_losses\": sigmas_losses.detach().cpu().numpy(),\n",
    "        \"reg_loss\": regularization_loss.item(),\n",
    "        \"collisions_losses\": collisions_losses.detach().cpu().numpy() if collisions_losses is not None else None,\n",
    "        \"images_losses\": images_losses.detach().cpu().numpy() if images_losses is not None else None,\n",
    "        \"loss\": loss.item(),\n",
    "    }\n",
    "\n",
    "    return to_return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early Stopper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopper:\n",
    "    def __init__(self, tolerance: int = 5, min_delta: int = 0, should_reset: bool = True):\n",
    "        self.tolerance: int = tolerance\n",
    "        self.min_delta: int = min_delta\n",
    "        self.best_loss: float = np.inf\n",
    "        self.counter: int = 0\n",
    "        self.early_stop: bool = False\n",
    "        self._should_reset: bool = should_reset\n",
    "\n",
    "    def __call__(self, loss):\n",
    "        # print(f\"best_loss: {self.best_loss}, loss: {loss}, counter: {self.counter}\")\n",
    "\n",
    "        if abs(self.best_loss - loss) < self.min_delta and (loss < self.best_loss):\n",
    "            # print(\"Stall\")\n",
    "            self.counter += 1\n",
    "        elif abs(self.best_loss - loss) > self.min_delta and (loss > self.best_loss):\n",
    "            # print(\"Growing\")\n",
    "            self.counter += 1\n",
    "        else:\n",
    "            if not self._should_reset:\n",
    "                if self.counter <= 0:\n",
    "                    self.counter = 0\n",
    "                else:\n",
    "                    self.counter -= 1\n",
    "            else:\n",
    "                self.counter = 0\n",
    "                self.best_loss = loss\n",
    "\n",
    "        if self.counter >= self.tolerance:\n",
    "            self.early_stop = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN: 20240121114900\n",
      "\u001b[95m Line:  print_allocated_memory(should_log_allocated_memory) , from:  <module> \u001b[0m\n",
      "Allocated Memory: 0.00 GB\n",
      "Peak Allocated Memory: 0.00 GB\n",
      "\u001b[96m -------------------- \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "train_images_paths = [\"./images/macaw2.jpg\"]\n",
    "\n",
    "wandb_entity = \"fedemonti00\"\n",
    "wandb_project = \"project_course_hashfunction_refactor\"\n",
    "# wandb_name = \"hash_function_training\"\n",
    "\n",
    "try:\n",
    "    time = wandb_name\n",
    "except NameError:\n",
    "    time = (datetime.now(ZoneInfo(\"Europe/Rome\"))).strftime(\"%Y%m%d%H%M%S\")\n",
    "print(\"RUN:\", time)\n",
    "\n",
    "should_fast_hash = False\n",
    "should_learn_images = False\n",
    "scheduler_type = \"CosineAnnealingWarmRestarts\" # None, \"StepLR\", \"CosineAnnealingLR\", \"CosineAnnealingWarmRestarts\"\n",
    "\n",
    "hyperparameters = {\n",
    "    # General\n",
    "    \"xavier_initialization\": None, # None, \"unifrom\", \"normal\"\n",
    "    \"epochs\": 1,\n",
    "    \"random_seed\": random_seed,\n",
    "    # ------- #\n",
    "    # Dataset\n",
    "    \"images_paths\": train_images_paths,\n",
    "\n",
    "    \"should_randomize_input\": False,\n",
    "    # ------- #\n",
    "    # HashFunctionModel\n",
    "    \"hash_hidden_layers_widths\": [64],\n",
    "    \"output_size\": 2,\n",
    "    \"hash_table_size\": 2**8,\n",
    "    \"sigmas_scale\": 1.0,\n",
    "    \"hidden_layers_activation\": nn.Tanh(),\n",
    "\n",
    "    \"hash_lr\": 1e-3 if not should_fast_hash else None,\n",
    "    \"hash_weight_decay\": 0 if not should_fast_hash else None, # 1e-6\n",
    "    # ------- #\n",
    "    # MultiresolutionModel\n",
    "    \"n_min\": 8,\n",
    "    \"n_max\": 32,\n",
    "    \"num_levels\": 4,\n",
    "    \n",
    "    \"should_fast_hash\": should_fast_hash,\n",
    "    \"should_use_all_levels\": False if not should_fast_hash else True,\n",
    "    \"should_calc_collisions\": True,\n",
    "    # ------- #\n",
    "    # GNGFModel\n",
    "    \"feature_size\": 2,\n",
    "    \"gngf_hidden_layers_widths\": [64, 64],\n",
    "    \"topk\": 5, # must be odd or -1 to use all the hashed coordinates\n",
    "\n",
    "    \"features_lr\": 1e-3,\n",
    "    \"features_weight_decay\": 0,\n",
    "    \"mlp_lr\": 1e-2,\n",
    "    \"mlp_weight_decay\": 1e-6,\n",
    "\n",
    "    \"should_circular_topk\": True,\n",
    "    \"should_learn_images\": should_learn_images if not should_fast_hash else True,\n",
    "    # ------- #\n",
    "    # Loss\n",
    "    \"kl_div_reduction\": \"sum\",\n",
    "\n",
    "    \"l_kl_loss\": 1.0,\n",
    "    \"l_sigmas_loss\": 0.0,\n",
    "    \"l_collisions_loss\": 0.0,\n",
    "    \"l_images_loss\": 0.0 if not should_learn_images else 1e2,\n",
    "    \"l_reg_loss\": 1e-6,\n",
    "    \"norm_regularization_order\": 2,\n",
    "\n",
    "    \"excluded_params_from_reg_loss\": np.array([\"_prime_numbers\", \"hash_tables\", \"mlp\"]),\n",
    "\n",
    "    \"gradient_clipping\": None if not should_fast_hash else None, # None to disable\n",
    "    # ------- #\n",
    "    # Optimizer & Scheduler\n",
    "    \"NeRF_optimizer\": torch.optim.Adam if should_learn_images else None,\n",
    "    \"hash_optimizer\": torch.optim.AdamW if not should_fast_hash else None,\n",
    "\n",
    "    # only for hash function model\n",
    "    \"scheduler_type\": scheduler_type if not should_fast_hash else None,\n",
    "    \"scheduler_gamma\": None if not scheduler_type else (0.9 if scheduler_type == \"StepLR\" else 1e-5),\n",
    "    \"scheduler_step_size\": None if not scheduler_type else (100 if scheduler_type == \"StepLR\" else 1000),\n",
    "    # ------- #\n",
    "}\n",
    "\n",
    "histograms_rate = 10\n",
    "save_weights_rate = None # None to disable\n",
    "\n",
    "early_stopper_tolerance = hyperparameters[\"epochs\"] // 10 if hyperparameters[\"epochs\"] > 99 else hyperparameters[\"epochs\"]\n",
    "early_stopper_min_delta = 1e-4\n",
    "\n",
    "should_log = True\n",
    "# should_log = False\n",
    "should_log_allocated_memory = True if should_log else False\n",
    "should_log_grads = True if should_log else False\n",
    "should_wandb = True if hyperparameters[\"epochs\"] > 99 else False\n",
    "\n",
    "print_allocated_memory(should_log_allocated_memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xavier Weights Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xavier_init_weights(model: nn.Module):\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "            # Applying Xavier initialization to linear and convolutional layers\n",
    "            if hyperparameters[\"xavier_initialization\"] == \"uniform\":\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "            elif hyperparameters[\"xavier_initialization\"] == \"normal\":\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if should_wandb:\n",
    "    wandb.init(\n",
    "        entity=wandb_entity,\n",
    "        project=wandb_project,\n",
    "        name=time,\n",
    "        config=hyperparameters,\n",
    "        save_code=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wandb_log(\n",
    "    e: int,\n",
    "    batch_size: int,\n",
    "    train_obj: Dict[str, Any],\n",
    "    lr: float | None = None,\n",
    "    should_log: bool = False,\n",
    "    should_wandb: bool = False\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    e : int\n",
    "        Epoch.\n",
    "    train_obj : Dict[str, Any]\n",
    "        Training object.\n",
    "    lr : float | None, optional (default is None)\n",
    "        Learning rate.\n",
    "    should_log : bool, optional (default is False)\n",
    "        Whether to log or not.\n",
    "    should_wandb : bool, optional (default is False)\n",
    "        Whether to log to wandb or not.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    \n",
    "    to_log = {}\n",
    "\n",
    "    if lr is not None:\n",
    "        to_log[\"lr\"] = lr\n",
    "\n",
    "    for key, values in train_obj.items():\n",
    "        if values is not None:\n",
    "            if isinstance(values, np.ndarray) or isinstance(values, List):\n",
    "                for i, value in enumerate(values):\n",
    "                    num = (\"level_\" if (len(values) > batch_size) else \"\") + str(i)\n",
    "\n",
    "                    if isinstance(value, plt.Figure) or isinstance(value, np.ndarray):\n",
    "                        to_log[f\"train/media/{key}_{num}\"] = wandb.Image(value)\n",
    "                    else:\n",
    "                        to_log[f\"train/{key}_{num}\"] = value\n",
    "            else:\n",
    "                to_log[f\"train/{key}\"] = values\n",
    "\n",
    "    log((\"log:\", to_log), should_log)\n",
    "    if should_wandb:\n",
    "        wandb.log(to_log)\n",
    "\n",
    "    del to_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ImageDataset(\n",
    "    train_images_paths,\n",
    "    should_randomize_input=hyperparameters[\"should_randomize_input\"],\n",
    "    should_log=[]\n",
    "    # should_log=[0]\n",
    ")\n",
    "\n",
    "X, Y, h, w, reordered_indices = data[-1].values()\n",
    "\n",
    "batch_size = X.shape[0]\n",
    "input_size = X.shape[2] # X = (batch, pixels, input_dim, 1, 1) \n",
    "\n",
    "# print(torch.count_nonzero(X[0] != random_X[0][random_reordered_indices[0, :]]))\n",
    "# print(torch.count_nonzero(X[1] != random_X[1][random_reordered_indices[1, :]]))\n",
    "# print(torch.count_nonzero(a[\"X\"]!= b[\"X\"][..., :][b[\"reordered_indices\"]]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNGFModel(\n",
      "  (multiresModel): MultiresolutionModel(\n",
      "    (hashModel): HashFunctionModel(\n",
      "      (_module_list): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): Linear(in_features=2, out_features=64, bias=True)\n",
      "          (1): Tanh()\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): Linear(in_features=64, out_features=2, bias=True)\n",
      "          (1): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (hash_tables): ModuleList(\n",
      "    (0): ModuleList(\n",
      "      (0-3): 4 x Embedding(256, 2)\n",
      "    )\n",
      "  )\n",
      "  (mlp): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=8, out_features=64, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=3, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "if not hyperparameters[\"should_fast_hash\"]:\n",
    "    hashFunctionModel = HashFunctionModel(\n",
    "        hidden_layers_widths=hyperparameters[\"hash_hidden_layers_widths\"],\n",
    "        input_size=input_size,\n",
    "        output_size=hyperparameters[\"output_size\"],\n",
    "        hash_table_size=hyperparameters[\"hash_table_size\"],\n",
    "        sigmas_scale=hyperparameters[\"sigmas_scale\"],\n",
    "        hidden_layers_activation=hyperparameters[\"hidden_layers_activation\"],\n",
    "        should_log=[] if should_log else []\n",
    "        # should_log=[0, 1, 2] if should_log else []\n",
    "    )\n",
    "\n",
    "    if hyperparameters[\"xavier_initialization\"] is not None:\n",
    "        hashFunctionModel.apply(xavier_init_weights)\n",
    "\n",
    "multiresolutionModel = MultiresolutionModel(\n",
    "    n_min=hyperparameters[\"n_min\"],\n",
    "    n_max=hyperparameters[\"n_max\"],\n",
    "    num_levels=hyperparameters[\"num_levels\"],\n",
    "    hashModel=None if hyperparameters[\"should_fast_hash\"] else hashFunctionModel,\n",
    "    hash_table_size=hyperparameters[\"hash_table_size\"] if hyperparameters[\"should_fast_hash\"] else None ,\n",
    "    input_size=input_size if hyperparameters[\"should_fast_hash\"] else None,\n",
    "    should_use_all_levels=hyperparameters[\"should_use_all_levels\"],\n",
    "    should_fast_hash=hyperparameters[\"should_fast_hash\"],\n",
    "    should_calc_collisions=hyperparameters[\"should_calc_collisions\"],\n",
    "    should_log=[] if should_log else []\n",
    "    # should_log=[0, 1, 2, 3, 4, 5, 6, 7, 8] if should_log else []\n",
    ")\n",
    "\n",
    "gngfModel = GNGFModel(\n",
    "    batch_size=batch_size,\n",
    "    hidden_layers_widths=hyperparameters[\"gngf_hidden_layers_widths\"],\n",
    "    multiresModel=multiresolutionModel,\n",
    "    feature_size=hyperparameters[\"feature_size\"],\n",
    "    topk=hyperparameters[\"topk\"],\n",
    "    should_circular_topk=hyperparameters[\"should_circular_topk\"],\n",
    "    should_learn_images=hyperparameters[\"should_learn_images\"],\n",
    "    should_log=[] if should_log else []\n",
    "    # should_log=[0, 1, 2, 3] if should_log else []\n",
    ")\n",
    "\n",
    "print(gngfModel)\n",
    "\n",
    "loss_fn = Loss(\n",
    "    hash_table_size=hyperparameters[\"hash_table_size\"],\n",
    "    kl_div_reduction=hyperparameters[\"kl_div_reduction\"],\n",
    "    should_use_all_levels=hyperparameters[\"should_use_all_levels\"],\n",
    "    should_log=[] if should_log else []\n",
    "    # should_log=[0, 1, 2, 3, 4] if should_log else []\n",
    ")\n",
    "\n",
    "models_parameters = {}\n",
    "opts = []\n",
    "if hyperparameters[\"should_learn_images\"]:\n",
    "    models_parameters[\"NeRF\"] = {\n",
    "        \"each\": [ # TODO cambiare nome\n",
    "            {\n",
    "                \"param\": gngfModel.hash_tables.parameters(),\n",
    "                \"lr\": hyperparameters[\"features_lr\"],\n",
    "                \"weight_decay\": hyperparameters[\"features_weight_decay\"]\n",
    "            },\n",
    "            {\n",
    "                \"param\": gngfModel.mlp.parameters(),\n",
    "                \"lr\": hyperparameters[\"mlp_lr\"],\n",
    "                \"weight_decay\": hyperparameters[\"mlp_weight_decay\"]\n",
    "            }\n",
    "        ],\n",
    "        \"betas\": (0.9, 0.99),\n",
    "        \"eps\": 1e-15\n",
    "    }\n",
    "    opts.append(hyperparameters[\"NeRF_optimizer\"])\n",
    "\n",
    "if not hyperparameters[\"should_fast_hash\"]:\n",
    "    models_parameters[\"hash\"] = {\n",
    "        \"each\": [ # TODO cambiare nome\n",
    "            {\n",
    "                \"param\": gngfModel.multiresModel.hashModel.parameters(),\n",
    "                \"lr\": hyperparameters[\"hash_lr\"],\n",
    "                \"weight_decay\": hyperparameters[\"hash_weight_decay\"]\n",
    "            }\n",
    "        ],\n",
    "        \"betas\": (0.9, 0.999), # default values\n",
    "        \"eps\": 1e-8 # default value\n",
    "    }\n",
    "    opts.append(hyperparameters[\"hash_optimizer\"])\n",
    "\n",
    "optimizers = get_optimizer(\n",
    "    models_parameters=models_parameters,\n",
    "    optimizers=opts,\n",
    ")\n",
    "\n",
    "if hyperparameters[\"scheduler_type\"] == \"CosineAnnealingLR\":\n",
    "    scheduler = CosineAnnealingLR(optimizers[\"hash\"], T_max=hyperparameters[\"scheduler_step_size\"], eta_min=hyperparameters[\"scheduler_gamma\"])\n",
    "elif hyperparameters[\"scheduler_type\"] == \"CosineAnnealingWarmRestarts\":\n",
    "    scheduler = CosineAnnealingWarmRestarts(optimizers[\"hash\"], T_0=hyperparameters[\"scheduler_step_size\"], T_mult=1, eta_min=hyperparameters[\"scheduler_gamma\"])\n",
    "elif hyperparameters[\"scheduler_type\"] == \"StepLR\":\n",
    "    scheduler = StepLR(optimizers[\"hash\"], step_size=hyperparameters[\"scheduler_step_size\"], gamma=hyperparameters[\"scheduler_gamma\"])\n",
    "\n",
    "early_stopper = EarlyStopper(\n",
    "    tolerance=early_stopper_tolerance, \n",
    "    min_delta=early_stopper_min_delta\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95m Line:  print_allocated_memory(should_log_allocated_memory) , from:  <module> \u001b[0m\n",
      "Allocated Memory: 0.00 GB\n",
      "Peak Allocated Memory: 0.00 GB\n",
      "\u001b[96m -------------------- \u001b[0m\n",
      "\u001b[92m Line:  log((\"Hashed gradient: \", hashed.grad, hashed.grad_fn, hashed.shape), True, color=bcolors.OKGREEN) \u001b[0m\n",
      "Hashed gradient:  tensor([[[[[ 0.0000e+00],\n",
      "           [ 0.0000e+00],\n",
      "           [ 0.0000e+00],\n",
      "           [ 0.0000e+00]],\n",
      "\n",
      "          [[ 0.0000e+00],\n",
      "           [ 0.0000e+00],\n",
      "           [ 0.0000e+00],\n",
      "           [ 0.0000e+00]],\n",
      "\n",
      "          [[-2.3469e-08],\n",
      "           [ 7.0548e-10],\n",
      "           [-8.6736e-08],\n",
      "           [ 7.0548e-10]],\n",
      "\n",
      "          [[ 4.6700e-08],\n",
      "           [-8.9102e-08],\n",
      "           [-1.2862e-07],\n",
      "           [-8.9102e-08]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0000e+00],\n",
      "           [ 0.0000e+00],\n",
      "           [ 0.0000e+00],\n",
      "           [ 0.0000e+00]],\n",
      "\n",
      "          [[ 0.0000e+00],\n",
      "           [ 0.0000e+00],\n",
      "           [ 0.0000e+00],\n",
      "           [ 0.0000e+00]],\n",
      "\n",
      "          [[-2.3469e-08],\n",
      "           [ 7.0548e-10],\n",
      "           [-8.6736e-08],\n",
      "           [ 7.0548e-10]],\n",
      "\n",
      "          [[ 4.6700e-08],\n",
      "           [-8.9102e-08],\n",
      "           [-1.2862e-07],\n",
      "           [-8.9102e-08]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0000e+00],\n",
      "           [ 0.0000e+00],\n",
      "           [ 0.0000e+00],\n",
      "           [ 0.0000e+00]],\n",
      "\n",
      "          [[ 0.0000e+00],\n",
      "           [ 0.0000e+00],\n",
      "           [ 0.0000e+00],\n",
      "           [ 0.0000e+00]],\n",
      "\n",
      "          [[-2.3469e-08],\n",
      "           [ 7.0548e-10],\n",
      "           [-8.6736e-08],\n",
      "           [ 7.0548e-10]],\n",
      "\n",
      "          [[ 4.6700e-08],\n",
      "           [-8.9102e-08],\n",
      "           [-1.2862e-07],\n",
      "           [-8.9102e-08]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 0.0000e+00],\n",
      "           [ 0.0000e+00],\n",
      "           [ 0.0000e+00],\n",
      "           [ 0.0000e+00]],\n",
      "\n",
      "          [[ 0.0000e+00],\n",
      "           [ 0.0000e+00],\n",
      "           [ 0.0000e+00],\n",
      "           [ 0.0000e+00]],\n",
      "\n",
      "          [[-2.7542e-08],\n",
      "           [-1.7876e-08],\n",
      "           [-1.2188e-08],\n",
      "           [ 1.1583e-10]],\n",
      "\n",
      "          [[ 1.6194e-08],\n",
      "           [-2.3913e-08],\n",
      "           [ 6.3678e-08],\n",
      "           [-3.5832e-08]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0000e+00],\n",
      "           [ 0.0000e+00],\n",
      "           [ 0.0000e+00],\n",
      "           [ 0.0000e+00]],\n",
      "\n",
      "          [[ 0.0000e+00],\n",
      "           [ 0.0000e+00],\n",
      "           [ 0.0000e+00],\n",
      "           [ 0.0000e+00]],\n",
      "\n",
      "          [[-2.7542e-08],\n",
      "           [-1.7876e-08],\n",
      "           [-1.2188e-08],\n",
      "           [ 1.1583e-10]],\n",
      "\n",
      "          [[ 1.6194e-08],\n",
      "           [-2.3913e-08],\n",
      "           [ 6.3678e-08],\n",
      "           [-3.5832e-08]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0000e+00],\n",
      "           [ 0.0000e+00],\n",
      "           [ 0.0000e+00],\n",
      "           [ 0.0000e+00]],\n",
      "\n",
      "          [[ 0.0000e+00],\n",
      "           [ 0.0000e+00],\n",
      "           [ 0.0000e+00],\n",
      "           [ 0.0000e+00]],\n",
      "\n",
      "          [[-2.7542e-08],\n",
      "           [-1.7876e-08],\n",
      "           [-1.2188e-08],\n",
      "           [ 1.1583e-10]],\n",
      "\n",
      "          [[ 1.6194e-08],\n",
      "           [-2.3913e-08],\n",
      "           [ 6.3678e-08],\n",
      "           [-3.5832e-08]]]]], device='cuda:0') <CopySlices object at 0x7f6c440fb5b0> torch.Size([1, 172212, 4, 4, 1])\n",
      "\u001b[92m -------------------- \u001b[0m\n",
      "\u001b[92m Line:  log((\"Sigmas gradient: \", sigmas.grad, sigmas.grad_fn, sigmas.shape), True, color=bcolors.OKGREEN) \u001b[0m\n",
      "Sigmas gradient:  tensor([[[[[0.],\n",
      "           [0.],\n",
      "           [0.],\n",
      "           [0.]],\n",
      "\n",
      "          [[0.],\n",
      "           [0.],\n",
      "           [0.],\n",
      "           [0.]],\n",
      "\n",
      "          [[0.],\n",
      "           [0.],\n",
      "           [0.],\n",
      "           [0.]],\n",
      "\n",
      "          [[0.],\n",
      "           [0.],\n",
      "           [0.],\n",
      "           [0.]]],\n",
      "\n",
      "\n",
      "         [[[0.],\n",
      "           [0.],\n",
      "           [0.],\n",
      "           [0.]],\n",
      "\n",
      "          [[0.],\n",
      "           [0.],\n",
      "           [0.],\n",
      "           [0.]],\n",
      "\n",
      "          [[0.],\n",
      "           [0.],\n",
      "           [0.],\n",
      "           [0.]],\n",
      "\n",
      "          [[0.],\n",
      "           [0.],\n",
      "           [0.],\n",
      "           [0.]]],\n",
      "\n",
      "\n",
      "         [[[0.],\n",
      "           [0.],\n",
      "           [0.],\n",
      "           [0.]],\n",
      "\n",
      "          [[0.],\n",
      "           [0.],\n",
      "           [0.],\n",
      "           [0.]],\n",
      "\n",
      "          [[0.],\n",
      "           [0.],\n",
      "           [0.],\n",
      "           [0.]],\n",
      "\n",
      "          [[0.],\n",
      "           [0.],\n",
      "           [0.],\n",
      "           [0.]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[0.],\n",
      "           [0.],\n",
      "           [0.],\n",
      "           [0.]],\n",
      "\n",
      "          [[0.],\n",
      "           [0.],\n",
      "           [0.],\n",
      "           [0.]],\n",
      "\n",
      "          [[0.],\n",
      "           [0.],\n",
      "           [0.],\n",
      "           [0.]],\n",
      "\n",
      "          [[0.],\n",
      "           [0.],\n",
      "           [0.],\n",
      "           [0.]]],\n",
      "\n",
      "\n",
      "         [[[0.],\n",
      "           [0.],\n",
      "           [0.],\n",
      "           [0.]],\n",
      "\n",
      "          [[0.],\n",
      "           [0.],\n",
      "           [0.],\n",
      "           [0.]],\n",
      "\n",
      "          [[0.],\n",
      "           [0.],\n",
      "           [0.],\n",
      "           [0.]],\n",
      "\n",
      "          [[0.],\n",
      "           [0.],\n",
      "           [0.],\n",
      "           [0.]]],\n",
      "\n",
      "\n",
      "         [[[0.],\n",
      "           [0.],\n",
      "           [0.],\n",
      "           [0.]],\n",
      "\n",
      "          [[0.],\n",
      "           [0.],\n",
      "           [0.],\n",
      "           [0.]],\n",
      "\n",
      "          [[0.],\n",
      "           [0.],\n",
      "           [0.],\n",
      "           [0.]],\n",
      "\n",
      "          [[0.],\n",
      "           [0.],\n",
      "           [0.],\n",
      "           [0.]]]]], device='cuda:0') <CopySlices object at 0x7f6c440dea40> torch.Size([1, 172212, 4, 4, 1])\n",
      "\u001b[92m -------------------- \u001b[0m\n",
      "\u001b[93m Line:  log((\"Saving checkpoint\", checkpoint.keys()), should_log, color=bcolors.WARNING) \u001b[0m\n",
      "Saving checkpoint dict_keys(['epoch', 'run_name', 'hyperparameters', 'model_state_dict', 'loss', 'optimizer_hash_state_dict'])\n",
      "\u001b[93m -------------------- \u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Loss: 30.957942962646484, Collisions: [  0.   0. 290. 731.], PSNR: None: 100%|██████████| 1/1 [00:05<00:00,  5.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[96m Line:  log((\"log:\", to_log), should_log) \u001b[0m\n",
      "log: {'lr': 0.001, 'train/min_possible_collisions_level_0': 0, 'train/min_possible_collisions_level_1': 0, 'train/min_possible_collisions_level_2': 59, 'train/min_possible_collisions_level_3': 503, 'train/collisions_level_0': 0.0, 'train/collisions_level_1': 0.0, 'train/collisions_level_2': 290.0, 'train/collisions_level_3': 731.0, 'train/histograms_level_0': None, 'train/histograms_level_1': None, 'train/media/histograms_level_2': <wandb.sdk.data_types.image.Image object at 0x7f6c7c07fe20>, 'train/media/histograms_level_3': <wandb.sdk.data_types.image.Image object at 0x7f6c7c0374f0>, 'train/kl_div_losses_level_0': 0.0, 'train/kl_div_losses_level_1': 0.0, 'train/kl_div_losses_level_2': 15.585391, 'train/kl_div_losses_level_3': 15.372543, 'train/sigmas_losses_level_0': 1.00000005e-20, 'train/sigmas_losses_level_1': 1.00000005e-20, 'train/sigmas_losses_level_2': 0.37297875, 'train/sigmas_losses_level_3': 0.3725219, 'train/reg_loss': 7.508126258850098, 'train/loss': 30.957942962646484}\n",
      "\u001b[96m -------------------- \u001b[0m\n",
      "\u001b[95m Line:  print_allocated_memory(should_log_allocated_memory) , from:  <module> \u001b[0m\n",
      "Allocated Memory: 0.02 GB\n",
      "Peak Allocated Memory: 3.03 GB\n",
      "\u001b[96m -------------------- \u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "plt.ioff()\n",
    "should_calc_hists = False\n",
    "\n",
    "pbar = tqdm(range(0, hyperparameters[\"epochs\"]))\n",
    "best_loss = np.inf\n",
    "\n",
    "print_allocated_memory(should_log_allocated_memory)\n",
    "\n",
    "for e in pbar:\n",
    "    should_calc_hists = ((e == hyperparameters[\"epochs\"] - 1) or (e % histograms_rate == 0) or early_stopper.early_stop)\n",
    "    \n",
    "    if hyperparameters[\"should_fast_hash\"] and (e > 0):\n",
    "        should_calc_hists = False\n",
    "\n",
    "    train_dict = train_loop(\n",
    "        x=X.to(device),\n",
    "        y=Y.to(device),\n",
    "        h=h,\n",
    "        w=w,\n",
    "        model=gngfModel,\n",
    "        optimizers=optimizers,\n",
    "        loss_fn=loss_fn,\n",
    "        l_kl_loss=hyperparameters[\"l_kl_loss\"],\n",
    "        l_sigmas_loss=hyperparameters[\"l_sigmas_loss\"],\n",
    "        l_collisions_loss=hyperparameters[\"l_collisions_loss\"],\n",
    "        l_images_loss=hyperparameters[\"l_images_loss\"],\n",
    "        l_reg_loss=hyperparameters[\"l_reg_loss\"],\n",
    "        norm_regularization_order=hyperparameters[\"norm_regularization_order\"],\n",
    "        gradient_clipping=hyperparameters[\"gradient_clipping\"],\n",
    "        should_calc_hists=should_calc_hists,\n",
    "        should_learn_images=hyperparameters[\"should_learn_images\"],\n",
    "        excluded_params_from_reg_loss=hyperparameters[\"excluded_params_from_reg_loss\"],\n",
    "        should_log=[] if should_log else [],\n",
    "        # should_log=[0, 1] if should_log else [],\n",
    "        should_log_grads=should_log_grads\n",
    "    )\n",
    "\n",
    "    if np.isnan(train_dict[\"loss\"]):\n",
    "        log((\"!!! NaN !!!\"), True, color=bcolors.FAIL)\n",
    "        break \n",
    "\n",
    "    if train_dict[\"loss\"] < best_loss: # only if the loss is better than the previous one save the model\n",
    "        best_loss = train_dict[\"loss\"]\n",
    "\n",
    "        checkpoint = {\n",
    "            \"epoch\": e,\n",
    "            \"run_name\": time,\n",
    "            \"hyperparameters\": hyperparameters,\n",
    "            \"model_state_dict\": gngfModel.state_dict(),\n",
    "            \"loss\": train_dict[\"loss\"],\n",
    "        }\n",
    "\n",
    "        if hyperparameters[\"should_learn_images\"]:\n",
    "            checkpoint[\"optimizer_NeRF_state_dict\"] = optimizers[\"NeRF\"].state_dict()\n",
    "\n",
    "        if not hyperparameters[\"should_fast_hash\"]:\n",
    "            checkpoint[\"optimizer_hash_state_dict\"] = optimizers[\"hash\"].state_dict()\n",
    "\n",
    "        if save_weights_rate is not None and (e % save_weights_rate == 0):\n",
    "            torch.save(checkpoint, f\"./weights/{time}_checkpoint.pth\") # overwrite the last checkpoint \n",
    "\n",
    "        log((\"Saving checkpoint\", checkpoint.keys()), should_log, color=bcolors.WARNING)\n",
    "        del checkpoint\n",
    "\n",
    "    wandb_log(\n",
    "        e=e,\n",
    "        batch_size=batch_size,\n",
    "        lr=scheduler.get_last_lr()[0] if (hyperparameters[\"scheduler_type\"] is not None) else None,\n",
    "        train_obj=train_dict,\n",
    "        should_log=True if should_log else False,\n",
    "        should_wandb=should_wandb\n",
    "    )\n",
    "\n",
    "    if hyperparameters[\"scheduler_type\"] is not None:\n",
    "        scheduler.step()\n",
    "\n",
    "    if early_stopper.early_stop:\n",
    "        print(\"!!! Stopping at epoch:\", e, \"!!!\")\n",
    "\n",
    "        del train_dict\n",
    "        break\n",
    "\n",
    "    early_stopper(train_dict[\"loss\"])\n",
    "\n",
    "    pbar.set_description(f\"Epoch {e} - Loss: {train_dict['loss']}, Collisions: {train_dict['collisions']}, PSNR: {train_dict['images_psnr']}\")\n",
    "    \n",
    "    print_allocated_memory(should_log_allocated_memory)\n",
    "    del train_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if should_wandb:\n",
    "    wandb.finish()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
